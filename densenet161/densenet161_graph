digraph {
	graph [size="621.9,621.9"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1574703919136 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	1574704485408 [label=AddmmBackward0]
	1574704485552 -> 1574704485408
	1574606859120 [label="classifier.bias
 (1000)" fillcolor=lightblue]
	1574606859120 -> 1574704485552
	1574704485552 [label=AccumulateGrad]
	1574704485600 -> 1574704485408
	1574704485600 [label=ReshapeAliasBackward0]
	1574704485696 -> 1574704485600
	1574704485696 [label=MeanBackward1]
	1574704485840 -> 1574704485696
	1574704485840 [label=ReluBackward0]
	1574704485936 -> 1574704485840
	1574704485936 [label=NativeBatchNormBackward0]
	1574704486032 -> 1574704485936
	1574704486032 [label=CatBackward0]
	1574704486224 -> 1574704486032
	1574704486224 [label=AvgPool2DBackward0]
	1574704487472 -> 1574704486224
	1574704487472 [label=ConvolutionBackward0]
	1574704487568 -> 1574704487472
	1574704487568 [label=ReluBackward0]
	1574704487712 -> 1574704487568
	1574704487712 [label=NativeBatchNormBackward0]
	1574704487808 -> 1574704487712
	1574704487808 [label=CatBackward0]
	1574704488000 -> 1574704487808
	1574704488000 [label=AvgPool2DBackward0]
	1574704489824 -> 1574704488000
	1574704489824 [label=ConvolutionBackward0]
	1574704489920 -> 1574704489824
	1574704489920 [label=ReluBackward0]
	1574704490064 -> 1574704489920
	1574704490064 [label=NativeBatchNormBackward0]
	1574704490160 -> 1574704490064
	1574704490160 [label=CatBackward0]
	1574704490352 -> 1574704490160
	1574704490352 [label=AvgPool2DBackward0]
	1574704491024 -> 1574704490352
	1574704491024 [label=ConvolutionBackward0]
	1574704491120 -> 1574704491024
	1574704491120 [label=ReluBackward0]
	1574704491264 -> 1574704491120
	1574704491264 [label=NativeBatchNormBackward0]
	1574704491360 -> 1574704491264
	1574704491360 [label=CatBackward0]
	1574704491552 -> 1574704491360
	1574704491552 [label=MaxPool2DWithIndicesBackward0]
	1574704491936 -> 1574704491552
	1574704491936 [label=ReluBackward0]
	1574704492032 -> 1574704491936
	1574704492032 [label=NativeBatchNormBackward0]
	1574704492128 -> 1574704492032
	1574704492128 [label=ConvolutionBackward0]
	1574704492320 -> 1574704492128
	1574584769568 [label="features.conv0.weight
 (96, 3, 7, 7)" fillcolor=lightblue]
	1574584769568 -> 1574704492320
	1574704492320 [label=AccumulateGrad]
	1574704492080 -> 1574704492032
	1574584769648 [label="features.norm0.weight
 (96)" fillcolor=lightblue]
	1574584769648 -> 1574704492080
	1574704492080 [label=AccumulateGrad]
	1574704491840 -> 1574704492032
	1574584769728 [label="features.norm0.bias
 (96)" fillcolor=lightblue]
	1574584769728 -> 1574704491840
	1574704491840 [label=AccumulateGrad]
	1574704491504 -> 1574704491360
	1574704491504 [label=ConvolutionBackward0]
	1574704492176 -> 1574704491504
	1574704492176 [label=ReluBackward0]
	1574704492368 -> 1574704492176
	1574704492368 [label=NativeBatchNormBackward0]
	1574704492464 -> 1574704492368
	1574704492464 [label=ConvolutionBackward0]
	1574704492656 -> 1574704492464
	1574704492656 [label=ReluBackward0]
	1574704492800 -> 1574704492656
	1574704492800 [label=NativeBatchNormBackward0]
	1574704492896 -> 1574704492800
	1574704492896 [label=CatBackward0]
	1574704491552 -> 1574704492896
	1574704492848 -> 1574704492800
	1574584770208 [label="features.denseblock1.denselayer1.norm1.weight
 (96)" fillcolor=lightblue]
	1574584770208 -> 1574704492848
	1574704492848 [label=AccumulateGrad]
	1574704492704 -> 1574704492800
	1574584770288 [label="features.denseblock1.denselayer1.norm1.bias
 (96)" fillcolor=lightblue]
	1574584770288 -> 1574704492704
	1574704492704 [label=AccumulateGrad]
	1574704492608 -> 1574704492464
	1574584770768 [label="features.denseblock1.denselayer1.conv1.weight
 (192, 96, 1, 1)" fillcolor=lightblue]
	1574584770768 -> 1574704492608
	1574704492608 [label=AccumulateGrad]
	1574704492224 -> 1574704492368
	1574584770848 [label="features.denseblock1.denselayer1.norm2.weight
 (192)" fillcolor=lightblue]
	1574584770848 -> 1574704492224
	1574704492224 [label=AccumulateGrad]
	1574704492272 -> 1574704492368
	1574584770928 [label="features.denseblock1.denselayer1.norm2.bias
 (192)" fillcolor=lightblue]
	1574584770928 -> 1574704492272
	1574704492272 [label=AccumulateGrad]
	1574704491984 -> 1574704491504
	1574584771408 [label="features.denseblock1.denselayer1.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574584771408 -> 1574704491984
	1574704491984 [label=AccumulateGrad]
	1574704491456 -> 1574704491360
	1574704491456 [label=ConvolutionBackward0]
	1574704492512 -> 1574704491456
	1574704492512 [label=ReluBackward0]
	1574704492944 -> 1574704492512
	1574704492944 [label=NativeBatchNormBackward0]
	1574704493040 -> 1574704492944
	1574704493040 [label=ConvolutionBackward0]
	1574704493232 -> 1574704493040
	1574704493232 [label=ReluBackward0]
	1574704493376 -> 1574704493232
	1574704493376 [label=NativeBatchNormBackward0]
	1574704493472 -> 1574704493376
	1574704493472 [label=CatBackward0]
	1574704491552 -> 1574704493472
	1574704491504 -> 1574704493472
	1574704493424 -> 1574704493376
	1574584771488 [label="features.denseblock1.denselayer2.norm1.weight
 (144)" fillcolor=lightblue]
	1574584771488 -> 1574704493424
	1574704493424 [label=AccumulateGrad]
	1574704493280 -> 1574704493376
	1574584771568 [label="features.denseblock1.denselayer2.norm1.bias
 (144)" fillcolor=lightblue]
	1574584771568 -> 1574704493280
	1574704493280 [label=AccumulateGrad]
	1574704493184 -> 1574704493040
	1574584772048 [label="features.denseblock1.denselayer2.conv1.weight
 (192, 144, 1, 1)" fillcolor=lightblue]
	1574584772048 -> 1574704493184
	1574704493184 [label=AccumulateGrad]
	1574704492752 -> 1574704492944
	1574584772128 [label="features.denseblock1.denselayer2.norm2.weight
 (192)" fillcolor=lightblue]
	1574584772128 -> 1574704492752
	1574704492752 [label=AccumulateGrad]
	1574704492416 -> 1574704492944
	1574584772208 [label="features.denseblock1.denselayer2.norm2.bias
 (192)" fillcolor=lightblue]
	1574584772208 -> 1574704492416
	1574704492416 [label=AccumulateGrad]
	1574704492560 -> 1574704491456
	1574584772688 [label="features.denseblock1.denselayer2.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574584772688 -> 1574704492560
	1574704492560 [label=AccumulateGrad]
	1574704491600 -> 1574704491360
	1574704491600 [label=ConvolutionBackward0]
	1574704492992 -> 1574704491600
	1574704492992 [label=ReluBackward0]
	1574704493520 -> 1574704492992
	1574704493520 [label=NativeBatchNormBackward0]
	1574704493616 -> 1574704493520
	1574704493616 [label=ConvolutionBackward0]
	1574704493808 -> 1574704493616
	1574704493808 [label=ReluBackward0]
	1574704493952 -> 1574704493808
	1574704493952 [label=NativeBatchNormBackward0]
	1574704494048 -> 1574704493952
	1574704494048 [label=CatBackward0]
	1574704491552 -> 1574704494048
	1574704491504 -> 1574704494048
	1574704491456 -> 1574704494048
	1574704494000 -> 1574704493952
	1574584772768 [label="features.denseblock1.denselayer3.norm1.weight
 (192)" fillcolor=lightblue]
	1574584772768 -> 1574704494000
	1574704494000 [label=AccumulateGrad]
	1574704493856 -> 1574704493952
	1574584772848 [label="features.denseblock1.denselayer3.norm1.bias
 (192)" fillcolor=lightblue]
	1574584772848 -> 1574704493856
	1574704493856 [label=AccumulateGrad]
	1574704493760 -> 1574704493616
	1574584773328 [label="features.denseblock1.denselayer3.conv1.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	1574584773328 -> 1574704493760
	1574704493760 [label=AccumulateGrad]
	1574704493328 -> 1574704493520
	1574584773408 [label="features.denseblock1.denselayer3.norm2.weight
 (192)" fillcolor=lightblue]
	1574584773408 -> 1574704493328
	1574704493328 [label=AccumulateGrad]
	1574704493088 -> 1574704493520
	1574584773488 [label="features.denseblock1.denselayer3.norm2.bias
 (192)" fillcolor=lightblue]
	1574584773488 -> 1574704493088
	1574704493088 [label=AccumulateGrad]
	1574704493136 -> 1574704491600
	1574584773968 [label="features.denseblock1.denselayer3.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574584773968 -> 1574704493136
	1574704493136 [label=AccumulateGrad]
	1574704491648 -> 1574704491360
	1574704491648 [label=ConvolutionBackward0]
	1574704493568 -> 1574704491648
	1574704493568 [label=ReluBackward0]
	1574704494096 -> 1574704493568
	1574704494096 [label=NativeBatchNormBackward0]
	1574704494192 -> 1574704494096
	1574704494192 [label=ConvolutionBackward0]
	1574704494384 -> 1574704494192
	1574704494384 [label=ReluBackward0]
	1574704494528 -> 1574704494384
	1574704494528 [label=NativeBatchNormBackward0]
	1574704494624 -> 1574704494528
	1574704494624 [label=CatBackward0]
	1574704491552 -> 1574704494624
	1574704491504 -> 1574704494624
	1574704491456 -> 1574704494624
	1574704491600 -> 1574704494624
	1574704494576 -> 1574704494528
	1574584774048 [label="features.denseblock1.denselayer4.norm1.weight
 (240)" fillcolor=lightblue]
	1574584774048 -> 1574704494576
	1574704494576 [label=AccumulateGrad]
	1574704494432 -> 1574704494528
	1574584774128 [label="features.denseblock1.denselayer4.norm1.bias
 (240)" fillcolor=lightblue]
	1574584774128 -> 1574704494432
	1574704494432 [label=AccumulateGrad]
	1574704494336 -> 1574704494192
	1574584774608 [label="features.denseblock1.denselayer4.conv1.weight
 (192, 240, 1, 1)" fillcolor=lightblue]
	1574584774608 -> 1574704494336
	1574704494336 [label=AccumulateGrad]
	1574704493904 -> 1574704494096
	1574584774688 [label="features.denseblock1.denselayer4.norm2.weight
 (192)" fillcolor=lightblue]
	1574584774688 -> 1574704493904
	1574704493904 [label=AccumulateGrad]
	1574704493664 -> 1574704494096
	1574584774768 [label="features.denseblock1.denselayer4.norm2.bias
 (192)" fillcolor=lightblue]
	1574584774768 -> 1574704493664
	1574704493664 [label=AccumulateGrad]
	1574704493712 -> 1574704491648
	1574584775248 [label="features.denseblock1.denselayer4.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574584775248 -> 1574704493712
	1574704493712 [label=AccumulateGrad]
	1574704491696 -> 1574704491360
	1574704491696 [label=ConvolutionBackward0]
	1574704494144 -> 1574704491696
	1574704494144 [label=ReluBackward0]
	1574704494672 -> 1574704494144
	1574704494672 [label=NativeBatchNormBackward0]
	1574704494768 -> 1574704494672
	1574704494768 [label=ConvolutionBackward0]
	1574704494960 -> 1574704494768
	1574704494960 [label=ReluBackward0]
	1574704495104 -> 1574704494960
	1574704495104 [label=NativeBatchNormBackward0]
	1574704495200 -> 1574704495104
	1574704495200 [label=CatBackward0]
	1574704491552 -> 1574704495200
	1574704491504 -> 1574704495200
	1574704491456 -> 1574704495200
	1574704491600 -> 1574704495200
	1574704491648 -> 1574704495200
	1574704495152 -> 1574704495104
	1574584775328 [label="features.denseblock1.denselayer5.norm1.weight
 (288)" fillcolor=lightblue]
	1574584775328 -> 1574704495152
	1574704495152 [label=AccumulateGrad]
	1574704495008 -> 1574704495104
	1574584775408 [label="features.denseblock1.denselayer5.norm1.bias
 (288)" fillcolor=lightblue]
	1574584775408 -> 1574704495008
	1574704495008 [label=AccumulateGrad]
	1574704494912 -> 1574704494768
	1574584775888 [label="features.denseblock1.denselayer5.conv1.weight
 (192, 288, 1, 1)" fillcolor=lightblue]
	1574584775888 -> 1574704494912
	1574704494912 [label=AccumulateGrad]
	1574704494480 -> 1574704494672
	1574584775968 [label="features.denseblock1.denselayer5.norm2.weight
 (192)" fillcolor=lightblue]
	1574584775968 -> 1574704494480
	1574704494480 [label=AccumulateGrad]
	1574704494240 -> 1574704494672
	1574584776048 [label="features.denseblock1.denselayer5.norm2.bias
 (192)" fillcolor=lightblue]
	1574584776048 -> 1574704494240
	1574704494240 [label=AccumulateGrad]
	1574704494288 -> 1574704491696
	1574584776528 [label="features.denseblock1.denselayer5.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574584776528 -> 1574704494288
	1574704494288 [label=AccumulateGrad]
	1574704491744 -> 1574704491360
	1574704491744 [label=ConvolutionBackward0]
	1574704494720 -> 1574704491744
	1574704494720 [label=ReluBackward0]
	1574704495248 -> 1574704494720
	1574704495248 [label=NativeBatchNormBackward0]
	1574704495344 -> 1574704495248
	1574704495344 [label=ConvolutionBackward0]
	1574704495536 -> 1574704495344
	1574704495536 [label=ReluBackward0]
	1574704495680 -> 1574704495536
	1574704495680 [label=NativeBatchNormBackward0]
	1574704495776 -> 1574704495680
	1574704495776 [label=CatBackward0]
	1574704491552 -> 1574704495776
	1574704491504 -> 1574704495776
	1574704491456 -> 1574704495776
	1574704491600 -> 1574704495776
	1574704491648 -> 1574704495776
	1574704491696 -> 1574704495776
	1574704495728 -> 1574704495680
	1574584776608 [label="features.denseblock1.denselayer6.norm1.weight
 (336)" fillcolor=lightblue]
	1574584776608 -> 1574704495728
	1574704495728 [label=AccumulateGrad]
	1574704495584 -> 1574704495680
	1574584776688 [label="features.denseblock1.denselayer6.norm1.bias
 (336)" fillcolor=lightblue]
	1574584776688 -> 1574704495584
	1574704495584 [label=AccumulateGrad]
	1574704495488 -> 1574704495344
	1574584777168 [label="features.denseblock1.denselayer6.conv1.weight
 (192, 336, 1, 1)" fillcolor=lightblue]
	1574584777168 -> 1574704495488
	1574704495488 [label=AccumulateGrad]
	1574704495056 -> 1574704495248
	1574584777248 [label="features.denseblock1.denselayer6.norm2.weight
 (192)" fillcolor=lightblue]
	1574584777248 -> 1574704495056
	1574704495056 [label=AccumulateGrad]
	1574704494816 -> 1574704495248
	1574584777328 [label="features.denseblock1.denselayer6.norm2.bias
 (192)" fillcolor=lightblue]
	1574584777328 -> 1574704494816
	1574704494816 [label=AccumulateGrad]
	1574704494864 -> 1574704491744
	1574584777808 [label="features.denseblock1.denselayer6.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574584777808 -> 1574704494864
	1574704494864 [label=AccumulateGrad]
	1574704491312 -> 1574704491264
	1574584777888 [label="features.transition1.norm.weight
 (384)" fillcolor=lightblue]
	1574584777888 -> 1574704491312
	1574704491312 [label=AccumulateGrad]
	1574704491168 -> 1574704491264
	1574584777968 [label="features.transition1.norm.bias
 (384)" fillcolor=lightblue]
	1574584777968 -> 1574704491168
	1574704491168 [label=AccumulateGrad]
	1574704491072 -> 1574704491024
	1574584778448 [label="features.transition1.conv.weight
 (192, 384, 1, 1)" fillcolor=lightblue]
	1574584778448 -> 1574704491072
	1574704491072 [label=AccumulateGrad]
	1574704490304 -> 1574704490160
	1574704490304 [label=ConvolutionBackward0]
	1574704491792 -> 1574704490304
	1574704491792 [label=ReluBackward0]
	1574704491888 -> 1574704491792
	1574704491888 [label=NativeBatchNormBackward0]
	1574704495296 -> 1574704491888
	1574704495296 [label=ConvolutionBackward0]
	1574704495632 -> 1574704495296
	1574704495632 [label=ReluBackward0]
	1574704496016 -> 1574704495632
	1574704496016 [label=NativeBatchNormBackward0]
	1574704496112 -> 1574704496016
	1574704496112 [label=CatBackward0]
	1574704490352 -> 1574704496112
	1574704496064 -> 1574704496016
	1574584778528 [label="features.denseblock2.denselayer1.norm1.weight
 (192)" fillcolor=lightblue]
	1574584778528 -> 1574704496064
	1574704496064 [label=AccumulateGrad]
	1574704495920 -> 1574704496016
	1574584778608 [label="features.denseblock2.denselayer1.norm1.bias
 (192)" fillcolor=lightblue]
	1574584778608 -> 1574704495920
	1574704495920 [label=AccumulateGrad]
	1574704495824 -> 1574704495296
	1574587761040 [label="features.denseblock2.denselayer1.conv1.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	1574587761040 -> 1574704495824
	1574704495824 [label=AccumulateGrad]
	1574704495440 -> 1574704491888
	1574587761120 [label="features.denseblock2.denselayer1.norm2.weight
 (192)" fillcolor=lightblue]
	1574587761120 -> 1574704495440
	1574704495440 [label=AccumulateGrad]
	1574704491408 -> 1574704491888
	1574587761200 [label="features.denseblock2.denselayer1.norm2.bias
 (192)" fillcolor=lightblue]
	1574587761200 -> 1574704491408
	1574704491408 [label=AccumulateGrad]
	1574704490928 -> 1574704490304
	1574587761680 [label="features.denseblock2.denselayer1.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587761680 -> 1574704490928
	1574704490928 [label=AccumulateGrad]
	1574704490256 -> 1574704490160
	1574704490256 [label=ConvolutionBackward0]
	1574704495392 -> 1574704490256
	1574704495392 [label=ReluBackward0]
	1574704496160 -> 1574704495392
	1574704496160 [label=NativeBatchNormBackward0]
	1574704496256 -> 1574704496160
	1574704496256 [label=ConvolutionBackward0]
	1574704496448 -> 1574704496256
	1574704496448 [label=ReluBackward0]
	1574704496592 -> 1574704496448
	1574704496592 [label=NativeBatchNormBackward0]
	1574704496496 -> 1574704496592
	1574704496496 [label=CatBackward0]
	1574704490352 -> 1574704496496
	1574704490304 -> 1574704496496
	1574704103536 -> 1574704496592
	1574587761760 [label="features.denseblock2.denselayer2.norm1.weight
 (240)" fillcolor=lightblue]
	1574587761760 -> 1574704103536
	1574704103536 [label=AccumulateGrad]
	1574704103488 -> 1574704496592
	1574587761840 [label="features.denseblock2.denselayer2.norm1.bias
 (240)" fillcolor=lightblue]
	1574587761840 -> 1574704103488
	1574704103488 [label=AccumulateGrad]
	1574704496400 -> 1574704496256
	1574587762320 [label="features.denseblock2.denselayer2.conv1.weight
 (192, 240, 1, 1)" fillcolor=lightblue]
	1574587762320 -> 1574704496400
	1574704496400 [label=AccumulateGrad]
	1574704495872 -> 1574704496160
	1574587762400 [label="features.denseblock2.denselayer2.norm2.weight
 (192)" fillcolor=lightblue]
	1574587762400 -> 1574704495872
	1574704495872 [label=AccumulateGrad]
	1574704491216 -> 1574704496160
	1574587762480 [label="features.denseblock2.denselayer2.norm2.bias
 (192)" fillcolor=lightblue]
	1574587762480 -> 1574704491216
	1574704491216 [label=AccumulateGrad]
	1574704495968 -> 1574704490256
	1574587762960 [label="features.denseblock2.denselayer2.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587762960 -> 1574704495968
	1574704495968 [label=AccumulateGrad]
	1574704490400 -> 1574704490160
	1574704490400 [label=ConvolutionBackward0]
	1574704496208 -> 1574704490400
	1574704496208 [label=ReluBackward0]
	1574704496544 -> 1574704496208
	1574704496544 [label=NativeBatchNormBackward0]
	1574704103680 -> 1574704496544
	1574704103680 [label=ConvolutionBackward0]
	1574704103872 -> 1574704103680
	1574704103872 [label=ReluBackward0]
	1574704104016 -> 1574704103872
	1574704104016 [label=NativeBatchNormBackward0]
	1574704104112 -> 1574704104016
	1574704104112 [label=CatBackward0]
	1574704490352 -> 1574704104112
	1574704490304 -> 1574704104112
	1574704490256 -> 1574704104112
	1574704104064 -> 1574704104016
	1574587763040 [label="features.denseblock2.denselayer3.norm1.weight
 (288)" fillcolor=lightblue]
	1574587763040 -> 1574704104064
	1574704104064 [label=AccumulateGrad]
	1574704103920 -> 1574704104016
	1574587763120 [label="features.denseblock2.denselayer3.norm1.bias
 (288)" fillcolor=lightblue]
	1574587763120 -> 1574704103920
	1574704103920 [label=AccumulateGrad]
	1574704103824 -> 1574704103680
	1574587763600 [label="features.denseblock2.denselayer3.conv1.weight
 (192, 288, 1, 1)" fillcolor=lightblue]
	1574587763600 -> 1574704103824
	1574704103824 [label=AccumulateGrad]
	1574704103584 -> 1574704496544
	1574587763680 [label="features.denseblock2.denselayer3.norm2.weight
 (192)" fillcolor=lightblue]
	1574587763680 -> 1574704103584
	1574704103584 [label=AccumulateGrad]
	1574704103728 -> 1574704496544
	1574587763760 [label="features.denseblock2.denselayer3.norm2.bias
 (192)" fillcolor=lightblue]
	1574587763760 -> 1574704103728
	1574704103728 [label=AccumulateGrad]
	1574704496352 -> 1574704490400
	1574587764240 [label="features.denseblock2.denselayer3.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587764240 -> 1574704496352
	1574704496352 [label=AccumulateGrad]
	1574704490448 -> 1574704490160
	1574704490448 [label=ConvolutionBackward0]
	1574704496304 -> 1574704490448
	1574704496304 [label=ReluBackward0]
	1574704104160 -> 1574704496304
	1574704104160 [label=NativeBatchNormBackward0]
	1574704104256 -> 1574704104160
	1574704104256 [label=ConvolutionBackward0]
	1574704104448 -> 1574704104256
	1574704104448 [label=ReluBackward0]
	1574704104592 -> 1574704104448
	1574704104592 [label=NativeBatchNormBackward0]
	1574704104688 -> 1574704104592
	1574704104688 [label=CatBackward0]
	1574704490352 -> 1574704104688
	1574704490304 -> 1574704104688
	1574704490256 -> 1574704104688
	1574704490400 -> 1574704104688
	1574704104640 -> 1574704104592
	1574587764320 [label="features.denseblock2.denselayer4.norm1.weight
 (336)" fillcolor=lightblue]
	1574587764320 -> 1574704104640
	1574704104640 [label=AccumulateGrad]
	1574704104496 -> 1574704104592
	1574587764400 [label="features.denseblock2.denselayer4.norm1.bias
 (336)" fillcolor=lightblue]
	1574587764400 -> 1574704104496
	1574704104496 [label=AccumulateGrad]
	1574704104400 -> 1574704104256
	1574587764880 [label="features.denseblock2.denselayer4.conv1.weight
 (192, 336, 1, 1)" fillcolor=lightblue]
	1574587764880 -> 1574704104400
	1574704104400 [label=AccumulateGrad]
	1574704103968 -> 1574704104160
	1574587764960 [label="features.denseblock2.denselayer4.norm2.weight
 (192)" fillcolor=lightblue]
	1574587764960 -> 1574704103968
	1574704103968 [label=AccumulateGrad]
	1574704103632 -> 1574704104160
	1574587765040 [label="features.denseblock2.denselayer4.norm2.bias
 (192)" fillcolor=lightblue]
	1574587765040 -> 1574704103632
	1574704103632 [label=AccumulateGrad]
	1574704490976 -> 1574704490448
	1574587765520 [label="features.denseblock2.denselayer4.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587765520 -> 1574704490976
	1574704490976 [label=AccumulateGrad]
	1574704490496 -> 1574704490160
	1574704490496 [label=ConvolutionBackward0]
	1574704104208 -> 1574704490496
	1574704104208 [label=ReluBackward0]
	1574704104736 -> 1574704104208
	1574704104736 [label=NativeBatchNormBackward0]
	1574704104832 -> 1574704104736
	1574704104832 [label=ConvolutionBackward0]
	1574704105024 -> 1574704104832
	1574704105024 [label=ReluBackward0]
	1574704105168 -> 1574704105024
	1574704105168 [label=NativeBatchNormBackward0]
	1574704105264 -> 1574704105168
	1574704105264 [label=CatBackward0]
	1574704490352 -> 1574704105264
	1574704490304 -> 1574704105264
	1574704490256 -> 1574704105264
	1574704490400 -> 1574704105264
	1574704490448 -> 1574704105264
	1574704105216 -> 1574704105168
	1574587765600 [label="features.denseblock2.denselayer5.norm1.weight
 (384)" fillcolor=lightblue]
	1574587765600 -> 1574704105216
	1574704105216 [label=AccumulateGrad]
	1574704105072 -> 1574704105168
	1574587765680 [label="features.denseblock2.denselayer5.norm1.bias
 (384)" fillcolor=lightblue]
	1574587765680 -> 1574704105072
	1574704105072 [label=AccumulateGrad]
	1574704104976 -> 1574704104832
	1574587766160 [label="features.denseblock2.denselayer5.conv1.weight
 (192, 384, 1, 1)" fillcolor=lightblue]
	1574587766160 -> 1574704104976
	1574704104976 [label=AccumulateGrad]
	1574704104544 -> 1574704104736
	1574587766240 [label="features.denseblock2.denselayer5.norm2.weight
 (192)" fillcolor=lightblue]
	1574587766240 -> 1574704104544
	1574704104544 [label=AccumulateGrad]
	1574704104304 -> 1574704104736
	1574587766320 [label="features.denseblock2.denselayer5.norm2.bias
 (192)" fillcolor=lightblue]
	1574587766320 -> 1574704104304
	1574704104304 [label=AccumulateGrad]
	1574704104352 -> 1574704490496
	1574587766800 [label="features.denseblock2.denselayer5.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587766800 -> 1574704104352
	1574704104352 [label=AccumulateGrad]
	1574704490544 -> 1574704490160
	1574704490544 [label=ConvolutionBackward0]
	1574704104784 -> 1574704490544
	1574704104784 [label=ReluBackward0]
	1574704105312 -> 1574704104784
	1574704105312 [label=NativeBatchNormBackward0]
	1574704105408 -> 1574704105312
	1574704105408 [label=ConvolutionBackward0]
	1574704105600 -> 1574704105408
	1574704105600 [label=ReluBackward0]
	1574704105744 -> 1574704105600
	1574704105744 [label=NativeBatchNormBackward0]
	1574704105840 -> 1574704105744
	1574704105840 [label=CatBackward0]
	1574704490352 -> 1574704105840
	1574704490304 -> 1574704105840
	1574704490256 -> 1574704105840
	1574704490400 -> 1574704105840
	1574704490448 -> 1574704105840
	1574704490496 -> 1574704105840
	1574704105792 -> 1574704105744
	1574587766880 [label="features.denseblock2.denselayer6.norm1.weight
 (432)" fillcolor=lightblue]
	1574587766880 -> 1574704105792
	1574704105792 [label=AccumulateGrad]
	1574704105648 -> 1574704105744
	1574587766960 [label="features.denseblock2.denselayer6.norm1.bias
 (432)" fillcolor=lightblue]
	1574587766960 -> 1574704105648
	1574704105648 [label=AccumulateGrad]
	1574704105552 -> 1574704105408
	1574587767440 [label="features.denseblock2.denselayer6.conv1.weight
 (192, 432, 1, 1)" fillcolor=lightblue]
	1574587767440 -> 1574704105552
	1574704105552 [label=AccumulateGrad]
	1574704105120 -> 1574704105312
	1574587767520 [label="features.denseblock2.denselayer6.norm2.weight
 (192)" fillcolor=lightblue]
	1574587767520 -> 1574704105120
	1574704105120 [label=AccumulateGrad]
	1574704104880 -> 1574704105312
	1574587767600 [label="features.denseblock2.denselayer6.norm2.bias
 (192)" fillcolor=lightblue]
	1574587767600 -> 1574704104880
	1574704104880 [label=AccumulateGrad]
	1574704104928 -> 1574704490544
	1574587768080 [label="features.denseblock2.denselayer6.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587768080 -> 1574704104928
	1574704104928 [label=AccumulateGrad]
	1574704490592 -> 1574704490160
	1574704490592 [label=ConvolutionBackward0]
	1574704105360 -> 1574704490592
	1574704105360 [label=ReluBackward0]
	1574704105888 -> 1574704105360
	1574704105888 [label=NativeBatchNormBackward0]
	1574704105984 -> 1574704105888
	1574704105984 [label=ConvolutionBackward0]
	1574704106176 -> 1574704105984
	1574704106176 [label=ReluBackward0]
	1574704106320 -> 1574704106176
	1574704106320 [label=NativeBatchNormBackward0]
	1574704106416 -> 1574704106320
	1574704106416 [label=CatBackward0]
	1574704490352 -> 1574704106416
	1574704490304 -> 1574704106416
	1574704490256 -> 1574704106416
	1574704490400 -> 1574704106416
	1574704490448 -> 1574704106416
	1574704490496 -> 1574704106416
	1574704490544 -> 1574704106416
	1574704106368 -> 1574704106320
	1574587768160 [label="features.denseblock2.denselayer7.norm1.weight
 (480)" fillcolor=lightblue]
	1574587768160 -> 1574704106368
	1574704106368 [label=AccumulateGrad]
	1574704106224 -> 1574704106320
	1574587768240 [label="features.denseblock2.denselayer7.norm1.bias
 (480)" fillcolor=lightblue]
	1574587768240 -> 1574704106224
	1574704106224 [label=AccumulateGrad]
	1574704106128 -> 1574704105984
	1574587768720 [label="features.denseblock2.denselayer7.conv1.weight
 (192, 480, 1, 1)" fillcolor=lightblue]
	1574587768720 -> 1574704106128
	1574704106128 [label=AccumulateGrad]
	1574704105696 -> 1574704105888
	1574587768800 [label="features.denseblock2.denselayer7.norm2.weight
 (192)" fillcolor=lightblue]
	1574587768800 -> 1574704105696
	1574704105696 [label=AccumulateGrad]
	1574704105456 -> 1574704105888
	1574587768880 [label="features.denseblock2.denselayer7.norm2.bias
 (192)" fillcolor=lightblue]
	1574587768880 -> 1574704105456
	1574704105456 [label=AccumulateGrad]
	1574704105504 -> 1574704490592
	1574587769360 [label="features.denseblock2.denselayer7.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587769360 -> 1574704105504
	1574704105504 [label=AccumulateGrad]
	1574704490640 -> 1574704490160
	1574704490640 [label=ConvolutionBackward0]
	1574704105936 -> 1574704490640
	1574704105936 [label=ReluBackward0]
	1574704106464 -> 1574704105936
	1574704106464 [label=NativeBatchNormBackward0]
	1574704106560 -> 1574704106464
	1574704106560 [label=ConvolutionBackward0]
	1574704106752 -> 1574704106560
	1574704106752 [label=ReluBackward0]
	1574704106896 -> 1574704106752
	1574704106896 [label=NativeBatchNormBackward0]
	1574704106992 -> 1574704106896
	1574704106992 [label=CatBackward0]
	1574704490352 -> 1574704106992
	1574704490304 -> 1574704106992
	1574704490256 -> 1574704106992
	1574704490400 -> 1574704106992
	1574704490448 -> 1574704106992
	1574704490496 -> 1574704106992
	1574704490544 -> 1574704106992
	1574704490592 -> 1574704106992
	1574704106944 -> 1574704106896
	1574587769440 [label="features.denseblock2.denselayer8.norm1.weight
 (528)" fillcolor=lightblue]
	1574587769440 -> 1574704106944
	1574704106944 [label=AccumulateGrad]
	1574704106800 -> 1574704106896
	1574587769520 [label="features.denseblock2.denselayer8.norm1.bias
 (528)" fillcolor=lightblue]
	1574587769520 -> 1574704106800
	1574704106800 [label=AccumulateGrad]
	1574704106704 -> 1574704106560
	1574587770000 [label="features.denseblock2.denselayer8.conv1.weight
 (192, 528, 1, 1)" fillcolor=lightblue]
	1574587770000 -> 1574704106704
	1574704106704 [label=AccumulateGrad]
	1574704106272 -> 1574704106464
	1574587770080 [label="features.denseblock2.denselayer8.norm2.weight
 (192)" fillcolor=lightblue]
	1574587770080 -> 1574704106272
	1574704106272 [label=AccumulateGrad]
	1574704106032 -> 1574704106464
	1574587770160 [label="features.denseblock2.denselayer8.norm2.bias
 (192)" fillcolor=lightblue]
	1574587770160 -> 1574704106032
	1574704106032 [label=AccumulateGrad]
	1574704106080 -> 1574704490640
	1574587770640 [label="features.denseblock2.denselayer8.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587770640 -> 1574704106080
	1574704106080 [label=AccumulateGrad]
	1574704490688 -> 1574704490160
	1574704490688 [label=ConvolutionBackward0]
	1574704106512 -> 1574704490688
	1574704106512 [label=ReluBackward0]
	1574704107040 -> 1574704106512
	1574704107040 [label=NativeBatchNormBackward0]
	1574704107136 -> 1574704107040
	1574704107136 [label=ConvolutionBackward0]
	1574704107328 -> 1574704107136
	1574704107328 [label=ReluBackward0]
	1574704107472 -> 1574704107328
	1574704107472 [label=NativeBatchNormBackward0]
	1574704107568 -> 1574704107472
	1574704107568 [label=CatBackward0]
	1574704490352 -> 1574704107568
	1574704490304 -> 1574704107568
	1574704490256 -> 1574704107568
	1574704490400 -> 1574704107568
	1574704490448 -> 1574704107568
	1574704490496 -> 1574704107568
	1574704490544 -> 1574704107568
	1574704490592 -> 1574704107568
	1574704490640 -> 1574704107568
	1574704107520 -> 1574704107472
	1574587770720 [label="features.denseblock2.denselayer9.norm1.weight
 (576)" fillcolor=lightblue]
	1574587770720 -> 1574704107520
	1574704107520 [label=AccumulateGrad]
	1574704107376 -> 1574704107472
	1574587770800 [label="features.denseblock2.denselayer9.norm1.bias
 (576)" fillcolor=lightblue]
	1574587770800 -> 1574704107376
	1574704107376 [label=AccumulateGrad]
	1574704107280 -> 1574704107136
	1574587771280 [label="features.denseblock2.denselayer9.conv1.weight
 (192, 576, 1, 1)" fillcolor=lightblue]
	1574587771280 -> 1574704107280
	1574704107280 [label=AccumulateGrad]
	1574704106848 -> 1574704107040
	1574587771360 [label="features.denseblock2.denselayer9.norm2.weight
 (192)" fillcolor=lightblue]
	1574587771360 -> 1574704106848
	1574704106848 [label=AccumulateGrad]
	1574704106608 -> 1574704107040
	1574587771440 [label="features.denseblock2.denselayer9.norm2.bias
 (192)" fillcolor=lightblue]
	1574587771440 -> 1574704106608
	1574704106608 [label=AccumulateGrad]
	1574704106656 -> 1574704490688
	1574587771920 [label="features.denseblock2.denselayer9.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587771920 -> 1574704106656
	1574704106656 [label=AccumulateGrad]
	1574704490736 -> 1574704490160
	1574704490736 [label=ConvolutionBackward0]
	1574704107088 -> 1574704490736
	1574704107088 [label=ReluBackward0]
	1574704107616 -> 1574704107088
	1574704107616 [label=NativeBatchNormBackward0]
	1574704107712 -> 1574704107616
	1574704107712 [label=ConvolutionBackward0]
	1574704107904 -> 1574704107712
	1574704107904 [label=ReluBackward0]
	1574704108048 -> 1574704107904
	1574704108048 [label=NativeBatchNormBackward0]
	1574704108144 -> 1574704108048
	1574704108144 [label=CatBackward0]
	1574704490352 -> 1574704108144
	1574704490304 -> 1574704108144
	1574704490256 -> 1574704108144
	1574704490400 -> 1574704108144
	1574704490448 -> 1574704108144
	1574704490496 -> 1574704108144
	1574704490544 -> 1574704108144
	1574704490592 -> 1574704108144
	1574704490640 -> 1574704108144
	1574704490688 -> 1574704108144
	1574704108096 -> 1574704108048
	1574587772000 [label="features.denseblock2.denselayer10.norm1.weight
 (624)" fillcolor=lightblue]
	1574587772000 -> 1574704108096
	1574704108096 [label=AccumulateGrad]
	1574704107952 -> 1574704108048
	1574587772080 [label="features.denseblock2.denselayer10.norm1.bias
 (624)" fillcolor=lightblue]
	1574587772080 -> 1574704107952
	1574704107952 [label=AccumulateGrad]
	1574704107856 -> 1574704107712
	1574587772560 [label="features.denseblock2.denselayer10.conv1.weight
 (192, 624, 1, 1)" fillcolor=lightblue]
	1574587772560 -> 1574704107856
	1574704107856 [label=AccumulateGrad]
	1574704107424 -> 1574704107616
	1574587772640 [label="features.denseblock2.denselayer10.norm2.weight
 (192)" fillcolor=lightblue]
	1574587772640 -> 1574704107424
	1574704107424 [label=AccumulateGrad]
	1574704107184 -> 1574704107616
	1574587772720 [label="features.denseblock2.denselayer10.norm2.bias
 (192)" fillcolor=lightblue]
	1574587772720 -> 1574704107184
	1574704107184 [label=AccumulateGrad]
	1574704107232 -> 1574704490736
	1574587773200 [label="features.denseblock2.denselayer10.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587773200 -> 1574704107232
	1574704107232 [label=AccumulateGrad]
	1574704490784 -> 1574704490160
	1574704490784 [label=ConvolutionBackward0]
	1574704107664 -> 1574704490784
	1574704107664 [label=ReluBackward0]
	1574704108192 -> 1574704107664
	1574704108192 [label=NativeBatchNormBackward0]
	1574704108288 -> 1574704108192
	1574704108288 [label=ConvolutionBackward0]
	1574704108480 -> 1574704108288
	1574704108480 [label=ReluBackward0]
	1574704108624 -> 1574704108480
	1574704108624 [label=NativeBatchNormBackward0]
	1574704108720 -> 1574704108624
	1574704108720 [label=CatBackward0]
	1574704490352 -> 1574704108720
	1574704490304 -> 1574704108720
	1574704490256 -> 1574704108720
	1574704490400 -> 1574704108720
	1574704490448 -> 1574704108720
	1574704490496 -> 1574704108720
	1574704490544 -> 1574704108720
	1574704490592 -> 1574704108720
	1574704490640 -> 1574704108720
	1574704490688 -> 1574704108720
	1574704490736 -> 1574704108720
	1574704108672 -> 1574704108624
	1574587773280 [label="features.denseblock2.denselayer11.norm1.weight
 (672)" fillcolor=lightblue]
	1574587773280 -> 1574704108672
	1574704108672 [label=AccumulateGrad]
	1574704108528 -> 1574704108624
	1574587773360 [label="features.denseblock2.denselayer11.norm1.bias
 (672)" fillcolor=lightblue]
	1574587773360 -> 1574704108528
	1574704108528 [label=AccumulateGrad]
	1574704108432 -> 1574704108288
	1574587773840 [label="features.denseblock2.denselayer11.conv1.weight
 (192, 672, 1, 1)" fillcolor=lightblue]
	1574587773840 -> 1574704108432
	1574704108432 [label=AccumulateGrad]
	1574704108000 -> 1574704108192
	1574587773920 [label="features.denseblock2.denselayer11.norm2.weight
 (192)" fillcolor=lightblue]
	1574587773920 -> 1574704108000
	1574704108000 [label=AccumulateGrad]
	1574704107760 -> 1574704108192
	1574587774000 [label="features.denseblock2.denselayer11.norm2.bias
 (192)" fillcolor=lightblue]
	1574587774000 -> 1574704107760
	1574704107760 [label=AccumulateGrad]
	1574704107808 -> 1574704490784
	1574587774480 [label="features.denseblock2.denselayer11.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587774480 -> 1574704107808
	1574704107808 [label=AccumulateGrad]
	1574704490832 -> 1574704490160
	1574704490832 [label=ConvolutionBackward0]
	1574704108240 -> 1574704490832
	1574704108240 [label=ReluBackward0]
	1574704108768 -> 1574704108240
	1574704108768 [label=NativeBatchNormBackward0]
	1574704108864 -> 1574704108768
	1574704108864 [label=ConvolutionBackward0]
	1574704109056 -> 1574704108864
	1574704109056 [label=ReluBackward0]
	1574704109200 -> 1574704109056
	1574704109200 [label=NativeBatchNormBackward0]
	1574704109296 -> 1574704109200
	1574704109296 [label=CatBackward0]
	1574704490352 -> 1574704109296
	1574704490304 -> 1574704109296
	1574704490256 -> 1574704109296
	1574704490400 -> 1574704109296
	1574704490448 -> 1574704109296
	1574704490496 -> 1574704109296
	1574704490544 -> 1574704109296
	1574704490592 -> 1574704109296
	1574704490640 -> 1574704109296
	1574704490688 -> 1574704109296
	1574704490736 -> 1574704109296
	1574704490784 -> 1574704109296
	1574704109248 -> 1574704109200
	1574587774560 [label="features.denseblock2.denselayer12.norm1.weight
 (720)" fillcolor=lightblue]
	1574587774560 -> 1574704109248
	1574704109248 [label=AccumulateGrad]
	1574704109104 -> 1574704109200
	1574587774640 [label="features.denseblock2.denselayer12.norm1.bias
 (720)" fillcolor=lightblue]
	1574587774640 -> 1574704109104
	1574704109104 [label=AccumulateGrad]
	1574704109008 -> 1574704108864
	1574587775120 [label="features.denseblock2.denselayer12.conv1.weight
 (192, 720, 1, 1)" fillcolor=lightblue]
	1574587775120 -> 1574704109008
	1574704109008 [label=AccumulateGrad]
	1574704108576 -> 1574704108768
	1574587775200 [label="features.denseblock2.denselayer12.norm2.weight
 (192)" fillcolor=lightblue]
	1574587775200 -> 1574704108576
	1574704108576 [label=AccumulateGrad]
	1574704108336 -> 1574704108768
	1574587775280 [label="features.denseblock2.denselayer12.norm2.bias
 (192)" fillcolor=lightblue]
	1574587775280 -> 1574704108336
	1574704108336 [label=AccumulateGrad]
	1574704108384 -> 1574704490832
	1574587775760 [label="features.denseblock2.denselayer12.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587775760 -> 1574704108384
	1574704108384 [label=AccumulateGrad]
	1574704490112 -> 1574704490064
	1574587775840 [label="features.transition2.norm.weight
 (768)" fillcolor=lightblue]
	1574587775840 -> 1574704490112
	1574704490112 [label=AccumulateGrad]
	1574704489968 -> 1574704490064
	1574587775920 [label="features.transition2.norm.bias
 (768)" fillcolor=lightblue]
	1574587775920 -> 1574704489968
	1574704489968 [label=AccumulateGrad]
	1574704489872 -> 1574704489824
	1574587776400 [label="features.transition2.conv.weight
 (384, 768, 1, 1)" fillcolor=lightblue]
	1574587776400 -> 1574704489872
	1574704489872 [label=AccumulateGrad]
	1574704487952 -> 1574704487808
	1574704487952 [label=ConvolutionBackward0]
	1574704490880 -> 1574704487952
	1574704490880 [label=ReluBackward0]
	1574704490016 -> 1574704490880
	1574704490016 [label=NativeBatchNormBackward0]
	1574704108816 -> 1574704490016
	1574704108816 [label=ConvolutionBackward0]
	1574704109152 -> 1574704108816
	1574704109152 [label=ReluBackward0]
	1574704109536 -> 1574704109152
	1574704109536 [label=NativeBatchNormBackward0]
	1574704109632 -> 1574704109536
	1574704109632 [label=CatBackward0]
	1574704488000 -> 1574704109632
	1574704109584 -> 1574704109536
	1574587776480 [label="features.denseblock3.denselayer1.norm1.weight
 (384)" fillcolor=lightblue]
	1574587776480 -> 1574704109584
	1574704109584 [label=AccumulateGrad]
	1574704109440 -> 1574704109536
	1574587776560 [label="features.denseblock3.denselayer1.norm1.bias
 (384)" fillcolor=lightblue]
	1574587776560 -> 1574704109440
	1574704109440 [label=AccumulateGrad]
	1574704109344 -> 1574704108816
	1574587973712 [label="features.denseblock3.denselayer1.conv1.weight
 (192, 384, 1, 1)" fillcolor=lightblue]
	1574587973712 -> 1574704109344
	1574704109344 [label=AccumulateGrad]
	1574704108960 -> 1574704490016
	1574587973792 [label="features.denseblock3.denselayer1.norm2.weight
 (192)" fillcolor=lightblue]
	1574587973792 -> 1574704108960
	1574704108960 [label=AccumulateGrad]
	1574704103776 -> 1574704490016
	1574587973872 [label="features.denseblock3.denselayer1.norm2.bias
 (192)" fillcolor=lightblue]
	1574587973872 -> 1574704103776
	1574704103776 [label=AccumulateGrad]
	1574704489728 -> 1574704487952
	1574587974352 [label="features.denseblock3.denselayer1.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587974352 -> 1574704489728
	1574704489728 [label=AccumulateGrad]
	1574704487904 -> 1574704487808
	1574704487904 [label=ConvolutionBackward0]
	1574704490208 -> 1574704487904
	1574704490208 [label=ReluBackward0]
	1574704109680 -> 1574704490208
	1574704109680 [label=NativeBatchNormBackward0]
	1574704109776 -> 1574704109680
	1574704109776 [label=ConvolutionBackward0]
	1574704109968 -> 1574704109776
	1574704109968 [label=ReluBackward0]
	1574704110112 -> 1574704109968
	1574704110112 [label=NativeBatchNormBackward0]
	1574704110208 -> 1574704110112
	1574704110208 [label=CatBackward0]
	1574704488000 -> 1574704110208
	1574704487952 -> 1574704110208
	1574704110160 -> 1574704110112
	1574587974432 [label="features.denseblock3.denselayer2.norm1.weight
 (432)" fillcolor=lightblue]
	1574587974432 -> 1574704110160
	1574704110160 [label=AccumulateGrad]
	1574704110016 -> 1574704110112
	1574587974512 [label="features.denseblock3.denselayer2.norm1.bias
 (432)" fillcolor=lightblue]
	1574587974512 -> 1574704110016
	1574704110016 [label=AccumulateGrad]
	1574704109920 -> 1574704109776
	1574587974992 [label="features.denseblock3.denselayer2.conv1.weight
 (192, 432, 1, 1)" fillcolor=lightblue]
	1574587974992 -> 1574704109920
	1574704109920 [label=AccumulateGrad]
	1574704109392 -> 1574704109680
	1574587975072 [label="features.denseblock3.denselayer2.norm2.weight
 (192)" fillcolor=lightblue]
	1574587975072 -> 1574704109392
	1574704109392 [label=AccumulateGrad]
	1574704108912 -> 1574704109680
	1574587975152 [label="features.denseblock3.denselayer2.norm2.bias
 (192)" fillcolor=lightblue]
	1574587975152 -> 1574704108912
	1574704108912 [label=AccumulateGrad]
	1574704489776 -> 1574704487904
	1574587975632 [label="features.denseblock3.denselayer2.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587975632 -> 1574704489776
	1574704489776 [label=AccumulateGrad]
	1574704488048 -> 1574704487808
	1574704488048 [label=ConvolutionBackward0]
	1574704109728 -> 1574704488048
	1574704109728 [label=ReluBackward0]
	1574704110256 -> 1574704109728
	1574704110256 [label=NativeBatchNormBackward0]
	1574704110352 -> 1574704110256
	1574704110352 [label=ConvolutionBackward0]
	1574704110544 -> 1574704110352
	1574704110544 [label=ReluBackward0]
	1574704110688 -> 1574704110544
	1574704110688 [label=NativeBatchNormBackward0]
	1574704110784 -> 1574704110688
	1574704110784 [label=CatBackward0]
	1574704488000 -> 1574704110784
	1574704487952 -> 1574704110784
	1574704487904 -> 1574704110784
	1574704110736 -> 1574704110688
	1574587975712 [label="features.denseblock3.denselayer3.norm1.weight
 (480)" fillcolor=lightblue]
	1574587975712 -> 1574704110736
	1574704110736 [label=AccumulateGrad]
	1574704110592 -> 1574704110688
	1574587975792 [label="features.denseblock3.denselayer3.norm1.bias
 (480)" fillcolor=lightblue]
	1574587975792 -> 1574704110592
	1574704110592 [label=AccumulateGrad]
	1574704110496 -> 1574704110352
	1574587976272 [label="features.denseblock3.denselayer3.conv1.weight
 (192, 480, 1, 1)" fillcolor=lightblue]
	1574587976272 -> 1574704110496
	1574704110496 [label=AccumulateGrad]
	1574704110064 -> 1574704110256
	1574587976352 [label="features.denseblock3.denselayer3.norm2.weight
 (192)" fillcolor=lightblue]
	1574587976352 -> 1574704110064
	1574704110064 [label=AccumulateGrad]
	1574704109824 -> 1574704110256
	1574587976432 [label="features.denseblock3.denselayer3.norm2.bias
 (192)" fillcolor=lightblue]
	1574587976432 -> 1574704109824
	1574704109824 [label=AccumulateGrad]
	1574704109872 -> 1574704488048
	1574587976912 [label="features.denseblock3.denselayer3.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587976912 -> 1574704109872
	1574704109872 [label=AccumulateGrad]
	1574704488096 -> 1574704487808
	1574704488096 [label=ConvolutionBackward0]
	1574704110304 -> 1574704488096
	1574704110304 [label=ReluBackward0]
	1574704110832 -> 1574704110304
	1574704110832 [label=NativeBatchNormBackward0]
	1574704110928 -> 1574704110832
	1574704110928 [label=ConvolutionBackward0]
	1574704111120 -> 1574704110928
	1574704111120 [label=ReluBackward0]
	1574704111264 -> 1574704111120
	1574704111264 [label=NativeBatchNormBackward0]
	1574704111360 -> 1574704111264
	1574704111360 [label=CatBackward0]
	1574704488000 -> 1574704111360
	1574704487952 -> 1574704111360
	1574704487904 -> 1574704111360
	1574704488048 -> 1574704111360
	1574704111312 -> 1574704111264
	1574587976992 [label="features.denseblock3.denselayer4.norm1.weight
 (528)" fillcolor=lightblue]
	1574587976992 -> 1574704111312
	1574704111312 [label=AccumulateGrad]
	1574704111168 -> 1574704111264
	1574587977072 [label="features.denseblock3.denselayer4.norm1.bias
 (528)" fillcolor=lightblue]
	1574587977072 -> 1574704111168
	1574704111168 [label=AccumulateGrad]
	1574704111072 -> 1574704110928
	1574587977552 [label="features.denseblock3.denselayer4.conv1.weight
 (192, 528, 1, 1)" fillcolor=lightblue]
	1574587977552 -> 1574704111072
	1574704111072 [label=AccumulateGrad]
	1574704110640 -> 1574704110832
	1574587977632 [label="features.denseblock3.denselayer4.norm2.weight
 (192)" fillcolor=lightblue]
	1574587977632 -> 1574704110640
	1574704110640 [label=AccumulateGrad]
	1574704110400 -> 1574704110832
	1574587977712 [label="features.denseblock3.denselayer4.norm2.bias
 (192)" fillcolor=lightblue]
	1574587977712 -> 1574704110400
	1574704110400 [label=AccumulateGrad]
	1574704110448 -> 1574704488096
	1574587978192 [label="features.denseblock3.denselayer4.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587978192 -> 1574704110448
	1574704110448 [label=AccumulateGrad]
	1574704488144 -> 1574704487808
	1574704488144 [label=ConvolutionBackward0]
	1574704110880 -> 1574704488144
	1574704110880 [label=ReluBackward0]
	1574704111408 -> 1574704110880
	1574704111408 [label=NativeBatchNormBackward0]
	1574704111504 -> 1574704111408
	1574704111504 [label=ConvolutionBackward0]
	1574704111696 -> 1574704111504
	1574704111696 [label=ReluBackward0]
	1574704111840 -> 1574704111696
	1574704111840 [label=NativeBatchNormBackward0]
	1574704111936 -> 1574704111840
	1574704111936 [label=CatBackward0]
	1574704488000 -> 1574704111936
	1574704487952 -> 1574704111936
	1574704487904 -> 1574704111936
	1574704488048 -> 1574704111936
	1574704488096 -> 1574704111936
	1574704111888 -> 1574704111840
	1574587978272 [label="features.denseblock3.denselayer5.norm1.weight
 (576)" fillcolor=lightblue]
	1574587978272 -> 1574704111888
	1574704111888 [label=AccumulateGrad]
	1574704111744 -> 1574704111840
	1574587978352 [label="features.denseblock3.denselayer5.norm1.bias
 (576)" fillcolor=lightblue]
	1574587978352 -> 1574704111744
	1574704111744 [label=AccumulateGrad]
	1574704111648 -> 1574704111504
	1574587978832 [label="features.denseblock3.denselayer5.conv1.weight
 (192, 576, 1, 1)" fillcolor=lightblue]
	1574587978832 -> 1574704111648
	1574704111648 [label=AccumulateGrad]
	1574704111216 -> 1574704111408
	1574587978912 [label="features.denseblock3.denselayer5.norm2.weight
 (192)" fillcolor=lightblue]
	1574587978912 -> 1574704111216
	1574704111216 [label=AccumulateGrad]
	1574704110976 -> 1574704111408
	1574587978992 [label="features.denseblock3.denselayer5.norm2.bias
 (192)" fillcolor=lightblue]
	1574587978992 -> 1574704110976
	1574704110976 [label=AccumulateGrad]
	1574704111024 -> 1574704488144
	1574587979472 [label="features.denseblock3.denselayer5.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587979472 -> 1574704111024
	1574704111024 [label=AccumulateGrad]
	1574704488192 -> 1574704487808
	1574704488192 [label=ConvolutionBackward0]
	1574704111456 -> 1574704488192
	1574704111456 [label=ReluBackward0]
	1574704111984 -> 1574704111456
	1574704111984 [label=NativeBatchNormBackward0]
	1574704112080 -> 1574704111984
	1574704112080 [label=ConvolutionBackward0]
	1574704112272 -> 1574704112080
	1574704112272 [label=ReluBackward0]
	1574704112416 -> 1574704112272
	1574704112416 [label=NativeBatchNormBackward0]
	1574704112512 -> 1574704112416
	1574704112512 [label=CatBackward0]
	1574704488000 -> 1574704112512
	1574704487952 -> 1574704112512
	1574704487904 -> 1574704112512
	1574704488048 -> 1574704112512
	1574704488096 -> 1574704112512
	1574704488144 -> 1574704112512
	1574704112464 -> 1574704112416
	1574587979552 [label="features.denseblock3.denselayer6.norm1.weight
 (624)" fillcolor=lightblue]
	1574587979552 -> 1574704112464
	1574704112464 [label=AccumulateGrad]
	1574704112320 -> 1574704112416
	1574587979632 [label="features.denseblock3.denselayer6.norm1.bias
 (624)" fillcolor=lightblue]
	1574587979632 -> 1574704112320
	1574704112320 [label=AccumulateGrad]
	1574704112224 -> 1574704112080
	1574587980112 [label="features.denseblock3.denselayer6.conv1.weight
 (192, 624, 1, 1)" fillcolor=lightblue]
	1574587980112 -> 1574704112224
	1574704112224 [label=AccumulateGrad]
	1574704111792 -> 1574704111984
	1574587980192 [label="features.denseblock3.denselayer6.norm2.weight
 (192)" fillcolor=lightblue]
	1574587980192 -> 1574704111792
	1574704111792 [label=AccumulateGrad]
	1574704111552 -> 1574704111984
	1574587980272 [label="features.denseblock3.denselayer6.norm2.bias
 (192)" fillcolor=lightblue]
	1574587980272 -> 1574704111552
	1574704111552 [label=AccumulateGrad]
	1574704111600 -> 1574704488192
	1574587980752 [label="features.denseblock3.denselayer6.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587980752 -> 1574704111600
	1574704111600 [label=AccumulateGrad]
	1574704488240 -> 1574704487808
	1574704488240 [label=ConvolutionBackward0]
	1574704112032 -> 1574704488240
	1574704112032 [label=ReluBackward0]
	1574704112560 -> 1574704112032
	1574704112560 [label=NativeBatchNormBackward0]
	1574704112656 -> 1574704112560
	1574704112656 [label=ConvolutionBackward0]
	1574704112848 -> 1574704112656
	1574704112848 [label=ReluBackward0]
	1574704112992 -> 1574704112848
	1574704112992 [label=NativeBatchNormBackward0]
	1574704113088 -> 1574704112992
	1574704113088 [label=CatBackward0]
	1574704488000 -> 1574704113088
	1574704487952 -> 1574704113088
	1574704487904 -> 1574704113088
	1574704488048 -> 1574704113088
	1574704488096 -> 1574704113088
	1574704488144 -> 1574704113088
	1574704488192 -> 1574704113088
	1574704113040 -> 1574704112992
	1574587980832 [label="features.denseblock3.denselayer7.norm1.weight
 (672)" fillcolor=lightblue]
	1574587980832 -> 1574704113040
	1574704113040 [label=AccumulateGrad]
	1574704112896 -> 1574704112992
	1574587980912 [label="features.denseblock3.denselayer7.norm1.bias
 (672)" fillcolor=lightblue]
	1574587980912 -> 1574704112896
	1574704112896 [label=AccumulateGrad]
	1574704112800 -> 1574704112656
	1574587981392 [label="features.denseblock3.denselayer7.conv1.weight
 (192, 672, 1, 1)" fillcolor=lightblue]
	1574587981392 -> 1574704112800
	1574704112800 [label=AccumulateGrad]
	1574704112368 -> 1574704112560
	1574587981472 [label="features.denseblock3.denselayer7.norm2.weight
 (192)" fillcolor=lightblue]
	1574587981472 -> 1574704112368
	1574704112368 [label=AccumulateGrad]
	1574704112128 -> 1574704112560
	1574587981552 [label="features.denseblock3.denselayer7.norm2.bias
 (192)" fillcolor=lightblue]
	1574587981552 -> 1574704112128
	1574704112128 [label=AccumulateGrad]
	1574704112176 -> 1574704488240
	1574587981952 [label="features.denseblock3.denselayer7.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587981952 -> 1574704112176
	1574704112176 [label=AccumulateGrad]
	1574704488288 -> 1574704487808
	1574704488288 [label=ConvolutionBackward0]
	1574704112608 -> 1574704488288
	1574704112608 [label=ReluBackward0]
	1574704113136 -> 1574704112608
	1574704113136 [label=NativeBatchNormBackward0]
	1574704113232 -> 1574704113136
	1574704113232 [label=ConvolutionBackward0]
	1574704113424 -> 1574704113232
	1574704113424 [label=ReluBackward0]
	1574704113568 -> 1574704113424
	1574704113568 [label=NativeBatchNormBackward0]
	1574704113664 -> 1574704113568
	1574704113664 [label=CatBackward0]
	1574704488000 -> 1574704113664
	1574704487952 -> 1574704113664
	1574704487904 -> 1574704113664
	1574704488048 -> 1574704113664
	1574704488096 -> 1574704113664
	1574704488144 -> 1574704113664
	1574704488192 -> 1574704113664
	1574704488240 -> 1574704113664
	1574704113616 -> 1574704113568
	1574587982032 [label="features.denseblock3.denselayer8.norm1.weight
 (720)" fillcolor=lightblue]
	1574587982032 -> 1574704113616
	1574704113616 [label=AccumulateGrad]
	1574704113472 -> 1574704113568
	1574587982112 [label="features.denseblock3.denselayer8.norm1.bias
 (720)" fillcolor=lightblue]
	1574587982112 -> 1574704113472
	1574704113472 [label=AccumulateGrad]
	1574704113376 -> 1574704113232
	1574587982592 [label="features.denseblock3.denselayer8.conv1.weight
 (192, 720, 1, 1)" fillcolor=lightblue]
	1574587982592 -> 1574704113376
	1574704113376 [label=AccumulateGrad]
	1574704112944 -> 1574704113136
	1574587982672 [label="features.denseblock3.denselayer8.norm2.weight
 (192)" fillcolor=lightblue]
	1574587982672 -> 1574704112944
	1574704112944 [label=AccumulateGrad]
	1574704112704 -> 1574704113136
	1574587982752 [label="features.denseblock3.denselayer8.norm2.bias
 (192)" fillcolor=lightblue]
	1574587982752 -> 1574704112704
	1574704112704 [label=AccumulateGrad]
	1574704112752 -> 1574704488288
	1574587983232 [label="features.denseblock3.denselayer8.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587983232 -> 1574704112752
	1574704112752 [label=AccumulateGrad]
	1574704488336 -> 1574704487808
	1574704488336 [label=ConvolutionBackward0]
	1574704113184 -> 1574704488336
	1574704113184 [label=ReluBackward0]
	1574704113712 -> 1574704113184
	1574704113712 [label=NativeBatchNormBackward0]
	1574704113808 -> 1574704113712
	1574704113808 [label=ConvolutionBackward0]
	1574704114000 -> 1574704113808
	1574704114000 [label=ReluBackward0]
	1574704114144 -> 1574704114000
	1574704114144 [label=NativeBatchNormBackward0]
	1574704114240 -> 1574704114144
	1574704114240 [label=CatBackward0]
	1574704488000 -> 1574704114240
	1574704487952 -> 1574704114240
	1574704487904 -> 1574704114240
	1574704488048 -> 1574704114240
	1574704488096 -> 1574704114240
	1574704488144 -> 1574704114240
	1574704488192 -> 1574704114240
	1574704488240 -> 1574704114240
	1574704488288 -> 1574704114240
	1574704114192 -> 1574704114144
	1574587983312 [label="features.denseblock3.denselayer9.norm1.weight
 (768)" fillcolor=lightblue]
	1574587983312 -> 1574704114192
	1574704114192 [label=AccumulateGrad]
	1574704114048 -> 1574704114144
	1574587983392 [label="features.denseblock3.denselayer9.norm1.bias
 (768)" fillcolor=lightblue]
	1574587983392 -> 1574704114048
	1574704114048 [label=AccumulateGrad]
	1574704113952 -> 1574704113808
	1574587983872 [label="features.denseblock3.denselayer9.conv1.weight
 (192, 768, 1, 1)" fillcolor=lightblue]
	1574587983872 -> 1574704113952
	1574704113952 [label=AccumulateGrad]
	1574704113520 -> 1574704113712
	1574587983952 [label="features.denseblock3.denselayer9.norm2.weight
 (192)" fillcolor=lightblue]
	1574587983952 -> 1574704113520
	1574704113520 [label=AccumulateGrad]
	1574704113280 -> 1574704113712
	1574587984032 [label="features.denseblock3.denselayer9.norm2.bias
 (192)" fillcolor=lightblue]
	1574587984032 -> 1574704113280
	1574704113280 [label=AccumulateGrad]
	1574704113328 -> 1574704488336
	1574587984512 [label="features.denseblock3.denselayer9.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587984512 -> 1574704113328
	1574704113328 [label=AccumulateGrad]
	1574704488384 -> 1574704487808
	1574704488384 [label=ConvolutionBackward0]
	1574704113760 -> 1574704488384
	1574704113760 [label=ReluBackward0]
	1574704114288 -> 1574704113760
	1574704114288 [label=NativeBatchNormBackward0]
	1574704114384 -> 1574704114288
	1574704114384 [label=ConvolutionBackward0]
	1574704114576 -> 1574704114384
	1574704114576 [label=ReluBackward0]
	1574704114720 -> 1574704114576
	1574704114720 [label=NativeBatchNormBackward0]
	1574704114816 -> 1574704114720
	1574704114816 [label=CatBackward0]
	1574704488000 -> 1574704114816
	1574704487952 -> 1574704114816
	1574704487904 -> 1574704114816
	1574704488048 -> 1574704114816
	1574704488096 -> 1574704114816
	1574704488144 -> 1574704114816
	1574704488192 -> 1574704114816
	1574704488240 -> 1574704114816
	1574704488288 -> 1574704114816
	1574704488336 -> 1574704114816
	1574704114768 -> 1574704114720
	1574587984592 [label="features.denseblock3.denselayer10.norm1.weight
 (816)" fillcolor=lightblue]
	1574587984592 -> 1574704114768
	1574704114768 [label=AccumulateGrad]
	1574704114624 -> 1574704114720
	1574587984672 [label="features.denseblock3.denselayer10.norm1.bias
 (816)" fillcolor=lightblue]
	1574587984672 -> 1574704114624
	1574704114624 [label=AccumulateGrad]
	1574704114528 -> 1574704114384
	1574587985152 [label="features.denseblock3.denselayer10.conv1.weight
 (192, 816, 1, 1)" fillcolor=lightblue]
	1574587985152 -> 1574704114528
	1574704114528 [label=AccumulateGrad]
	1574704114096 -> 1574704114288
	1574587985232 [label="features.denseblock3.denselayer10.norm2.weight
 (192)" fillcolor=lightblue]
	1574587985232 -> 1574704114096
	1574704114096 [label=AccumulateGrad]
	1574704113856 -> 1574704114288
	1574587985312 [label="features.denseblock3.denselayer10.norm2.bias
 (192)" fillcolor=lightblue]
	1574587985312 -> 1574704113856
	1574704113856 [label=AccumulateGrad]
	1574704113904 -> 1574704488384
	1574587985792 [label="features.denseblock3.denselayer10.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587985792 -> 1574704113904
	1574704113904 [label=AccumulateGrad]
	1574704488432 -> 1574704487808
	1574704488432 [label=ConvolutionBackward0]
	1574704114336 -> 1574704488432
	1574704114336 [label=ReluBackward0]
	1574704114864 -> 1574704114336
	1574704114864 [label=NativeBatchNormBackward0]
	1574704114960 -> 1574704114864
	1574704114960 [label=ConvolutionBackward0]
	1574704115152 -> 1574704114960
	1574704115152 [label=ReluBackward0]
	1574704115296 -> 1574704115152
	1574704115296 [label=NativeBatchNormBackward0]
	1574704115392 -> 1574704115296
	1574704115392 [label=CatBackward0]
	1574704488000 -> 1574704115392
	1574704487952 -> 1574704115392
	1574704487904 -> 1574704115392
	1574704488048 -> 1574704115392
	1574704488096 -> 1574704115392
	1574704488144 -> 1574704115392
	1574704488192 -> 1574704115392
	1574704488240 -> 1574704115392
	1574704488288 -> 1574704115392
	1574704488336 -> 1574704115392
	1574704488384 -> 1574704115392
	1574704115344 -> 1574704115296
	1574587985872 [label="features.denseblock3.denselayer11.norm1.weight
 (864)" fillcolor=lightblue]
	1574587985872 -> 1574704115344
	1574704115344 [label=AccumulateGrad]
	1574704115200 -> 1574704115296
	1574587985952 [label="features.denseblock3.denselayer11.norm1.bias
 (864)" fillcolor=lightblue]
	1574587985952 -> 1574704115200
	1574704115200 [label=AccumulateGrad]
	1574704115104 -> 1574704114960
	1574587986432 [label="features.denseblock3.denselayer11.conv1.weight
 (192, 864, 1, 1)" fillcolor=lightblue]
	1574587986432 -> 1574704115104
	1574704115104 [label=AccumulateGrad]
	1574704114672 -> 1574704114864
	1574587986512 [label="features.denseblock3.denselayer11.norm2.weight
 (192)" fillcolor=lightblue]
	1574587986512 -> 1574704114672
	1574704114672 [label=AccumulateGrad]
	1574704114432 -> 1574704114864
	1574587986592 [label="features.denseblock3.denselayer11.norm2.bias
 (192)" fillcolor=lightblue]
	1574587986592 -> 1574704114432
	1574704114432 [label=AccumulateGrad]
	1574704114480 -> 1574704488432
	1574587987072 [label="features.denseblock3.denselayer11.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587987072 -> 1574704114480
	1574704114480 [label=AccumulateGrad]
	1574704488480 -> 1574704487808
	1574704488480 [label=ConvolutionBackward0]
	1574704114912 -> 1574704488480
	1574704114912 [label=ReluBackward0]
	1574704115440 -> 1574704114912
	1574704115440 [label=NativeBatchNormBackward0]
	1574704115536 -> 1574704115440
	1574704115536 [label=ConvolutionBackward0]
	1574704115728 -> 1574704115536
	1574704115728 [label=ReluBackward0]
	1574704115872 -> 1574704115728
	1574704115872 [label=NativeBatchNormBackward0]
	1574704115968 -> 1574704115872
	1574704115968 [label=CatBackward0]
	1574704488000 -> 1574704115968
	1574704487952 -> 1574704115968
	1574704487904 -> 1574704115968
	1574704488048 -> 1574704115968
	1574704488096 -> 1574704115968
	1574704488144 -> 1574704115968
	1574704488192 -> 1574704115968
	1574704488240 -> 1574704115968
	1574704488288 -> 1574704115968
	1574704488336 -> 1574704115968
	1574704488384 -> 1574704115968
	1574704488432 -> 1574704115968
	1574704115920 -> 1574704115872
	1574587987152 [label="features.denseblock3.denselayer12.norm1.weight
 (912)" fillcolor=lightblue]
	1574587987152 -> 1574704115920
	1574704115920 [label=AccumulateGrad]
	1574704115776 -> 1574704115872
	1574587987232 [label="features.denseblock3.denselayer12.norm1.bias
 (912)" fillcolor=lightblue]
	1574587987232 -> 1574704115776
	1574704115776 [label=AccumulateGrad]
	1574704115680 -> 1574704115536
	1574587987712 [label="features.denseblock3.denselayer12.conv1.weight
 (192, 912, 1, 1)" fillcolor=lightblue]
	1574587987712 -> 1574704115680
	1574704115680 [label=AccumulateGrad]
	1574704115248 -> 1574704115440
	1574587987792 [label="features.denseblock3.denselayer12.norm2.weight
 (192)" fillcolor=lightblue]
	1574587987792 -> 1574704115248
	1574704115248 [label=AccumulateGrad]
	1574704115008 -> 1574704115440
	1574587987872 [label="features.denseblock3.denselayer12.norm2.bias
 (192)" fillcolor=lightblue]
	1574587987872 -> 1574704115008
	1574704115008 [label=AccumulateGrad]
	1574704115056 -> 1574704488480
	1574587988352 [label="features.denseblock3.denselayer12.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587988352 -> 1574704115056
	1574704115056 [label=AccumulateGrad]
	1574704488528 -> 1574704487808
	1574704488528 [label=ConvolutionBackward0]
	1574704115488 -> 1574704488528
	1574704115488 [label=ReluBackward0]
	1574704116016 -> 1574704115488
	1574704116016 [label=NativeBatchNormBackward0]
	1574704116112 -> 1574704116016
	1574704116112 [label=ConvolutionBackward0]
	1574704116304 -> 1574704116112
	1574704116304 [label=ReluBackward0]
	1574704116448 -> 1574704116304
	1574704116448 [label=NativeBatchNormBackward0]
	1574704116544 -> 1574704116448
	1574704116544 [label=CatBackward0]
	1574704488000 -> 1574704116544
	1574704487952 -> 1574704116544
	1574704487904 -> 1574704116544
	1574704488048 -> 1574704116544
	1574704488096 -> 1574704116544
	1574704488144 -> 1574704116544
	1574704488192 -> 1574704116544
	1574704488240 -> 1574704116544
	1574704488288 -> 1574704116544
	1574704488336 -> 1574704116544
	1574704488384 -> 1574704116544
	1574704488432 -> 1574704116544
	1574704488480 -> 1574704116544
	1574704116496 -> 1574704116448
	1574587988432 [label="features.denseblock3.denselayer13.norm1.weight
 (960)" fillcolor=lightblue]
	1574587988432 -> 1574704116496
	1574704116496 [label=AccumulateGrad]
	1574704116352 -> 1574704116448
	1574587988512 [label="features.denseblock3.denselayer13.norm1.bias
 (960)" fillcolor=lightblue]
	1574587988512 -> 1574704116352
	1574704116352 [label=AccumulateGrad]
	1574704116256 -> 1574704116112
	1574587988992 [label="features.denseblock3.denselayer13.conv1.weight
 (192, 960, 1, 1)" fillcolor=lightblue]
	1574587988992 -> 1574704116256
	1574704116256 [label=AccumulateGrad]
	1574704115824 -> 1574704116016
	1574587989072 [label="features.denseblock3.denselayer13.norm2.weight
 (192)" fillcolor=lightblue]
	1574587989072 -> 1574704115824
	1574704115824 [label=AccumulateGrad]
	1574704115584 -> 1574704116016
	1574587989152 [label="features.denseblock3.denselayer13.norm2.bias
 (192)" fillcolor=lightblue]
	1574587989152 -> 1574704115584
	1574704115584 [label=AccumulateGrad]
	1574704115632 -> 1574704488528
	1574587989632 [label="features.denseblock3.denselayer13.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574587989632 -> 1574704115632
	1574704115632 [label=AccumulateGrad]
	1574704488576 -> 1574704487808
	1574704488576 [label=ConvolutionBackward0]
	1574704116064 -> 1574704488576
	1574704116064 [label=ReluBackward0]
	1574704116592 -> 1574704116064
	1574704116592 [label=NativeBatchNormBackward0]
	1574704116688 -> 1574704116592
	1574704116688 [label=ConvolutionBackward0]
	1574704116880 -> 1574704116688
	1574704116880 [label=ReluBackward0]
	1574704117024 -> 1574704116880
	1574704117024 [label=NativeBatchNormBackward0]
	1574704117120 -> 1574704117024
	1574704117120 [label=CatBackward0]
	1574704488000 -> 1574704117120
	1574704487952 -> 1574704117120
	1574704487904 -> 1574704117120
	1574704488048 -> 1574704117120
	1574704488096 -> 1574704117120
	1574704488144 -> 1574704117120
	1574704488192 -> 1574704117120
	1574704488240 -> 1574704117120
	1574704488288 -> 1574704117120
	1574704488336 -> 1574704117120
	1574704488384 -> 1574704117120
	1574704488432 -> 1574704117120
	1574704488480 -> 1574704117120
	1574704488528 -> 1574704117120
	1574704117072 -> 1574704117024
	1574587989712 [label="features.denseblock3.denselayer14.norm1.weight
 (1008)" fillcolor=lightblue]
	1574587989712 -> 1574704117072
	1574704117072 [label=AccumulateGrad]
	1574704116928 -> 1574704117024
	1574587989792 [label="features.denseblock3.denselayer14.norm1.bias
 (1008)" fillcolor=lightblue]
	1574587989792 -> 1574704116928
	1574704116928 [label=AccumulateGrad]
	1574704116832 -> 1574704116688
	1574606061888 [label="features.denseblock3.denselayer14.conv1.weight
 (192, 1008, 1, 1)" fillcolor=lightblue]
	1574606061888 -> 1574704116832
	1574704116832 [label=AccumulateGrad]
	1574704116400 -> 1574704116592
	1574606061968 [label="features.denseblock3.denselayer14.norm2.weight
 (192)" fillcolor=lightblue]
	1574606061968 -> 1574704116400
	1574704116400 [label=AccumulateGrad]
	1574704116160 -> 1574704116592
	1574606062048 [label="features.denseblock3.denselayer14.norm2.bias
 (192)" fillcolor=lightblue]
	1574606062048 -> 1574704116160
	1574704116160 [label=AccumulateGrad]
	1574704116208 -> 1574704488576
	1574606062528 [label="features.denseblock3.denselayer14.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606062528 -> 1574704116208
	1574704116208 [label=AccumulateGrad]
	1574704488624 -> 1574704487808
	1574704488624 [label=ConvolutionBackward0]
	1574704116640 -> 1574704488624
	1574704116640 [label=ReluBackward0]
	1574704117168 -> 1574704116640
	1574704117168 [label=NativeBatchNormBackward0]
	1574704117264 -> 1574704117168
	1574704117264 [label=ConvolutionBackward0]
	1574704117456 -> 1574704117264
	1574704117456 [label=ReluBackward0]
	1574704117600 -> 1574704117456
	1574704117600 [label=NativeBatchNormBackward0]
	1574704117696 -> 1574704117600
	1574704117696 [label=CatBackward0]
	1574704488000 -> 1574704117696
	1574704487952 -> 1574704117696
	1574704487904 -> 1574704117696
	1574704488048 -> 1574704117696
	1574704488096 -> 1574704117696
	1574704488144 -> 1574704117696
	1574704488192 -> 1574704117696
	1574704488240 -> 1574704117696
	1574704488288 -> 1574704117696
	1574704488336 -> 1574704117696
	1574704488384 -> 1574704117696
	1574704488432 -> 1574704117696
	1574704488480 -> 1574704117696
	1574704488528 -> 1574704117696
	1574704488576 -> 1574704117696
	1574704117648 -> 1574704117600
	1574606062608 [label="features.denseblock3.denselayer15.norm1.weight
 (1056)" fillcolor=lightblue]
	1574606062608 -> 1574704117648
	1574704117648 [label=AccumulateGrad]
	1574704117504 -> 1574704117600
	1574606062688 [label="features.denseblock3.denselayer15.norm1.bias
 (1056)" fillcolor=lightblue]
	1574606062688 -> 1574704117504
	1574704117504 [label=AccumulateGrad]
	1574704117408 -> 1574704117264
	1574606063168 [label="features.denseblock3.denselayer15.conv1.weight
 (192, 1056, 1, 1)" fillcolor=lightblue]
	1574606063168 -> 1574704117408
	1574704117408 [label=AccumulateGrad]
	1574704116976 -> 1574704117168
	1574606063248 [label="features.denseblock3.denselayer15.norm2.weight
 (192)" fillcolor=lightblue]
	1574606063248 -> 1574704116976
	1574704116976 [label=AccumulateGrad]
	1574704116736 -> 1574704117168
	1574606063328 [label="features.denseblock3.denselayer15.norm2.bias
 (192)" fillcolor=lightblue]
	1574606063328 -> 1574704116736
	1574704116736 [label=AccumulateGrad]
	1574704116784 -> 1574704488624
	1574606063808 [label="features.denseblock3.denselayer15.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606063808 -> 1574704116784
	1574704116784 [label=AccumulateGrad]
	1574704488672 -> 1574704487808
	1574704488672 [label=ConvolutionBackward0]
	1574704117216 -> 1574704488672
	1574704117216 [label=ReluBackward0]
	1574704117744 -> 1574704117216
	1574704117744 [label=NativeBatchNormBackward0]
	1574704117840 -> 1574704117744
	1574704117840 [label=ConvolutionBackward0]
	1574704118032 -> 1574704117840
	1574704118032 [label=ReluBackward0]
	1574704118176 -> 1574704118032
	1574704118176 [label=NativeBatchNormBackward0]
	1574704118272 -> 1574704118176
	1574704118272 [label=CatBackward0]
	1574704488000 -> 1574704118272
	1574704487952 -> 1574704118272
	1574704487904 -> 1574704118272
	1574704488048 -> 1574704118272
	1574704488096 -> 1574704118272
	1574704488144 -> 1574704118272
	1574704488192 -> 1574704118272
	1574704488240 -> 1574704118272
	1574704488288 -> 1574704118272
	1574704488336 -> 1574704118272
	1574704488384 -> 1574704118272
	1574704488432 -> 1574704118272
	1574704488480 -> 1574704118272
	1574704488528 -> 1574704118272
	1574704488576 -> 1574704118272
	1574704488624 -> 1574704118272
	1574704118224 -> 1574704118176
	1574606063888 [label="features.denseblock3.denselayer16.norm1.weight
 (1104)" fillcolor=lightblue]
	1574606063888 -> 1574704118224
	1574704118224 [label=AccumulateGrad]
	1574704118080 -> 1574704118176
	1574606063968 [label="features.denseblock3.denselayer16.norm1.bias
 (1104)" fillcolor=lightblue]
	1574606063968 -> 1574704118080
	1574704118080 [label=AccumulateGrad]
	1574704117984 -> 1574704117840
	1574606064448 [label="features.denseblock3.denselayer16.conv1.weight
 (192, 1104, 1, 1)" fillcolor=lightblue]
	1574606064448 -> 1574704117984
	1574704117984 [label=AccumulateGrad]
	1574704117552 -> 1574704117744
	1574606064528 [label="features.denseblock3.denselayer16.norm2.weight
 (192)" fillcolor=lightblue]
	1574606064528 -> 1574704117552
	1574704117552 [label=AccumulateGrad]
	1574704117312 -> 1574704117744
	1574606064608 [label="features.denseblock3.denselayer16.norm2.bias
 (192)" fillcolor=lightblue]
	1574606064608 -> 1574704117312
	1574704117312 [label=AccumulateGrad]
	1574704117360 -> 1574704488672
	1574606065088 [label="features.denseblock3.denselayer16.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606065088 -> 1574704117360
	1574704117360 [label=AccumulateGrad]
	1574704488720 -> 1574704487808
	1574704488720 [label=ConvolutionBackward0]
	1574704117792 -> 1574704488720
	1574704117792 [label=ReluBackward0]
	1574704118320 -> 1574704117792
	1574704118320 [label=NativeBatchNormBackward0]
	1574704118416 -> 1574704118320
	1574704118416 [label=ConvolutionBackward0]
	1574704118608 -> 1574704118416
	1574704118608 [label=ReluBackward0]
	1574704118752 -> 1574704118608
	1574704118752 [label=NativeBatchNormBackward0]
	1574704118848 -> 1574704118752
	1574704118848 [label=CatBackward0]
	1574704488000 -> 1574704118848
	1574704487952 -> 1574704118848
	1574704487904 -> 1574704118848
	1574704488048 -> 1574704118848
	1574704488096 -> 1574704118848
	1574704488144 -> 1574704118848
	1574704488192 -> 1574704118848
	1574704488240 -> 1574704118848
	1574704488288 -> 1574704118848
	1574704488336 -> 1574704118848
	1574704488384 -> 1574704118848
	1574704488432 -> 1574704118848
	1574704488480 -> 1574704118848
	1574704488528 -> 1574704118848
	1574704488576 -> 1574704118848
	1574704488624 -> 1574704118848
	1574704488672 -> 1574704118848
	1574704118800 -> 1574704118752
	1574606065168 [label="features.denseblock3.denselayer17.norm1.weight
 (1152)" fillcolor=lightblue]
	1574606065168 -> 1574704118800
	1574704118800 [label=AccumulateGrad]
	1574704118656 -> 1574704118752
	1574606065248 [label="features.denseblock3.denselayer17.norm1.bias
 (1152)" fillcolor=lightblue]
	1574606065248 -> 1574704118656
	1574704118656 [label=AccumulateGrad]
	1574704118560 -> 1574704118416
	1574606065728 [label="features.denseblock3.denselayer17.conv1.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	1574606065728 -> 1574704118560
	1574704118560 [label=AccumulateGrad]
	1574704118128 -> 1574704118320
	1574606065808 [label="features.denseblock3.denselayer17.norm2.weight
 (192)" fillcolor=lightblue]
	1574606065808 -> 1574704118128
	1574704118128 [label=AccumulateGrad]
	1574704117888 -> 1574704118320
	1574606065888 [label="features.denseblock3.denselayer17.norm2.bias
 (192)" fillcolor=lightblue]
	1574606065888 -> 1574704117888
	1574704117888 [label=AccumulateGrad]
	1574704117936 -> 1574704488720
	1574606066368 [label="features.denseblock3.denselayer17.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606066368 -> 1574704117936
	1574704117936 [label=AccumulateGrad]
	1574704488768 -> 1574704487808
	1574704488768 [label=ConvolutionBackward0]
	1574704118368 -> 1574704488768
	1574704118368 [label=ReluBackward0]
	1574704118896 -> 1574704118368
	1574704118896 [label=NativeBatchNormBackward0]
	1574704118992 -> 1574704118896
	1574704118992 [label=ConvolutionBackward0]
	1574704119184 -> 1574704118992
	1574704119184 [label=ReluBackward0]
	1574704119328 -> 1574704119184
	1574704119328 [label=NativeBatchNormBackward0]
	1574704119424 -> 1574704119328
	1574704119424 [label=CatBackward0]
	1574704488000 -> 1574704119424
	1574704487952 -> 1574704119424
	1574704487904 -> 1574704119424
	1574704488048 -> 1574704119424
	1574704488096 -> 1574704119424
	1574704488144 -> 1574704119424
	1574704488192 -> 1574704119424
	1574704488240 -> 1574704119424
	1574704488288 -> 1574704119424
	1574704488336 -> 1574704119424
	1574704488384 -> 1574704119424
	1574704488432 -> 1574704119424
	1574704488480 -> 1574704119424
	1574704488528 -> 1574704119424
	1574704488576 -> 1574704119424
	1574704488624 -> 1574704119424
	1574704488672 -> 1574704119424
	1574704488720 -> 1574704119424
	1574704119376 -> 1574704119328
	1574606066448 [label="features.denseblock3.denselayer18.norm1.weight
 (1200)" fillcolor=lightblue]
	1574606066448 -> 1574704119376
	1574704119376 [label=AccumulateGrad]
	1574704119232 -> 1574704119328
	1574606066528 [label="features.denseblock3.denselayer18.norm1.bias
 (1200)" fillcolor=lightblue]
	1574606066528 -> 1574704119232
	1574704119232 [label=AccumulateGrad]
	1574704119136 -> 1574704118992
	1574606067008 [label="features.denseblock3.denselayer18.conv1.weight
 (192, 1200, 1, 1)" fillcolor=lightblue]
	1574606067008 -> 1574704119136
	1574704119136 [label=AccumulateGrad]
	1574704118704 -> 1574704118896
	1574606067088 [label="features.denseblock3.denselayer18.norm2.weight
 (192)" fillcolor=lightblue]
	1574606067088 -> 1574704118704
	1574704118704 [label=AccumulateGrad]
	1574704118464 -> 1574704118896
	1574606067168 [label="features.denseblock3.denselayer18.norm2.bias
 (192)" fillcolor=lightblue]
	1574606067168 -> 1574704118464
	1574704118464 [label=AccumulateGrad]
	1574704118512 -> 1574704488768
	1574606067648 [label="features.denseblock3.denselayer18.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606067648 -> 1574704118512
	1574704118512 [label=AccumulateGrad]
	1574704488816 -> 1574704487808
	1574704488816 [label=ConvolutionBackward0]
	1574704118944 -> 1574704488816
	1574704118944 [label=ReluBackward0]
	1574704119472 -> 1574704118944
	1574704119472 [label=NativeBatchNormBackward0]
	1574704119568 -> 1574704119472
	1574704119568 [label=ConvolutionBackward0]
	1574704119760 -> 1574704119568
	1574704119760 [label=ReluBackward0]
	1574704693408 -> 1574704119760
	1574704693408 [label=NativeBatchNormBackward0]
	1574704693504 -> 1574704693408
	1574704693504 [label=CatBackward0]
	1574704488000 -> 1574704693504
	1574704487952 -> 1574704693504
	1574704487904 -> 1574704693504
	1574704488048 -> 1574704693504
	1574704488096 -> 1574704693504
	1574704488144 -> 1574704693504
	1574704488192 -> 1574704693504
	1574704488240 -> 1574704693504
	1574704488288 -> 1574704693504
	1574704488336 -> 1574704693504
	1574704488384 -> 1574704693504
	1574704488432 -> 1574704693504
	1574704488480 -> 1574704693504
	1574704488528 -> 1574704693504
	1574704488576 -> 1574704693504
	1574704488624 -> 1574704693504
	1574704488672 -> 1574704693504
	1574704488720 -> 1574704693504
	1574704488768 -> 1574704693504
	1574704693456 -> 1574704693408
	1574606067728 [label="features.denseblock3.denselayer19.norm1.weight
 (1248)" fillcolor=lightblue]
	1574606067728 -> 1574704693456
	1574704693456 [label=AccumulateGrad]
	1574704693312 -> 1574704693408
	1574606067808 [label="features.denseblock3.denselayer19.norm1.bias
 (1248)" fillcolor=lightblue]
	1574606067808 -> 1574704693312
	1574704693312 [label=AccumulateGrad]
	1574704119712 -> 1574704119568
	1574606068288 [label="features.denseblock3.denselayer19.conv1.weight
 (192, 1248, 1, 1)" fillcolor=lightblue]
	1574606068288 -> 1574704119712
	1574704119712 [label=AccumulateGrad]
	1574704119280 -> 1574704119472
	1574606068368 [label="features.denseblock3.denselayer19.norm2.weight
 (192)" fillcolor=lightblue]
	1574606068368 -> 1574704119280
	1574704119280 [label=AccumulateGrad]
	1574704119040 -> 1574704119472
	1574606068448 [label="features.denseblock3.denselayer19.norm2.bias
 (192)" fillcolor=lightblue]
	1574606068448 -> 1574704119040
	1574704119040 [label=AccumulateGrad]
	1574704119088 -> 1574704488816
	1574606068928 [label="features.denseblock3.denselayer19.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606068928 -> 1574704119088
	1574704119088 [label=AccumulateGrad]
	1574704488864 -> 1574704487808
	1574704488864 [label=ConvolutionBackward0]
	1574704119520 -> 1574704488864
	1574704119520 [label=ReluBackward0]
	1574704119616 -> 1574704119520
	1574704119616 [label=NativeBatchNormBackward0]
	1574704693648 -> 1574704119616
	1574704693648 [label=ConvolutionBackward0]
	1574704693840 -> 1574704693648
	1574704693840 [label=ReluBackward0]
	1574704693984 -> 1574704693840
	1574704693984 [label=NativeBatchNormBackward0]
	1574704694080 -> 1574704693984
	1574704694080 [label=CatBackward0]
	1574704488000 -> 1574704694080
	1574704487952 -> 1574704694080
	1574704487904 -> 1574704694080
	1574704488048 -> 1574704694080
	1574704488096 -> 1574704694080
	1574704488144 -> 1574704694080
	1574704488192 -> 1574704694080
	1574704488240 -> 1574704694080
	1574704488288 -> 1574704694080
	1574704488336 -> 1574704694080
	1574704488384 -> 1574704694080
	1574704488432 -> 1574704694080
	1574704488480 -> 1574704694080
	1574704488528 -> 1574704694080
	1574704488576 -> 1574704694080
	1574704488624 -> 1574704694080
	1574704488672 -> 1574704694080
	1574704488720 -> 1574704694080
	1574704488768 -> 1574704694080
	1574704488816 -> 1574704694080
	1574704694032 -> 1574704693984
	1574606069008 [label="features.denseblock3.denselayer20.norm1.weight
 (1296)" fillcolor=lightblue]
	1574606069008 -> 1574704694032
	1574704694032 [label=AccumulateGrad]
	1574704693888 -> 1574704693984
	1574606069088 [label="features.denseblock3.denselayer20.norm1.bias
 (1296)" fillcolor=lightblue]
	1574606069088 -> 1574704693888
	1574704693888 [label=AccumulateGrad]
	1574704693792 -> 1574704693648
	1574606069568 [label="features.denseblock3.denselayer20.conv1.weight
 (192, 1296, 1, 1)" fillcolor=lightblue]
	1574606069568 -> 1574704693792
	1574704693792 [label=AccumulateGrad]
	1574704693360 -> 1574704119616
	1574606069648 [label="features.denseblock3.denselayer20.norm2.weight
 (192)" fillcolor=lightblue]
	1574606069648 -> 1574704693360
	1574704693360 [label=AccumulateGrad]
	1574704693696 -> 1574704119616
	1574606069728 [label="features.denseblock3.denselayer20.norm2.bias
 (192)" fillcolor=lightblue]
	1574606069728 -> 1574704693696
	1574704693696 [label=AccumulateGrad]
	1574704119664 -> 1574704488864
	1574606070208 [label="features.denseblock3.denselayer20.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606070208 -> 1574704119664
	1574704119664 [label=AccumulateGrad]
	1574704488912 -> 1574704487808
	1574704488912 [label=ConvolutionBackward0]
	1574704109488 -> 1574704488912
	1574704109488 [label=ReluBackward0]
	1574704694128 -> 1574704109488
	1574704694128 [label=NativeBatchNormBackward0]
	1574704694224 -> 1574704694128
	1574704694224 [label=ConvolutionBackward0]
	1574704694416 -> 1574704694224
	1574704694416 [label=ReluBackward0]
	1574704694560 -> 1574704694416
	1574704694560 [label=NativeBatchNormBackward0]
	1574704694656 -> 1574704694560
	1574704694656 [label=CatBackward0]
	1574704488000 -> 1574704694656
	1574704487952 -> 1574704694656
	1574704487904 -> 1574704694656
	1574704488048 -> 1574704694656
	1574704488096 -> 1574704694656
	1574704488144 -> 1574704694656
	1574704488192 -> 1574704694656
	1574704488240 -> 1574704694656
	1574704488288 -> 1574704694656
	1574704488336 -> 1574704694656
	1574704488384 -> 1574704694656
	1574704488432 -> 1574704694656
	1574704488480 -> 1574704694656
	1574704488528 -> 1574704694656
	1574704488576 -> 1574704694656
	1574704488624 -> 1574704694656
	1574704488672 -> 1574704694656
	1574704488720 -> 1574704694656
	1574704488768 -> 1574704694656
	1574704488816 -> 1574704694656
	1574704488864 -> 1574704694656
	1574704694608 -> 1574704694560
	1574606070288 [label="features.denseblock3.denselayer21.norm1.weight
 (1344)" fillcolor=lightblue]
	1574606070288 -> 1574704694608
	1574704694608 [label=AccumulateGrad]
	1574704694464 -> 1574704694560
	1574606070368 [label="features.denseblock3.denselayer21.norm1.bias
 (1344)" fillcolor=lightblue]
	1574606070368 -> 1574704694464
	1574704694464 [label=AccumulateGrad]
	1574704694368 -> 1574704694224
	1574606070848 [label="features.denseblock3.denselayer21.conv1.weight
 (192, 1344, 1, 1)" fillcolor=lightblue]
	1574606070848 -> 1574704694368
	1574704694368 [label=AccumulateGrad]
	1574704693936 -> 1574704694128
	1574606070928 [label="features.denseblock3.denselayer21.norm2.weight
 (192)" fillcolor=lightblue]
	1574606070928 -> 1574704693936
	1574704693936 [label=AccumulateGrad]
	1574704693552 -> 1574704694128
	1574606071008 [label="features.denseblock3.denselayer21.norm2.bias
 (192)" fillcolor=lightblue]
	1574606071008 -> 1574704693552
	1574704693552 [label=AccumulateGrad]
	1574704693600 -> 1574704488912
	1574606071488 [label="features.denseblock3.denselayer21.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606071488 -> 1574704693600
	1574704693600 [label=AccumulateGrad]
	1574704488960 -> 1574704487808
	1574704488960 [label=ConvolutionBackward0]
	1574704694176 -> 1574704488960
	1574704694176 [label=ReluBackward0]
	1574704694704 -> 1574704694176
	1574704694704 [label=NativeBatchNormBackward0]
	1574704694800 -> 1574704694704
	1574704694800 [label=ConvolutionBackward0]
	1574704694992 -> 1574704694800
	1574704694992 [label=ReluBackward0]
	1574704695136 -> 1574704694992
	1574704695136 [label=NativeBatchNormBackward0]
	1574704695232 -> 1574704695136
	1574704695232 [label=CatBackward0]
	1574704488000 -> 1574704695232
	1574704487952 -> 1574704695232
	1574704487904 -> 1574704695232
	1574704488048 -> 1574704695232
	1574704488096 -> 1574704695232
	1574704488144 -> 1574704695232
	1574704488192 -> 1574704695232
	1574704488240 -> 1574704695232
	1574704488288 -> 1574704695232
	1574704488336 -> 1574704695232
	1574704488384 -> 1574704695232
	1574704488432 -> 1574704695232
	1574704488480 -> 1574704695232
	1574704488528 -> 1574704695232
	1574704488576 -> 1574704695232
	1574704488624 -> 1574704695232
	1574704488672 -> 1574704695232
	1574704488720 -> 1574704695232
	1574704488768 -> 1574704695232
	1574704488816 -> 1574704695232
	1574704488864 -> 1574704695232
	1574704488912 -> 1574704695232
	1574704695184 -> 1574704695136
	1574606071568 [label="features.denseblock3.denselayer22.norm1.weight
 (1392)" fillcolor=lightblue]
	1574606071568 -> 1574704695184
	1574704695184 [label=AccumulateGrad]
	1574704695040 -> 1574704695136
	1574606071648 [label="features.denseblock3.denselayer22.norm1.bias
 (1392)" fillcolor=lightblue]
	1574606071648 -> 1574704695040
	1574704695040 [label=AccumulateGrad]
	1574704694944 -> 1574704694800
	1574606072128 [label="features.denseblock3.denselayer22.conv1.weight
 (192, 1392, 1, 1)" fillcolor=lightblue]
	1574606072128 -> 1574704694944
	1574704694944 [label=AccumulateGrad]
	1574704694512 -> 1574704694704
	1574606072208 [label="features.denseblock3.denselayer22.norm2.weight
 (192)" fillcolor=lightblue]
	1574606072208 -> 1574704694512
	1574704694512 [label=AccumulateGrad]
	1574704694272 -> 1574704694704
	1574606072288 [label="features.denseblock3.denselayer22.norm2.bias
 (192)" fillcolor=lightblue]
	1574606072288 -> 1574704694272
	1574704694272 [label=AccumulateGrad]
	1574704694320 -> 1574704488960
	1574606072768 [label="features.denseblock3.denselayer22.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606072768 -> 1574704694320
	1574704694320 [label=AccumulateGrad]
	1574704489008 -> 1574704487808
	1574704489008 [label=ConvolutionBackward0]
	1574704694752 -> 1574704489008
	1574704694752 [label=ReluBackward0]
	1574704695280 -> 1574704694752
	1574704695280 [label=NativeBatchNormBackward0]
	1574704695376 -> 1574704695280
	1574704695376 [label=ConvolutionBackward0]
	1574704695568 -> 1574704695376
	1574704695568 [label=ReluBackward0]
	1574704695712 -> 1574704695568
	1574704695712 [label=NativeBatchNormBackward0]
	1574704695808 -> 1574704695712
	1574704695808 [label=CatBackward0]
	1574704488000 -> 1574704695808
	1574704487952 -> 1574704695808
	1574704487904 -> 1574704695808
	1574704488048 -> 1574704695808
	1574704488096 -> 1574704695808
	1574704488144 -> 1574704695808
	1574704488192 -> 1574704695808
	1574704488240 -> 1574704695808
	1574704488288 -> 1574704695808
	1574704488336 -> 1574704695808
	1574704488384 -> 1574704695808
	1574704488432 -> 1574704695808
	1574704488480 -> 1574704695808
	1574704488528 -> 1574704695808
	1574704488576 -> 1574704695808
	1574704488624 -> 1574704695808
	1574704488672 -> 1574704695808
	1574704488720 -> 1574704695808
	1574704488768 -> 1574704695808
	1574704488816 -> 1574704695808
	1574704488864 -> 1574704695808
	1574704488912 -> 1574704695808
	1574704488960 -> 1574704695808
	1574704695760 -> 1574704695712
	1574606072848 [label="features.denseblock3.denselayer23.norm1.weight
 (1440)" fillcolor=lightblue]
	1574606072848 -> 1574704695760
	1574704695760 [label=AccumulateGrad]
	1574704695616 -> 1574704695712
	1574606072928 [label="features.denseblock3.denselayer23.norm1.bias
 (1440)" fillcolor=lightblue]
	1574606072928 -> 1574704695616
	1574704695616 [label=AccumulateGrad]
	1574704695520 -> 1574704695376
	1574606073408 [label="features.denseblock3.denselayer23.conv1.weight
 (192, 1440, 1, 1)" fillcolor=lightblue]
	1574606073408 -> 1574704695520
	1574704695520 [label=AccumulateGrad]
	1574704695088 -> 1574704695280
	1574606073488 [label="features.denseblock3.denselayer23.norm2.weight
 (192)" fillcolor=lightblue]
	1574606073488 -> 1574704695088
	1574704695088 [label=AccumulateGrad]
	1574704694848 -> 1574704695280
	1574606073568 [label="features.denseblock3.denselayer23.norm2.bias
 (192)" fillcolor=lightblue]
	1574606073568 -> 1574704694848
	1574704694848 [label=AccumulateGrad]
	1574704694896 -> 1574704489008
	1574606074048 [label="features.denseblock3.denselayer23.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606074048 -> 1574704694896
	1574704694896 [label=AccumulateGrad]
	1574704489056 -> 1574704487808
	1574704489056 [label=ConvolutionBackward0]
	1574704695328 -> 1574704489056
	1574704695328 [label=ReluBackward0]
	1574704695856 -> 1574704695328
	1574704695856 [label=NativeBatchNormBackward0]
	1574704695952 -> 1574704695856
	1574704695952 [label=ConvolutionBackward0]
	1574704696144 -> 1574704695952
	1574704696144 [label=ReluBackward0]
	1574704696288 -> 1574704696144
	1574704696288 [label=NativeBatchNormBackward0]
	1574704696384 -> 1574704696288
	1574704696384 [label=CatBackward0]
	1574704488000 -> 1574704696384
	1574704487952 -> 1574704696384
	1574704487904 -> 1574704696384
	1574704488048 -> 1574704696384
	1574704488096 -> 1574704696384
	1574704488144 -> 1574704696384
	1574704488192 -> 1574704696384
	1574704488240 -> 1574704696384
	1574704488288 -> 1574704696384
	1574704488336 -> 1574704696384
	1574704488384 -> 1574704696384
	1574704488432 -> 1574704696384
	1574704488480 -> 1574704696384
	1574704488528 -> 1574704696384
	1574704488576 -> 1574704696384
	1574704488624 -> 1574704696384
	1574704488672 -> 1574704696384
	1574704488720 -> 1574704696384
	1574704488768 -> 1574704696384
	1574704488816 -> 1574704696384
	1574704488864 -> 1574704696384
	1574704488912 -> 1574704696384
	1574704488960 -> 1574704696384
	1574704489008 -> 1574704696384
	1574704696336 -> 1574704696288
	1574606074128 [label="features.denseblock3.denselayer24.norm1.weight
 (1488)" fillcolor=lightblue]
	1574606074128 -> 1574704696336
	1574704696336 [label=AccumulateGrad]
	1574704696192 -> 1574704696288
	1574606074208 [label="features.denseblock3.denselayer24.norm1.bias
 (1488)" fillcolor=lightblue]
	1574606074208 -> 1574704696192
	1574704696192 [label=AccumulateGrad]
	1574704696096 -> 1574704695952
	1574606074688 [label="features.denseblock3.denselayer24.conv1.weight
 (192, 1488, 1, 1)" fillcolor=lightblue]
	1574606074688 -> 1574704696096
	1574704696096 [label=AccumulateGrad]
	1574704695664 -> 1574704695856
	1574606074768 [label="features.denseblock3.denselayer24.norm2.weight
 (192)" fillcolor=lightblue]
	1574606074768 -> 1574704695664
	1574704695664 [label=AccumulateGrad]
	1574704695424 -> 1574704695856
	1574606074848 [label="features.denseblock3.denselayer24.norm2.bias
 (192)" fillcolor=lightblue]
	1574606074848 -> 1574704695424
	1574704695424 [label=AccumulateGrad]
	1574704695472 -> 1574704489056
	1574606075328 [label="features.denseblock3.denselayer24.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606075328 -> 1574704695472
	1574704695472 [label=AccumulateGrad]
	1574704489104 -> 1574704487808
	1574704489104 [label=ConvolutionBackward0]
	1574704695904 -> 1574704489104
	1574704695904 [label=ReluBackward0]
	1574704696432 -> 1574704695904
	1574704696432 [label=NativeBatchNormBackward0]
	1574704696528 -> 1574704696432
	1574704696528 [label=ConvolutionBackward0]
	1574704696720 -> 1574704696528
	1574704696720 [label=ReluBackward0]
	1574704696864 -> 1574704696720
	1574704696864 [label=NativeBatchNormBackward0]
	1574704696960 -> 1574704696864
	1574704696960 [label=CatBackward0]
	1574704488000 -> 1574704696960
	1574704487952 -> 1574704696960
	1574704487904 -> 1574704696960
	1574704488048 -> 1574704696960
	1574704488096 -> 1574704696960
	1574704488144 -> 1574704696960
	1574704488192 -> 1574704696960
	1574704488240 -> 1574704696960
	1574704488288 -> 1574704696960
	1574704488336 -> 1574704696960
	1574704488384 -> 1574704696960
	1574704488432 -> 1574704696960
	1574704488480 -> 1574704696960
	1574704488528 -> 1574704696960
	1574704488576 -> 1574704696960
	1574704488624 -> 1574704696960
	1574704488672 -> 1574704696960
	1574704488720 -> 1574704696960
	1574704488768 -> 1574704696960
	1574704488816 -> 1574704696960
	1574704488864 -> 1574704696960
	1574704488912 -> 1574704696960
	1574704488960 -> 1574704696960
	1574704489008 -> 1574704696960
	1574704489056 -> 1574704696960
	1574704696912 -> 1574704696864
	1574606075408 [label="features.denseblock3.denselayer25.norm1.weight
 (1536)" fillcolor=lightblue]
	1574606075408 -> 1574704696912
	1574704696912 [label=AccumulateGrad]
	1574704696768 -> 1574704696864
	1574606075488 [label="features.denseblock3.denselayer25.norm1.bias
 (1536)" fillcolor=lightblue]
	1574606075488 -> 1574704696768
	1574704696768 [label=AccumulateGrad]
	1574704696672 -> 1574704696528
	1574606075968 [label="features.denseblock3.denselayer25.conv1.weight
 (192, 1536, 1, 1)" fillcolor=lightblue]
	1574606075968 -> 1574704696672
	1574704696672 [label=AccumulateGrad]
	1574704696240 -> 1574704696432
	1574606076048 [label="features.denseblock3.denselayer25.norm2.weight
 (192)" fillcolor=lightblue]
	1574606076048 -> 1574704696240
	1574704696240 [label=AccumulateGrad]
	1574704696000 -> 1574704696432
	1574606076128 [label="features.denseblock3.denselayer25.norm2.bias
 (192)" fillcolor=lightblue]
	1574606076128 -> 1574704696000
	1574704696000 [label=AccumulateGrad]
	1574704696048 -> 1574704489104
	1574606076608 [label="features.denseblock3.denselayer25.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606076608 -> 1574704696048
	1574704696048 [label=AccumulateGrad]
	1574704489152 -> 1574704487808
	1574704489152 [label=ConvolutionBackward0]
	1574704696480 -> 1574704489152
	1574704696480 [label=ReluBackward0]
	1574704697008 -> 1574704696480
	1574704697008 [label=NativeBatchNormBackward0]
	1574704697104 -> 1574704697008
	1574704697104 [label=ConvolutionBackward0]
	1574704697296 -> 1574704697104
	1574704697296 [label=ReluBackward0]
	1574704697440 -> 1574704697296
	1574704697440 [label=NativeBatchNormBackward0]
	1574704697536 -> 1574704697440
	1574704697536 [label=CatBackward0]
	1574704488000 -> 1574704697536
	1574704487952 -> 1574704697536
	1574704487904 -> 1574704697536
	1574704488048 -> 1574704697536
	1574704488096 -> 1574704697536
	1574704488144 -> 1574704697536
	1574704488192 -> 1574704697536
	1574704488240 -> 1574704697536
	1574704488288 -> 1574704697536
	1574704488336 -> 1574704697536
	1574704488384 -> 1574704697536
	1574704488432 -> 1574704697536
	1574704488480 -> 1574704697536
	1574704488528 -> 1574704697536
	1574704488576 -> 1574704697536
	1574704488624 -> 1574704697536
	1574704488672 -> 1574704697536
	1574704488720 -> 1574704697536
	1574704488768 -> 1574704697536
	1574704488816 -> 1574704697536
	1574704488864 -> 1574704697536
	1574704488912 -> 1574704697536
	1574704488960 -> 1574704697536
	1574704489008 -> 1574704697536
	1574704489056 -> 1574704697536
	1574704489104 -> 1574704697536
	1574704697488 -> 1574704697440
	1574606076688 [label="features.denseblock3.denselayer26.norm1.weight
 (1584)" fillcolor=lightblue]
	1574606076688 -> 1574704697488
	1574704697488 [label=AccumulateGrad]
	1574704697344 -> 1574704697440
	1574606076768 [label="features.denseblock3.denselayer26.norm1.bias
 (1584)" fillcolor=lightblue]
	1574606076768 -> 1574704697344
	1574704697344 [label=AccumulateGrad]
	1574704697248 -> 1574704697104
	1574606077248 [label="features.denseblock3.denselayer26.conv1.weight
 (192, 1584, 1, 1)" fillcolor=lightblue]
	1574606077248 -> 1574704697248
	1574704697248 [label=AccumulateGrad]
	1574704696816 -> 1574704697008
	1574606077328 [label="features.denseblock3.denselayer26.norm2.weight
 (192)" fillcolor=lightblue]
	1574606077328 -> 1574704696816
	1574704696816 [label=AccumulateGrad]
	1574704696576 -> 1574704697008
	1574606077408 [label="features.denseblock3.denselayer26.norm2.bias
 (192)" fillcolor=lightblue]
	1574606077408 -> 1574704696576
	1574704696576 [label=AccumulateGrad]
	1574704696624 -> 1574704489152
	1574606077888 [label="features.denseblock3.denselayer26.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606077888 -> 1574704696624
	1574704696624 [label=AccumulateGrad]
	1574704489200 -> 1574704487808
	1574704489200 [label=ConvolutionBackward0]
	1574704697056 -> 1574704489200
	1574704697056 [label=ReluBackward0]
	1574704697584 -> 1574704697056
	1574704697584 [label=NativeBatchNormBackward0]
	1574704697680 -> 1574704697584
	1574704697680 [label=ConvolutionBackward0]
	1574704697872 -> 1574704697680
	1574704697872 [label=ReluBackward0]
	1574704698016 -> 1574704697872
	1574704698016 [label=NativeBatchNormBackward0]
	1574704698112 -> 1574704698016
	1574704698112 [label=CatBackward0]
	1574704488000 -> 1574704698112
	1574704487952 -> 1574704698112
	1574704487904 -> 1574704698112
	1574704488048 -> 1574704698112
	1574704488096 -> 1574704698112
	1574704488144 -> 1574704698112
	1574704488192 -> 1574704698112
	1574704488240 -> 1574704698112
	1574704488288 -> 1574704698112
	1574704488336 -> 1574704698112
	1574704488384 -> 1574704698112
	1574704488432 -> 1574704698112
	1574704488480 -> 1574704698112
	1574704488528 -> 1574704698112
	1574704488576 -> 1574704698112
	1574704488624 -> 1574704698112
	1574704488672 -> 1574704698112
	1574704488720 -> 1574704698112
	1574704488768 -> 1574704698112
	1574704488816 -> 1574704698112
	1574704488864 -> 1574704698112
	1574704488912 -> 1574704698112
	1574704488960 -> 1574704698112
	1574704489008 -> 1574704698112
	1574704489056 -> 1574704698112
	1574704489104 -> 1574704698112
	1574704489152 -> 1574704698112
	1574704698064 -> 1574704698016
	1574606291024 [label="features.denseblock3.denselayer27.norm1.weight
 (1632)" fillcolor=lightblue]
	1574606291024 -> 1574704698064
	1574704698064 [label=AccumulateGrad]
	1574704697920 -> 1574704698016
	1574606291104 [label="features.denseblock3.denselayer27.norm1.bias
 (1632)" fillcolor=lightblue]
	1574606291104 -> 1574704697920
	1574704697920 [label=AccumulateGrad]
	1574704697824 -> 1574704697680
	1574606291584 [label="features.denseblock3.denselayer27.conv1.weight
 (192, 1632, 1, 1)" fillcolor=lightblue]
	1574606291584 -> 1574704697824
	1574704697824 [label=AccumulateGrad]
	1574704697392 -> 1574704697584
	1574606291664 [label="features.denseblock3.denselayer27.norm2.weight
 (192)" fillcolor=lightblue]
	1574606291664 -> 1574704697392
	1574704697392 [label=AccumulateGrad]
	1574704697152 -> 1574704697584
	1574606291744 [label="features.denseblock3.denselayer27.norm2.bias
 (192)" fillcolor=lightblue]
	1574606291744 -> 1574704697152
	1574704697152 [label=AccumulateGrad]
	1574704697200 -> 1574704489200
	1574606292224 [label="features.denseblock3.denselayer27.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606292224 -> 1574704697200
	1574704697200 [label=AccumulateGrad]
	1574704489248 -> 1574704487808
	1574704489248 [label=ConvolutionBackward0]
	1574704697632 -> 1574704489248
	1574704697632 [label=ReluBackward0]
	1574704698160 -> 1574704697632
	1574704698160 [label=NativeBatchNormBackward0]
	1574704698256 -> 1574704698160
	1574704698256 [label=ConvolutionBackward0]
	1574704698448 -> 1574704698256
	1574704698448 [label=ReluBackward0]
	1574704698592 -> 1574704698448
	1574704698592 [label=NativeBatchNormBackward0]
	1574704698688 -> 1574704698592
	1574704698688 [label=CatBackward0]
	1574704488000 -> 1574704698688
	1574704487952 -> 1574704698688
	1574704487904 -> 1574704698688
	1574704488048 -> 1574704698688
	1574704488096 -> 1574704698688
	1574704488144 -> 1574704698688
	1574704488192 -> 1574704698688
	1574704488240 -> 1574704698688
	1574704488288 -> 1574704698688
	1574704488336 -> 1574704698688
	1574704488384 -> 1574704698688
	1574704488432 -> 1574704698688
	1574704488480 -> 1574704698688
	1574704488528 -> 1574704698688
	1574704488576 -> 1574704698688
	1574704488624 -> 1574704698688
	1574704488672 -> 1574704698688
	1574704488720 -> 1574704698688
	1574704488768 -> 1574704698688
	1574704488816 -> 1574704698688
	1574704488864 -> 1574704698688
	1574704488912 -> 1574704698688
	1574704488960 -> 1574704698688
	1574704489008 -> 1574704698688
	1574704489056 -> 1574704698688
	1574704489104 -> 1574704698688
	1574704489152 -> 1574704698688
	1574704489200 -> 1574704698688
	1574704698640 -> 1574704698592
	1574606292304 [label="features.denseblock3.denselayer28.norm1.weight
 (1680)" fillcolor=lightblue]
	1574606292304 -> 1574704698640
	1574704698640 [label=AccumulateGrad]
	1574704698496 -> 1574704698592
	1574606292384 [label="features.denseblock3.denselayer28.norm1.bias
 (1680)" fillcolor=lightblue]
	1574606292384 -> 1574704698496
	1574704698496 [label=AccumulateGrad]
	1574704698400 -> 1574704698256
	1574606292544 [label="features.denseblock3.denselayer28.conv1.weight
 (192, 1680, 1, 1)" fillcolor=lightblue]
	1574606292544 -> 1574704698400
	1574704698400 [label=AccumulateGrad]
	1574704697968 -> 1574704698160
	1574606292864 [label="features.denseblock3.denselayer28.norm2.weight
 (192)" fillcolor=lightblue]
	1574606292864 -> 1574704697968
	1574704697968 [label=AccumulateGrad]
	1574704697728 -> 1574704698160
	1574606292944 [label="features.denseblock3.denselayer28.norm2.bias
 (192)" fillcolor=lightblue]
	1574606292944 -> 1574704697728
	1574704697728 [label=AccumulateGrad]
	1574704697776 -> 1574704489248
	1574606293424 [label="features.denseblock3.denselayer28.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606293424 -> 1574704697776
	1574704697776 [label=AccumulateGrad]
	1574704489296 -> 1574704487808
	1574704489296 [label=ConvolutionBackward0]
	1574704698208 -> 1574704489296
	1574704698208 [label=ReluBackward0]
	1574704698736 -> 1574704698208
	1574704698736 [label=NativeBatchNormBackward0]
	1574704698832 -> 1574704698736
	1574704698832 [label=ConvolutionBackward0]
	1574704699024 -> 1574704698832
	1574704699024 [label=ReluBackward0]
	1574704699168 -> 1574704699024
	1574704699168 [label=NativeBatchNormBackward0]
	1574704699264 -> 1574704699168
	1574704699264 [label=CatBackward0]
	1574704488000 -> 1574704699264
	1574704487952 -> 1574704699264
	1574704487904 -> 1574704699264
	1574704488048 -> 1574704699264
	1574704488096 -> 1574704699264
	1574704488144 -> 1574704699264
	1574704488192 -> 1574704699264
	1574704488240 -> 1574704699264
	1574704488288 -> 1574704699264
	1574704488336 -> 1574704699264
	1574704488384 -> 1574704699264
	1574704488432 -> 1574704699264
	1574704488480 -> 1574704699264
	1574704488528 -> 1574704699264
	1574704488576 -> 1574704699264
	1574704488624 -> 1574704699264
	1574704488672 -> 1574704699264
	1574704488720 -> 1574704699264
	1574704488768 -> 1574704699264
	1574704488816 -> 1574704699264
	1574704488864 -> 1574704699264
	1574704488912 -> 1574704699264
	1574704488960 -> 1574704699264
	1574704489008 -> 1574704699264
	1574704489056 -> 1574704699264
	1574704489104 -> 1574704699264
	1574704489152 -> 1574704699264
	1574704489200 -> 1574704699264
	1574704489248 -> 1574704699264
	1574704699216 -> 1574704699168
	1574606293504 [label="features.denseblock3.denselayer29.norm1.weight
 (1728)" fillcolor=lightblue]
	1574606293504 -> 1574704699216
	1574704699216 [label=AccumulateGrad]
	1574704699072 -> 1574704699168
	1574606293584 [label="features.denseblock3.denselayer29.norm1.bias
 (1728)" fillcolor=lightblue]
	1574606293584 -> 1574704699072
	1574704699072 [label=AccumulateGrad]
	1574704698976 -> 1574704698832
	1574606294064 [label="features.denseblock3.denselayer29.conv1.weight
 (192, 1728, 1, 1)" fillcolor=lightblue]
	1574606294064 -> 1574704698976
	1574704698976 [label=AccumulateGrad]
	1574704698544 -> 1574704698736
	1574606294144 [label="features.denseblock3.denselayer29.norm2.weight
 (192)" fillcolor=lightblue]
	1574606294144 -> 1574704698544
	1574704698544 [label=AccumulateGrad]
	1574704698304 -> 1574704698736
	1574606294224 [label="features.denseblock3.denselayer29.norm2.bias
 (192)" fillcolor=lightblue]
	1574606294224 -> 1574704698304
	1574704698304 [label=AccumulateGrad]
	1574704698352 -> 1574704489296
	1574606294704 [label="features.denseblock3.denselayer29.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606294704 -> 1574704698352
	1574704698352 [label=AccumulateGrad]
	1574704489344 -> 1574704487808
	1574704489344 [label=ConvolutionBackward0]
	1574704698784 -> 1574704489344
	1574704698784 [label=ReluBackward0]
	1574704699312 -> 1574704698784
	1574704699312 [label=NativeBatchNormBackward0]
	1574704699408 -> 1574704699312
	1574704699408 [label=ConvolutionBackward0]
	1574704699600 -> 1574704699408
	1574704699600 [label=ReluBackward0]
	1574704699744 -> 1574704699600
	1574704699744 [label=NativeBatchNormBackward0]
	1574704699840 -> 1574704699744
	1574704699840 [label=CatBackward0]
	1574704488000 -> 1574704699840
	1574704487952 -> 1574704699840
	1574704487904 -> 1574704699840
	1574704488048 -> 1574704699840
	1574704488096 -> 1574704699840
	1574704488144 -> 1574704699840
	1574704488192 -> 1574704699840
	1574704488240 -> 1574704699840
	1574704488288 -> 1574704699840
	1574704488336 -> 1574704699840
	1574704488384 -> 1574704699840
	1574704488432 -> 1574704699840
	1574704488480 -> 1574704699840
	1574704488528 -> 1574704699840
	1574704488576 -> 1574704699840
	1574704488624 -> 1574704699840
	1574704488672 -> 1574704699840
	1574704488720 -> 1574704699840
	1574704488768 -> 1574704699840
	1574704488816 -> 1574704699840
	1574704488864 -> 1574704699840
	1574704488912 -> 1574704699840
	1574704488960 -> 1574704699840
	1574704489008 -> 1574704699840
	1574704489056 -> 1574704699840
	1574704489104 -> 1574704699840
	1574704489152 -> 1574704699840
	1574704489200 -> 1574704699840
	1574704489248 -> 1574704699840
	1574704489296 -> 1574704699840
	1574704699792 -> 1574704699744
	1574606294784 [label="features.denseblock3.denselayer30.norm1.weight
 (1776)" fillcolor=lightblue]
	1574606294784 -> 1574704699792
	1574704699792 [label=AccumulateGrad]
	1574704699648 -> 1574704699744
	1574606294864 [label="features.denseblock3.denselayer30.norm1.bias
 (1776)" fillcolor=lightblue]
	1574606294864 -> 1574704699648
	1574704699648 [label=AccumulateGrad]
	1574704699552 -> 1574704699408
	1574606295344 [label="features.denseblock3.denselayer30.conv1.weight
 (192, 1776, 1, 1)" fillcolor=lightblue]
	1574606295344 -> 1574704699552
	1574704699552 [label=AccumulateGrad]
	1574704699120 -> 1574704699312
	1574606295424 [label="features.denseblock3.denselayer30.norm2.weight
 (192)" fillcolor=lightblue]
	1574606295424 -> 1574704699120
	1574704699120 [label=AccumulateGrad]
	1574704698880 -> 1574704699312
	1574606295504 [label="features.denseblock3.denselayer30.norm2.bias
 (192)" fillcolor=lightblue]
	1574606295504 -> 1574704698880
	1574704698880 [label=AccumulateGrad]
	1574704698928 -> 1574704489344
	1574606295984 [label="features.denseblock3.denselayer30.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606295984 -> 1574704698928
	1574704698928 [label=AccumulateGrad]
	1574704489392 -> 1574704487808
	1574704489392 [label=ConvolutionBackward0]
	1574704699360 -> 1574704489392
	1574704699360 [label=ReluBackward0]
	1574704699888 -> 1574704699360
	1574704699888 [label=NativeBatchNormBackward0]
	1574704699984 -> 1574704699888
	1574704699984 [label=ConvolutionBackward0]
	1574704700176 -> 1574704699984
	1574704700176 [label=ReluBackward0]
	1574704700320 -> 1574704700176
	1574704700320 [label=NativeBatchNormBackward0]
	1574704700416 -> 1574704700320
	1574704700416 [label=CatBackward0]
	1574704488000 -> 1574704700416
	1574704487952 -> 1574704700416
	1574704487904 -> 1574704700416
	1574704488048 -> 1574704700416
	1574704488096 -> 1574704700416
	1574704488144 -> 1574704700416
	1574704488192 -> 1574704700416
	1574704488240 -> 1574704700416
	1574704488288 -> 1574704700416
	1574704488336 -> 1574704700416
	1574704488384 -> 1574704700416
	1574704488432 -> 1574704700416
	1574704488480 -> 1574704700416
	1574704488528 -> 1574704700416
	1574704488576 -> 1574704700416
	1574704488624 -> 1574704700416
	1574704488672 -> 1574704700416
	1574704488720 -> 1574704700416
	1574704488768 -> 1574704700416
	1574704488816 -> 1574704700416
	1574704488864 -> 1574704700416
	1574704488912 -> 1574704700416
	1574704488960 -> 1574704700416
	1574704489008 -> 1574704700416
	1574704489056 -> 1574704700416
	1574704489104 -> 1574704700416
	1574704489152 -> 1574704700416
	1574704489200 -> 1574704700416
	1574704489248 -> 1574704700416
	1574704489296 -> 1574704700416
	1574704489344 -> 1574704700416
	1574704700368 -> 1574704700320
	1574606296064 [label="features.denseblock3.denselayer31.norm1.weight
 (1824)" fillcolor=lightblue]
	1574606296064 -> 1574704700368
	1574704700368 [label=AccumulateGrad]
	1574704700224 -> 1574704700320
	1574606296144 [label="features.denseblock3.denselayer31.norm1.bias
 (1824)" fillcolor=lightblue]
	1574606296144 -> 1574704700224
	1574704700224 [label=AccumulateGrad]
	1574704700128 -> 1574704699984
	1574606296624 [label="features.denseblock3.denselayer31.conv1.weight
 (192, 1824, 1, 1)" fillcolor=lightblue]
	1574606296624 -> 1574704700128
	1574704700128 [label=AccumulateGrad]
	1574704699696 -> 1574704699888
	1574606296704 [label="features.denseblock3.denselayer31.norm2.weight
 (192)" fillcolor=lightblue]
	1574606296704 -> 1574704699696
	1574704699696 [label=AccumulateGrad]
	1574704699456 -> 1574704699888
	1574606296784 [label="features.denseblock3.denselayer31.norm2.bias
 (192)" fillcolor=lightblue]
	1574606296784 -> 1574704699456
	1574704699456 [label=AccumulateGrad]
	1574704699504 -> 1574704489392
	1574606297264 [label="features.denseblock3.denselayer31.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606297264 -> 1574704699504
	1574704699504 [label=AccumulateGrad]
	1574704489440 -> 1574704487808
	1574704489440 [label=ConvolutionBackward0]
	1574704699936 -> 1574704489440
	1574704699936 [label=ReluBackward0]
	1574704700464 -> 1574704699936
	1574704700464 [label=NativeBatchNormBackward0]
	1574704700560 -> 1574704700464
	1574704700560 [label=ConvolutionBackward0]
	1574704700752 -> 1574704700560
	1574704700752 [label=ReluBackward0]
	1574704700896 -> 1574704700752
	1574704700896 [label=NativeBatchNormBackward0]
	1574704700992 -> 1574704700896
	1574704700992 [label=CatBackward0]
	1574704488000 -> 1574704700992
	1574704487952 -> 1574704700992
	1574704487904 -> 1574704700992
	1574704488048 -> 1574704700992
	1574704488096 -> 1574704700992
	1574704488144 -> 1574704700992
	1574704488192 -> 1574704700992
	1574704488240 -> 1574704700992
	1574704488288 -> 1574704700992
	1574704488336 -> 1574704700992
	1574704488384 -> 1574704700992
	1574704488432 -> 1574704700992
	1574704488480 -> 1574704700992
	1574704488528 -> 1574704700992
	1574704488576 -> 1574704700992
	1574704488624 -> 1574704700992
	1574704488672 -> 1574704700992
	1574704488720 -> 1574704700992
	1574704488768 -> 1574704700992
	1574704488816 -> 1574704700992
	1574704488864 -> 1574704700992
	1574704488912 -> 1574704700992
	1574704488960 -> 1574704700992
	1574704489008 -> 1574704700992
	1574704489056 -> 1574704700992
	1574704489104 -> 1574704700992
	1574704489152 -> 1574704700992
	1574704489200 -> 1574704700992
	1574704489248 -> 1574704700992
	1574704489296 -> 1574704700992
	1574704489344 -> 1574704700992
	1574704489392 -> 1574704700992
	1574704700944 -> 1574704700896
	1574606297344 [label="features.denseblock3.denselayer32.norm1.weight
 (1872)" fillcolor=lightblue]
	1574606297344 -> 1574704700944
	1574704700944 [label=AccumulateGrad]
	1574704700800 -> 1574704700896
	1574606297424 [label="features.denseblock3.denselayer32.norm1.bias
 (1872)" fillcolor=lightblue]
	1574606297424 -> 1574704700800
	1574704700800 [label=AccumulateGrad]
	1574704700704 -> 1574704700560
	1574606297904 [label="features.denseblock3.denselayer32.conv1.weight
 (192, 1872, 1, 1)" fillcolor=lightblue]
	1574606297904 -> 1574704700704
	1574704700704 [label=AccumulateGrad]
	1574704700272 -> 1574704700464
	1574606297984 [label="features.denseblock3.denselayer32.norm2.weight
 (192)" fillcolor=lightblue]
	1574606297984 -> 1574704700272
	1574704700272 [label=AccumulateGrad]
	1574704700032 -> 1574704700464
	1574606298064 [label="features.denseblock3.denselayer32.norm2.bias
 (192)" fillcolor=lightblue]
	1574606298064 -> 1574704700032
	1574704700032 [label=AccumulateGrad]
	1574704700080 -> 1574704489440
	1574606298544 [label="features.denseblock3.denselayer32.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606298544 -> 1574704700080
	1574704700080 [label=AccumulateGrad]
	1574704489488 -> 1574704487808
	1574704489488 [label=ConvolutionBackward0]
	1574704700512 -> 1574704489488
	1574704700512 [label=ReluBackward0]
	1574704701040 -> 1574704700512
	1574704701040 [label=NativeBatchNormBackward0]
	1574704701136 -> 1574704701040
	1574704701136 [label=ConvolutionBackward0]
	1574704701328 -> 1574704701136
	1574704701328 [label=ReluBackward0]
	1574704701472 -> 1574704701328
	1574704701472 [label=NativeBatchNormBackward0]
	1574704701568 -> 1574704701472
	1574704701568 [label=CatBackward0]
	1574704488000 -> 1574704701568
	1574704487952 -> 1574704701568
	1574704487904 -> 1574704701568
	1574704488048 -> 1574704701568
	1574704488096 -> 1574704701568
	1574704488144 -> 1574704701568
	1574704488192 -> 1574704701568
	1574704488240 -> 1574704701568
	1574704488288 -> 1574704701568
	1574704488336 -> 1574704701568
	1574704488384 -> 1574704701568
	1574704488432 -> 1574704701568
	1574704488480 -> 1574704701568
	1574704488528 -> 1574704701568
	1574704488576 -> 1574704701568
	1574704488624 -> 1574704701568
	1574704488672 -> 1574704701568
	1574704488720 -> 1574704701568
	1574704488768 -> 1574704701568
	1574704488816 -> 1574704701568
	1574704488864 -> 1574704701568
	1574704488912 -> 1574704701568
	1574704488960 -> 1574704701568
	1574704489008 -> 1574704701568
	1574704489056 -> 1574704701568
	1574704489104 -> 1574704701568
	1574704489152 -> 1574704701568
	1574704489200 -> 1574704701568
	1574704489248 -> 1574704701568
	1574704489296 -> 1574704701568
	1574704489344 -> 1574704701568
	1574704489392 -> 1574704701568
	1574704489440 -> 1574704701568
	1574704701520 -> 1574704701472
	1574606298624 [label="features.denseblock3.denselayer33.norm1.weight
 (1920)" fillcolor=lightblue]
	1574606298624 -> 1574704701520
	1574704701520 [label=AccumulateGrad]
	1574704701376 -> 1574704701472
	1574606298704 [label="features.denseblock3.denselayer33.norm1.bias
 (1920)" fillcolor=lightblue]
	1574606298704 -> 1574704701376
	1574704701376 [label=AccumulateGrad]
	1574704701280 -> 1574704701136
	1574606299184 [label="features.denseblock3.denselayer33.conv1.weight
 (192, 1920, 1, 1)" fillcolor=lightblue]
	1574606299184 -> 1574704701280
	1574704701280 [label=AccumulateGrad]
	1574704700848 -> 1574704701040
	1574606299264 [label="features.denseblock3.denselayer33.norm2.weight
 (192)" fillcolor=lightblue]
	1574606299264 -> 1574704700848
	1574704700848 [label=AccumulateGrad]
	1574704700608 -> 1574704701040
	1574606299344 [label="features.denseblock3.denselayer33.norm2.bias
 (192)" fillcolor=lightblue]
	1574606299344 -> 1574704700608
	1574704700608 [label=AccumulateGrad]
	1574704700656 -> 1574704489488
	1574606299824 [label="features.denseblock3.denselayer33.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606299824 -> 1574704700656
	1574704700656 [label=AccumulateGrad]
	1574704489536 -> 1574704487808
	1574704489536 [label=ConvolutionBackward0]
	1574704701088 -> 1574704489536
	1574704701088 [label=ReluBackward0]
	1574704701616 -> 1574704701088
	1574704701616 [label=NativeBatchNormBackward0]
	1574704701712 -> 1574704701616
	1574704701712 [label=ConvolutionBackward0]
	1574704701904 -> 1574704701712
	1574704701904 [label=ReluBackward0]
	1574704702048 -> 1574704701904
	1574704702048 [label=NativeBatchNormBackward0]
	1574704702144 -> 1574704702048
	1574704702144 [label=CatBackward0]
	1574704488000 -> 1574704702144
	1574704487952 -> 1574704702144
	1574704487904 -> 1574704702144
	1574704488048 -> 1574704702144
	1574704488096 -> 1574704702144
	1574704488144 -> 1574704702144
	1574704488192 -> 1574704702144
	1574704488240 -> 1574704702144
	1574704488288 -> 1574704702144
	1574704488336 -> 1574704702144
	1574704488384 -> 1574704702144
	1574704488432 -> 1574704702144
	1574704488480 -> 1574704702144
	1574704488528 -> 1574704702144
	1574704488576 -> 1574704702144
	1574704488624 -> 1574704702144
	1574704488672 -> 1574704702144
	1574704488720 -> 1574704702144
	1574704488768 -> 1574704702144
	1574704488816 -> 1574704702144
	1574704488864 -> 1574704702144
	1574704488912 -> 1574704702144
	1574704488960 -> 1574704702144
	1574704489008 -> 1574704702144
	1574704489056 -> 1574704702144
	1574704489104 -> 1574704702144
	1574704489152 -> 1574704702144
	1574704489200 -> 1574704702144
	1574704489248 -> 1574704702144
	1574704489296 -> 1574704702144
	1574704489344 -> 1574704702144
	1574704489392 -> 1574704702144
	1574704489440 -> 1574704702144
	1574704489488 -> 1574704702144
	1574704702096 -> 1574704702048
	1574606299904 [label="features.denseblock3.denselayer34.norm1.weight
 (1968)" fillcolor=lightblue]
	1574606299904 -> 1574704702096
	1574704702096 [label=AccumulateGrad]
	1574704701952 -> 1574704702048
	1574606299984 [label="features.denseblock3.denselayer34.norm1.bias
 (1968)" fillcolor=lightblue]
	1574606299984 -> 1574704701952
	1574704701952 [label=AccumulateGrad]
	1574704701856 -> 1574704701712
	1574606300464 [label="features.denseblock3.denselayer34.conv1.weight
 (192, 1968, 1, 1)" fillcolor=lightblue]
	1574606300464 -> 1574704701856
	1574704701856 [label=AccumulateGrad]
	1574704701424 -> 1574704701616
	1574606300544 [label="features.denseblock3.denselayer34.norm2.weight
 (192)" fillcolor=lightblue]
	1574606300544 -> 1574704701424
	1574704701424 [label=AccumulateGrad]
	1574704701184 -> 1574704701616
	1574606300624 [label="features.denseblock3.denselayer34.norm2.bias
 (192)" fillcolor=lightblue]
	1574606300624 -> 1574704701184
	1574704701184 [label=AccumulateGrad]
	1574704701232 -> 1574704489536
	1574606301104 [label="features.denseblock3.denselayer34.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606301104 -> 1574704701232
	1574704701232 [label=AccumulateGrad]
	1574704489584 -> 1574704487808
	1574704489584 [label=ConvolutionBackward0]
	1574704701664 -> 1574704489584
	1574704701664 [label=ReluBackward0]
	1574704702192 -> 1574704701664
	1574704702192 [label=NativeBatchNormBackward0]
	1574704702288 -> 1574704702192
	1574704702288 [label=ConvolutionBackward0]
	1574704702480 -> 1574704702288
	1574704702480 [label=ReluBackward0]
	1574704702624 -> 1574704702480
	1574704702624 [label=NativeBatchNormBackward0]
	1574704702720 -> 1574704702624
	1574704702720 [label=CatBackward0]
	1574704488000 -> 1574704702720
	1574704487952 -> 1574704702720
	1574704487904 -> 1574704702720
	1574704488048 -> 1574704702720
	1574704488096 -> 1574704702720
	1574704488144 -> 1574704702720
	1574704488192 -> 1574704702720
	1574704488240 -> 1574704702720
	1574704488288 -> 1574704702720
	1574704488336 -> 1574704702720
	1574704488384 -> 1574704702720
	1574704488432 -> 1574704702720
	1574704488480 -> 1574704702720
	1574704488528 -> 1574704702720
	1574704488576 -> 1574704702720
	1574704488624 -> 1574704702720
	1574704488672 -> 1574704702720
	1574704488720 -> 1574704702720
	1574704488768 -> 1574704702720
	1574704488816 -> 1574704702720
	1574704488864 -> 1574704702720
	1574704488912 -> 1574704702720
	1574704488960 -> 1574704702720
	1574704489008 -> 1574704702720
	1574704489056 -> 1574704702720
	1574704489104 -> 1574704702720
	1574704489152 -> 1574704702720
	1574704489200 -> 1574704702720
	1574704489248 -> 1574704702720
	1574704489296 -> 1574704702720
	1574704489344 -> 1574704702720
	1574704489392 -> 1574704702720
	1574704489440 -> 1574704702720
	1574704489488 -> 1574704702720
	1574704489536 -> 1574704702720
	1574704702672 -> 1574704702624
	1574606301184 [label="features.denseblock3.denselayer35.norm1.weight
 (2016)" fillcolor=lightblue]
	1574606301184 -> 1574704702672
	1574704702672 [label=AccumulateGrad]
	1574704702528 -> 1574704702624
	1574606301264 [label="features.denseblock3.denselayer35.norm1.bias
 (2016)" fillcolor=lightblue]
	1574606301264 -> 1574704702528
	1574704702528 [label=AccumulateGrad]
	1574704702432 -> 1574704702288
	1574606301744 [label="features.denseblock3.denselayer35.conv1.weight
 (192, 2016, 1, 1)" fillcolor=lightblue]
	1574606301744 -> 1574704702432
	1574704702432 [label=AccumulateGrad]
	1574704702000 -> 1574704702192
	1574606301824 [label="features.denseblock3.denselayer35.norm2.weight
 (192)" fillcolor=lightblue]
	1574606301824 -> 1574704702000
	1574704702000 [label=AccumulateGrad]
	1574704701760 -> 1574704702192
	1574606301904 [label="features.denseblock3.denselayer35.norm2.bias
 (192)" fillcolor=lightblue]
	1574606301904 -> 1574704701760
	1574704701760 [label=AccumulateGrad]
	1574704701808 -> 1574704489584
	1574606302384 [label="features.denseblock3.denselayer35.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606302384 -> 1574704701808
	1574704701808 [label=AccumulateGrad]
	1574704489632 -> 1574704487808
	1574704489632 [label=ConvolutionBackward0]
	1574704702240 -> 1574704489632
	1574704702240 [label=ReluBackward0]
	1574704702768 -> 1574704702240
	1574704702768 [label=NativeBatchNormBackward0]
	1574704702864 -> 1574704702768
	1574704702864 [label=ConvolutionBackward0]
	1574704703056 -> 1574704702864
	1574704703056 [label=ReluBackward0]
	1574704703200 -> 1574704703056
	1574704703200 [label=NativeBatchNormBackward0]
	1574704703296 -> 1574704703200
	1574704703296 [label=CatBackward0]
	1574704488000 -> 1574704703296
	1574704487952 -> 1574704703296
	1574704487904 -> 1574704703296
	1574704488048 -> 1574704703296
	1574704488096 -> 1574704703296
	1574704488144 -> 1574704703296
	1574704488192 -> 1574704703296
	1574704488240 -> 1574704703296
	1574704488288 -> 1574704703296
	1574704488336 -> 1574704703296
	1574704488384 -> 1574704703296
	1574704488432 -> 1574704703296
	1574704488480 -> 1574704703296
	1574704488528 -> 1574704703296
	1574704488576 -> 1574704703296
	1574704488624 -> 1574704703296
	1574704488672 -> 1574704703296
	1574704488720 -> 1574704703296
	1574704488768 -> 1574704703296
	1574704488816 -> 1574704703296
	1574704488864 -> 1574704703296
	1574704488912 -> 1574704703296
	1574704488960 -> 1574704703296
	1574704489008 -> 1574704703296
	1574704489056 -> 1574704703296
	1574704489104 -> 1574704703296
	1574704489152 -> 1574704703296
	1574704489200 -> 1574704703296
	1574704489248 -> 1574704703296
	1574704489296 -> 1574704703296
	1574704489344 -> 1574704703296
	1574704489392 -> 1574704703296
	1574704489440 -> 1574704703296
	1574704489488 -> 1574704703296
	1574704489536 -> 1574704703296
	1574704489584 -> 1574704703296
	1574704703248 -> 1574704703200
	1574606302464 [label="features.denseblock3.denselayer36.norm1.weight
 (2064)" fillcolor=lightblue]
	1574606302464 -> 1574704703248
	1574704703248 [label=AccumulateGrad]
	1574704703104 -> 1574704703200
	1574606302544 [label="features.denseblock3.denselayer36.norm1.bias
 (2064)" fillcolor=lightblue]
	1574606302544 -> 1574704703104
	1574704703104 [label=AccumulateGrad]
	1574704703008 -> 1574704702864
	1574606303024 [label="features.denseblock3.denselayer36.conv1.weight
 (192, 2064, 1, 1)" fillcolor=lightblue]
	1574606303024 -> 1574704703008
	1574704703008 [label=AccumulateGrad]
	1574704702576 -> 1574704702768
	1574606303104 [label="features.denseblock3.denselayer36.norm2.weight
 (192)" fillcolor=lightblue]
	1574606303104 -> 1574704702576
	1574704702576 [label=AccumulateGrad]
	1574704702336 -> 1574704702768
	1574606303184 [label="features.denseblock3.denselayer36.norm2.bias
 (192)" fillcolor=lightblue]
	1574606303184 -> 1574704702336
	1574704702336 [label=AccumulateGrad]
	1574704702384 -> 1574704489632
	1574606303664 [label="features.denseblock3.denselayer36.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606303664 -> 1574704702384
	1574704702384 [label=AccumulateGrad]
	1574704487760 -> 1574704487712
	1574606303584 [label="features.transition3.norm.weight
 (2112)" fillcolor=lightblue]
	1574606303584 -> 1574704487760
	1574704487760 [label=AccumulateGrad]
	1574704487616 -> 1574704487712
	1574606303744 [label="features.transition3.norm.bias
 (2112)" fillcolor=lightblue]
	1574606303744 -> 1574704487616
	1574704487616 [label=AccumulateGrad]
	1574704487520 -> 1574704487472
	1574606304224 [label="features.transition3.conv.weight
 (1056, 2112, 1, 1)" fillcolor=lightblue]
	1574606304224 -> 1574704487520
	1574704487520 [label=AccumulateGrad]
	1574704486176 -> 1574704486032
	1574704486176 [label=ConvolutionBackward0]
	1574704489680 -> 1574704486176
	1574704489680 [label=ReluBackward0]
	1574704487664 -> 1574704489680
	1574704487664 [label=NativeBatchNormBackward0]
	1574704702816 -> 1574704487664
	1574704702816 [label=ConvolutionBackward0]
	1574704703152 -> 1574704702816
	1574704703152 [label=ReluBackward0]
	1574704703536 -> 1574704703152
	1574704703536 [label=NativeBatchNormBackward0]
	1574704703632 -> 1574704703536
	1574704703632 [label=CatBackward0]
	1574704486224 -> 1574704703632
	1574704703584 -> 1574704703536
	1574606304304 [label="features.denseblock4.denselayer1.norm1.weight
 (1056)" fillcolor=lightblue]
	1574606304304 -> 1574704703584
	1574704703584 [label=AccumulateGrad]
	1574704703440 -> 1574704703536
	1574606304384 [label="features.denseblock4.denselayer1.norm1.bias
 (1056)" fillcolor=lightblue]
	1574606304384 -> 1574704703440
	1574704703440 [label=AccumulateGrad]
	1574704703344 -> 1574704702816
	1574606304864 [label="features.denseblock4.denselayer1.conv1.weight
 (192, 1056, 1, 1)" fillcolor=lightblue]
	1574606304864 -> 1574704703344
	1574704703344 [label=AccumulateGrad]
	1574704702960 -> 1574704487664
	1574606304944 [label="features.denseblock4.denselayer1.norm2.weight
 (192)" fillcolor=lightblue]
	1574606304944 -> 1574704702960
	1574704702960 [label=AccumulateGrad]
	1574704693744 -> 1574704487664
	1574606305024 [label="features.denseblock4.denselayer1.norm2.bias
 (192)" fillcolor=lightblue]
	1574606305024 -> 1574704693744
	1574704693744 [label=AccumulateGrad]
	1574704487376 -> 1574704486176
	1574606305504 [label="features.denseblock4.denselayer1.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606305504 -> 1574704487376
	1574704487376 [label=AccumulateGrad]
	1574704486128 -> 1574704486032
	1574704486128 [label=ConvolutionBackward0]
	1574704487856 -> 1574704486128
	1574704487856 [label=ReluBackward0]
	1574704703680 -> 1574704487856
	1574704703680 [label=NativeBatchNormBackward0]
	1574704703776 -> 1574704703680
	1574704703776 [label=ConvolutionBackward0]
	1574704703968 -> 1574704703776
	1574704703968 [label=ReluBackward0]
	1574704704112 -> 1574704703968
	1574704704112 [label=NativeBatchNormBackward0]
	1574704704208 -> 1574704704112
	1574704704208 [label=CatBackward0]
	1574704486224 -> 1574704704208
	1574704486176 -> 1574704704208
	1574704704160 -> 1574704704112
	1574606305584 [label="features.denseblock4.denselayer2.norm1.weight
 (1104)" fillcolor=lightblue]
	1574606305584 -> 1574704704160
	1574704704160 [label=AccumulateGrad]
	1574704704016 -> 1574704704112
	1574606305664 [label="features.denseblock4.denselayer2.norm1.bias
 (1104)" fillcolor=lightblue]
	1574606305664 -> 1574704704016
	1574704704016 [label=AccumulateGrad]
	1574704703920 -> 1574704703776
	1574606306144 [label="features.denseblock4.denselayer2.conv1.weight
 (192, 1104, 1, 1)" fillcolor=lightblue]
	1574606306144 -> 1574704703920
	1574704703920 [label=AccumulateGrad]
	1574704703392 -> 1574704703680
	1574606306224 [label="features.denseblock4.denselayer2.norm2.weight
 (192)" fillcolor=lightblue]
	1574606306224 -> 1574704703392
	1574704703392 [label=AccumulateGrad]
	1574704702912 -> 1574704703680
	1574606306304 [label="features.denseblock4.denselayer2.norm2.bias
 (192)" fillcolor=lightblue]
	1574606306304 -> 1574704702912
	1574704702912 [label=AccumulateGrad]
	1574704487424 -> 1574704486128
	1574606306784 [label="features.denseblock4.denselayer2.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606306784 -> 1574704487424
	1574704487424 [label=AccumulateGrad]
	1574704486272 -> 1574704486032
	1574704486272 [label=ConvolutionBackward0]
	1574704703728 -> 1574704486272
	1574704703728 [label=ReluBackward0]
	1574704704256 -> 1574704703728
	1574704704256 [label=NativeBatchNormBackward0]
	1574704704352 -> 1574704704256
	1574704704352 [label=ConvolutionBackward0]
	1574704704544 -> 1574704704352
	1574704704544 [label=ReluBackward0]
	1574704704688 -> 1574704704544
	1574704704688 [label=NativeBatchNormBackward0]
	1574704704784 -> 1574704704688
	1574704704784 [label=CatBackward0]
	1574704486224 -> 1574704704784
	1574704486176 -> 1574704704784
	1574704486128 -> 1574704704784
	1574704704736 -> 1574704704688
	1574606306864 [label="features.denseblock4.denselayer3.norm1.weight
 (1152)" fillcolor=lightblue]
	1574606306864 -> 1574704704736
	1574704704736 [label=AccumulateGrad]
	1574704704592 -> 1574704704688
	1574606306944 [label="features.denseblock4.denselayer3.norm1.bias
 (1152)" fillcolor=lightblue]
	1574606306944 -> 1574704704592
	1574704704592 [label=AccumulateGrad]
	1574704704496 -> 1574704704352
	1574606586016 [label="features.denseblock4.denselayer3.conv1.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	1574606586016 -> 1574704704496
	1574704704496 [label=AccumulateGrad]
	1574704704064 -> 1574704704256
	1574606586096 [label="features.denseblock4.denselayer3.norm2.weight
 (192)" fillcolor=lightblue]
	1574606586096 -> 1574704704064
	1574704704064 [label=AccumulateGrad]
	1574704703824 -> 1574704704256
	1574606586176 [label="features.denseblock4.denselayer3.norm2.bias
 (192)" fillcolor=lightblue]
	1574606586176 -> 1574704703824
	1574704703824 [label=AccumulateGrad]
	1574704703872 -> 1574704486272
	1574606586656 [label="features.denseblock4.denselayer3.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606586656 -> 1574704703872
	1574704703872 [label=AccumulateGrad]
	1574704486320 -> 1574704486032
	1574704486320 [label=ConvolutionBackward0]
	1574704704304 -> 1574704486320
	1574704704304 [label=ReluBackward0]
	1574704704832 -> 1574704704304
	1574704704832 [label=NativeBatchNormBackward0]
	1574704704928 -> 1574704704832
	1574704704928 [label=ConvolutionBackward0]
	1574704705120 -> 1574704704928
	1574704705120 [label=ReluBackward0]
	1574704705264 -> 1574704705120
	1574704705264 [label=NativeBatchNormBackward0]
	1574704705360 -> 1574704705264
	1574704705360 [label=CatBackward0]
	1574704486224 -> 1574704705360
	1574704486176 -> 1574704705360
	1574704486128 -> 1574704705360
	1574704486272 -> 1574704705360
	1574704705312 -> 1574704705264
	1574606586736 [label="features.denseblock4.denselayer4.norm1.weight
 (1200)" fillcolor=lightblue]
	1574606586736 -> 1574704705312
	1574704705312 [label=AccumulateGrad]
	1574704705168 -> 1574704705264
	1574606586816 [label="features.denseblock4.denselayer4.norm1.bias
 (1200)" fillcolor=lightblue]
	1574606586816 -> 1574704705168
	1574704705168 [label=AccumulateGrad]
	1574704705072 -> 1574704704928
	1574606587296 [label="features.denseblock4.denselayer4.conv1.weight
 (192, 1200, 1, 1)" fillcolor=lightblue]
	1574606587296 -> 1574704705072
	1574704705072 [label=AccumulateGrad]
	1574704704640 -> 1574704704832
	1574606587376 [label="features.denseblock4.denselayer4.norm2.weight
 (192)" fillcolor=lightblue]
	1574606587376 -> 1574704704640
	1574704704640 [label=AccumulateGrad]
	1574704704400 -> 1574704704832
	1574606587456 [label="features.denseblock4.denselayer4.norm2.bias
 (192)" fillcolor=lightblue]
	1574606587456 -> 1574704704400
	1574704704400 [label=AccumulateGrad]
	1574704704448 -> 1574704486320
	1574606587936 [label="features.denseblock4.denselayer4.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606587936 -> 1574704704448
	1574704704448 [label=AccumulateGrad]
	1574704486368 -> 1574704486032
	1574704486368 [label=ConvolutionBackward0]
	1574704704880 -> 1574704486368
	1574704704880 [label=ReluBackward0]
	1574704705408 -> 1574704704880
	1574704705408 [label=NativeBatchNormBackward0]
	1574704705504 -> 1574704705408
	1574704705504 [label=ConvolutionBackward0]
	1574704705696 -> 1574704705504
	1574704705696 [label=ReluBackward0]
	1574704705840 -> 1574704705696
	1574704705840 [label=NativeBatchNormBackward0]
	1574704705936 -> 1574704705840
	1574704705936 [label=CatBackward0]
	1574704486224 -> 1574704705936
	1574704486176 -> 1574704705936
	1574704486128 -> 1574704705936
	1574704486272 -> 1574704705936
	1574704486320 -> 1574704705936
	1574704705888 -> 1574704705840
	1574606588016 [label="features.denseblock4.denselayer5.norm1.weight
 (1248)" fillcolor=lightblue]
	1574606588016 -> 1574704705888
	1574704705888 [label=AccumulateGrad]
	1574704705744 -> 1574704705840
	1574606588096 [label="features.denseblock4.denselayer5.norm1.bias
 (1248)" fillcolor=lightblue]
	1574606588096 -> 1574704705744
	1574704705744 [label=AccumulateGrad]
	1574704705648 -> 1574704705504
	1574606588576 [label="features.denseblock4.denselayer5.conv1.weight
 (192, 1248, 1, 1)" fillcolor=lightblue]
	1574606588576 -> 1574704705648
	1574704705648 [label=AccumulateGrad]
	1574704705216 -> 1574704705408
	1574606588656 [label="features.denseblock4.denselayer5.norm2.weight
 (192)" fillcolor=lightblue]
	1574606588656 -> 1574704705216
	1574704705216 [label=AccumulateGrad]
	1574704704976 -> 1574704705408
	1574606588736 [label="features.denseblock4.denselayer5.norm2.bias
 (192)" fillcolor=lightblue]
	1574606588736 -> 1574704704976
	1574704704976 [label=AccumulateGrad]
	1574704705024 -> 1574704486368
	1574606589216 [label="features.denseblock4.denselayer5.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606589216 -> 1574704705024
	1574704705024 [label=AccumulateGrad]
	1574704486416 -> 1574704486032
	1574704486416 [label=ConvolutionBackward0]
	1574704705456 -> 1574704486416
	1574704705456 [label=ReluBackward0]
	1574704705984 -> 1574704705456
	1574704705984 [label=NativeBatchNormBackward0]
	1574704706080 -> 1574704705984
	1574704706080 [label=ConvolutionBackward0]
	1574704706272 -> 1574704706080
	1574704706272 [label=ReluBackward0]
	1574704706416 -> 1574704706272
	1574704706416 [label=NativeBatchNormBackward0]
	1574704706512 -> 1574704706416
	1574704706512 [label=CatBackward0]
	1574704486224 -> 1574704706512
	1574704486176 -> 1574704706512
	1574704486128 -> 1574704706512
	1574704486272 -> 1574704706512
	1574704486320 -> 1574704706512
	1574704486368 -> 1574704706512
	1574704706464 -> 1574704706416
	1574606589296 [label="features.denseblock4.denselayer6.norm1.weight
 (1296)" fillcolor=lightblue]
	1574606589296 -> 1574704706464
	1574704706464 [label=AccumulateGrad]
	1574704706320 -> 1574704706416
	1574606589376 [label="features.denseblock4.denselayer6.norm1.bias
 (1296)" fillcolor=lightblue]
	1574606589376 -> 1574704706320
	1574704706320 [label=AccumulateGrad]
	1574704706224 -> 1574704706080
	1574606589856 [label="features.denseblock4.denselayer6.conv1.weight
 (192, 1296, 1, 1)" fillcolor=lightblue]
	1574606589856 -> 1574704706224
	1574704706224 [label=AccumulateGrad]
	1574704705792 -> 1574704705984
	1574606589936 [label="features.denseblock4.denselayer6.norm2.weight
 (192)" fillcolor=lightblue]
	1574606589936 -> 1574704705792
	1574704705792 [label=AccumulateGrad]
	1574704705552 -> 1574704705984
	1574606590016 [label="features.denseblock4.denselayer6.norm2.bias
 (192)" fillcolor=lightblue]
	1574606590016 -> 1574704705552
	1574704705552 [label=AccumulateGrad]
	1574704705600 -> 1574704486416
	1574606590496 [label="features.denseblock4.denselayer6.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606590496 -> 1574704705600
	1574704705600 [label=AccumulateGrad]
	1574704486464 -> 1574704486032
	1574704486464 [label=ConvolutionBackward0]
	1574704706032 -> 1574704486464
	1574704706032 [label=ReluBackward0]
	1574704706560 -> 1574704706032
	1574704706560 [label=NativeBatchNormBackward0]
	1574704706656 -> 1574704706560
	1574704706656 [label=ConvolutionBackward0]
	1574704706848 -> 1574704706656
	1574704706848 [label=ReluBackward0]
	1574704706992 -> 1574704706848
	1574704706992 [label=NativeBatchNormBackward0]
	1574704707088 -> 1574704706992
	1574704707088 [label=CatBackward0]
	1574704486224 -> 1574704707088
	1574704486176 -> 1574704707088
	1574704486128 -> 1574704707088
	1574704486272 -> 1574704707088
	1574704486320 -> 1574704707088
	1574704486368 -> 1574704707088
	1574704486416 -> 1574704707088
	1574704707040 -> 1574704706992
	1574606590576 [label="features.denseblock4.denselayer7.norm1.weight
 (1344)" fillcolor=lightblue]
	1574606590576 -> 1574704707040
	1574704707040 [label=AccumulateGrad]
	1574704706896 -> 1574704706992
	1574606590656 [label="features.denseblock4.denselayer7.norm1.bias
 (1344)" fillcolor=lightblue]
	1574606590656 -> 1574704706896
	1574704706896 [label=AccumulateGrad]
	1574704706800 -> 1574704706656
	1574606591136 [label="features.denseblock4.denselayer7.conv1.weight
 (192, 1344, 1, 1)" fillcolor=lightblue]
	1574606591136 -> 1574704706800
	1574704706800 [label=AccumulateGrad]
	1574704706368 -> 1574704706560
	1574606591216 [label="features.denseblock4.denselayer7.norm2.weight
 (192)" fillcolor=lightblue]
	1574606591216 -> 1574704706368
	1574704706368 [label=AccumulateGrad]
	1574704706128 -> 1574704706560
	1574606591296 [label="features.denseblock4.denselayer7.norm2.bias
 (192)" fillcolor=lightblue]
	1574606591296 -> 1574704706128
	1574704706128 [label=AccumulateGrad]
	1574704706176 -> 1574704486464
	1574606591776 [label="features.denseblock4.denselayer7.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606591776 -> 1574704706176
	1574704706176 [label=AccumulateGrad]
	1574704486512 -> 1574704486032
	1574704486512 [label=ConvolutionBackward0]
	1574704706608 -> 1574704486512
	1574704706608 [label=ReluBackward0]
	1574704707136 -> 1574704706608
	1574704707136 [label=NativeBatchNormBackward0]
	1574704707232 -> 1574704707136
	1574704707232 [label=ConvolutionBackward0]
	1574704707424 -> 1574704707232
	1574704707424 [label=ReluBackward0]
	1574704707568 -> 1574704707424
	1574704707568 [label=NativeBatchNormBackward0]
	1574704707664 -> 1574704707568
	1574704707664 [label=CatBackward0]
	1574704486224 -> 1574704707664
	1574704486176 -> 1574704707664
	1574704486128 -> 1574704707664
	1574704486272 -> 1574704707664
	1574704486320 -> 1574704707664
	1574704486368 -> 1574704707664
	1574704486416 -> 1574704707664
	1574704486464 -> 1574704707664
	1574704707616 -> 1574704707568
	1574606591856 [label="features.denseblock4.denselayer8.norm1.weight
 (1392)" fillcolor=lightblue]
	1574606591856 -> 1574704707616
	1574704707616 [label=AccumulateGrad]
	1574704707472 -> 1574704707568
	1574606591936 [label="features.denseblock4.denselayer8.norm1.bias
 (1392)" fillcolor=lightblue]
	1574606591936 -> 1574704707472
	1574704707472 [label=AccumulateGrad]
	1574704707376 -> 1574704707232
	1574606592416 [label="features.denseblock4.denselayer8.conv1.weight
 (192, 1392, 1, 1)" fillcolor=lightblue]
	1574606592416 -> 1574704707376
	1574704707376 [label=AccumulateGrad]
	1574704706944 -> 1574704707136
	1574606592496 [label="features.denseblock4.denselayer8.norm2.weight
 (192)" fillcolor=lightblue]
	1574606592496 -> 1574704706944
	1574704706944 [label=AccumulateGrad]
	1574704706704 -> 1574704707136
	1574606592576 [label="features.denseblock4.denselayer8.norm2.bias
 (192)" fillcolor=lightblue]
	1574606592576 -> 1574704706704
	1574704706704 [label=AccumulateGrad]
	1574704706752 -> 1574704486512
	1574606593056 [label="features.denseblock4.denselayer8.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606593056 -> 1574704706752
	1574704706752 [label=AccumulateGrad]
	1574704486560 -> 1574704486032
	1574704486560 [label=ConvolutionBackward0]
	1574704707184 -> 1574704486560
	1574704707184 [label=ReluBackward0]
	1574704707712 -> 1574704707184
	1574704707712 [label=NativeBatchNormBackward0]
	1574704707808 -> 1574704707712
	1574704707808 [label=ConvolutionBackward0]
	1574704708000 -> 1574704707808
	1574704708000 [label=ReluBackward0]
	1574704708144 -> 1574704708000
	1574704708144 [label=NativeBatchNormBackward0]
	1574704708240 -> 1574704708144
	1574704708240 [label=CatBackward0]
	1574704486224 -> 1574704708240
	1574704486176 -> 1574704708240
	1574704486128 -> 1574704708240
	1574704486272 -> 1574704708240
	1574704486320 -> 1574704708240
	1574704486368 -> 1574704708240
	1574704486416 -> 1574704708240
	1574704486464 -> 1574704708240
	1574704486512 -> 1574704708240
	1574704708192 -> 1574704708144
	1574606593136 [label="features.denseblock4.denselayer9.norm1.weight
 (1440)" fillcolor=lightblue]
	1574606593136 -> 1574704708192
	1574704708192 [label=AccumulateGrad]
	1574704708048 -> 1574704708144
	1574606593216 [label="features.denseblock4.denselayer9.norm1.bias
 (1440)" fillcolor=lightblue]
	1574606593216 -> 1574704708048
	1574704708048 [label=AccumulateGrad]
	1574704707952 -> 1574704707808
	1574606593616 [label="features.denseblock4.denselayer9.conv1.weight
 (192, 1440, 1, 1)" fillcolor=lightblue]
	1574606593616 -> 1574704707952
	1574704707952 [label=AccumulateGrad]
	1574704707520 -> 1574704707712
	1574606593696 [label="features.denseblock4.denselayer9.norm2.weight
 (192)" fillcolor=lightblue]
	1574606593696 -> 1574704707520
	1574704707520 [label=AccumulateGrad]
	1574704707280 -> 1574704707712
	1574606593776 [label="features.denseblock4.denselayer9.norm2.bias
 (192)" fillcolor=lightblue]
	1574606593776 -> 1574704707280
	1574704707280 [label=AccumulateGrad]
	1574704707328 -> 1574704486560
	1574606594176 [label="features.denseblock4.denselayer9.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606594176 -> 1574704707328
	1574704707328 [label=AccumulateGrad]
	1574704486608 -> 1574704486032
	1574704486608 [label=ConvolutionBackward0]
	1574704707760 -> 1574704486608
	1574704707760 [label=ReluBackward0]
	1574704708288 -> 1574704707760
	1574704708288 [label=NativeBatchNormBackward0]
	1574704708384 -> 1574704708288
	1574704708384 [label=ConvolutionBackward0]
	1574704708576 -> 1574704708384
	1574704708576 [label=ReluBackward0]
	1574704708720 -> 1574704708576
	1574704708720 [label=NativeBatchNormBackward0]
	1574704708816 -> 1574704708720
	1574704708816 [label=CatBackward0]
	1574704486224 -> 1574704708816
	1574704486176 -> 1574704708816
	1574704486128 -> 1574704708816
	1574704486272 -> 1574704708816
	1574704486320 -> 1574704708816
	1574704486368 -> 1574704708816
	1574704486416 -> 1574704708816
	1574704486464 -> 1574704708816
	1574704486512 -> 1574704708816
	1574704486560 -> 1574704708816
	1574704708768 -> 1574704708720
	1574606594256 [label="features.denseblock4.denselayer10.norm1.weight
 (1488)" fillcolor=lightblue]
	1574606594256 -> 1574704708768
	1574704708768 [label=AccumulateGrad]
	1574704708624 -> 1574704708720
	1574606594336 [label="features.denseblock4.denselayer10.norm1.bias
 (1488)" fillcolor=lightblue]
	1574606594336 -> 1574704708624
	1574704708624 [label=AccumulateGrad]
	1574704708528 -> 1574704708384
	1574606594736 [label="features.denseblock4.denselayer10.conv1.weight
 (192, 1488, 1, 1)" fillcolor=lightblue]
	1574606594736 -> 1574704708528
	1574704708528 [label=AccumulateGrad]
	1574704708096 -> 1574704708288
	1574606594816 [label="features.denseblock4.denselayer10.norm2.weight
 (192)" fillcolor=lightblue]
	1574606594816 -> 1574704708096
	1574704708096 [label=AccumulateGrad]
	1574704707856 -> 1574704708288
	1574606594896 [label="features.denseblock4.denselayer10.norm2.bias
 (192)" fillcolor=lightblue]
	1574606594896 -> 1574704707856
	1574704707856 [label=AccumulateGrad]
	1574704707904 -> 1574704486608
	1574606595296 [label="features.denseblock4.denselayer10.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606595296 -> 1574704707904
	1574704707904 [label=AccumulateGrad]
	1574704486656 -> 1574704486032
	1574704486656 [label=ConvolutionBackward0]
	1574704708336 -> 1574704486656
	1574704708336 [label=ReluBackward0]
	1574704708864 -> 1574704708336
	1574704708864 [label=NativeBatchNormBackward0]
	1574704708960 -> 1574704708864
	1574704708960 [label=ConvolutionBackward0]
	1574704709152 -> 1574704708960
	1574704709152 [label=ReluBackward0]
	1574704709296 -> 1574704709152
	1574704709296 [label=NativeBatchNormBackward0]
	1574704709392 -> 1574704709296
	1574704709392 [label=CatBackward0]
	1574704486224 -> 1574704709392
	1574704486176 -> 1574704709392
	1574704486128 -> 1574704709392
	1574704486272 -> 1574704709392
	1574704486320 -> 1574704709392
	1574704486368 -> 1574704709392
	1574704486416 -> 1574704709392
	1574704486464 -> 1574704709392
	1574704486512 -> 1574704709392
	1574704486560 -> 1574704709392
	1574704486608 -> 1574704709392
	1574704709344 -> 1574704709296
	1574606595376 [label="features.denseblock4.denselayer11.norm1.weight
 (1536)" fillcolor=lightblue]
	1574606595376 -> 1574704709344
	1574704709344 [label=AccumulateGrad]
	1574704709200 -> 1574704709296
	1574606595456 [label="features.denseblock4.denselayer11.norm1.bias
 (1536)" fillcolor=lightblue]
	1574606595456 -> 1574704709200
	1574704709200 [label=AccumulateGrad]
	1574704709104 -> 1574704708960
	1574606595936 [label="features.denseblock4.denselayer11.conv1.weight
 (192, 1536, 1, 1)" fillcolor=lightblue]
	1574606595936 -> 1574704709104
	1574704709104 [label=AccumulateGrad]
	1574704708672 -> 1574704708864
	1574606596016 [label="features.denseblock4.denselayer11.norm2.weight
 (192)" fillcolor=lightblue]
	1574606596016 -> 1574704708672
	1574704708672 [label=AccumulateGrad]
	1574704708432 -> 1574704708864
	1574606596096 [label="features.denseblock4.denselayer11.norm2.bias
 (192)" fillcolor=lightblue]
	1574606596096 -> 1574704708432
	1574704708432 [label=AccumulateGrad]
	1574704708480 -> 1574704486656
	1574606596576 [label="features.denseblock4.denselayer11.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606596576 -> 1574704708480
	1574704708480 [label=AccumulateGrad]
	1574704486704 -> 1574704486032
	1574704486704 [label=ConvolutionBackward0]
	1574704708912 -> 1574704486704
	1574704708912 [label=ReluBackward0]
	1574704709440 -> 1574704708912
	1574704709440 [label=NativeBatchNormBackward0]
	1574704709536 -> 1574704709440
	1574704709536 [label=ConvolutionBackward0]
	1575027589280 -> 1574704709536
	1575027589280 [label=ReluBackward0]
	1575027589424 -> 1575027589280
	1575027589424 [label=NativeBatchNormBackward0]
	1575027589520 -> 1575027589424
	1575027589520 [label=CatBackward0]
	1574704486224 -> 1575027589520
	1574704486176 -> 1575027589520
	1574704486128 -> 1575027589520
	1574704486272 -> 1575027589520
	1574704486320 -> 1575027589520
	1574704486368 -> 1575027589520
	1574704486416 -> 1575027589520
	1574704486464 -> 1575027589520
	1574704486512 -> 1575027589520
	1574704486560 -> 1575027589520
	1574704486608 -> 1575027589520
	1574704486656 -> 1575027589520
	1575027589472 -> 1575027589424
	1574606596656 [label="features.denseblock4.denselayer12.norm1.weight
 (1584)" fillcolor=lightblue]
	1574606596656 -> 1575027589472
	1575027589472 [label=AccumulateGrad]
	1575027589328 -> 1575027589424
	1574606596736 [label="features.denseblock4.denselayer12.norm1.bias
 (1584)" fillcolor=lightblue]
	1574606596736 -> 1575027589328
	1575027589328 [label=AccumulateGrad]
	1575027589232 -> 1574704709536
	1574606597216 [label="features.denseblock4.denselayer12.conv1.weight
 (192, 1584, 1, 1)" fillcolor=lightblue]
	1574606597216 -> 1575027589232
	1575027589232 [label=AccumulateGrad]
	1574704709248 -> 1574704709440
	1574606597296 [label="features.denseblock4.denselayer12.norm2.weight
 (192)" fillcolor=lightblue]
	1574606597296 -> 1574704709248
	1574704709248 [label=AccumulateGrad]
	1574704709008 -> 1574704709440
	1574606597376 [label="features.denseblock4.denselayer12.norm2.bias
 (192)" fillcolor=lightblue]
	1574606597376 -> 1574704709008
	1574704709008 [label=AccumulateGrad]
	1574704709056 -> 1574704486704
	1574606597856 [label="features.denseblock4.denselayer12.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606597856 -> 1574704709056
	1574704709056 [label=AccumulateGrad]
	1574704486752 -> 1574704486032
	1574704486752 [label=ConvolutionBackward0]
	1574704709584 -> 1574704486752
	1574704709584 [label=ReluBackward0]
	1575027589568 -> 1574704709584
	1575027589568 [label=NativeBatchNormBackward0]
	1575027589664 -> 1575027589568
	1575027589664 [label=ConvolutionBackward0]
	1575027589856 -> 1575027589664
	1575027589856 [label=ReluBackward0]
	1575027590000 -> 1575027589856
	1575027590000 [label=NativeBatchNormBackward0]
	1575027590096 -> 1575027590000
	1575027590096 [label=CatBackward0]
	1574704486224 -> 1575027590096
	1574704486176 -> 1575027590096
	1574704486128 -> 1575027590096
	1574704486272 -> 1575027590096
	1574704486320 -> 1575027590096
	1574704486368 -> 1575027590096
	1574704486416 -> 1575027590096
	1574704486464 -> 1575027590096
	1574704486512 -> 1575027590096
	1574704486560 -> 1575027590096
	1574704486608 -> 1575027590096
	1574704486656 -> 1575027590096
	1574704486704 -> 1575027590096
	1575027590048 -> 1575027590000
	1574606597936 [label="features.denseblock4.denselayer13.norm1.weight
 (1632)" fillcolor=lightblue]
	1574606597936 -> 1575027590048
	1575027590048 [label=AccumulateGrad]
	1575027589904 -> 1575027590000
	1574606598016 [label="features.denseblock4.denselayer13.norm1.bias
 (1632)" fillcolor=lightblue]
	1574606598016 -> 1575027589904
	1575027589904 [label=AccumulateGrad]
	1575027589808 -> 1575027589664
	1574606598416 [label="features.denseblock4.denselayer13.conv1.weight
 (192, 1632, 1, 1)" fillcolor=lightblue]
	1574606598416 -> 1575027589808
	1575027589808 [label=AccumulateGrad]
	1575027589376 -> 1575027589568
	1574606598496 [label="features.denseblock4.denselayer13.norm2.weight
 (192)" fillcolor=lightblue]
	1574606598496 -> 1575027589376
	1575027589376 [label=AccumulateGrad]
	1575027589184 -> 1575027589568
	1574606598576 [label="features.denseblock4.denselayer13.norm2.bias
 (192)" fillcolor=lightblue]
	1574606598576 -> 1575027589184
	1575027589184 [label=AccumulateGrad]
	1574704709488 -> 1574704486752
	1574606599056 [label="features.denseblock4.denselayer13.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606599056 -> 1574704709488
	1574704709488 [label=AccumulateGrad]
	1574704486800 -> 1574704486032
	1574704486800 [label=ConvolutionBackward0]
	1574704703488 -> 1574704486800
	1574704703488 [label=ReluBackward0]
	1575027590144 -> 1574704703488
	1575027590144 [label=NativeBatchNormBackward0]
	1575027590240 -> 1575027590144
	1575027590240 [label=ConvolutionBackward0]
	1575027590432 -> 1575027590240
	1575027590432 [label=ReluBackward0]
	1575027590576 -> 1575027590432
	1575027590576 [label=NativeBatchNormBackward0]
	1575027590672 -> 1575027590576
	1575027590672 [label=CatBackward0]
	1574704486224 -> 1575027590672
	1574704486176 -> 1575027590672
	1574704486128 -> 1575027590672
	1574704486272 -> 1575027590672
	1574704486320 -> 1575027590672
	1574704486368 -> 1575027590672
	1574704486416 -> 1575027590672
	1574704486464 -> 1575027590672
	1574704486512 -> 1575027590672
	1574704486560 -> 1575027590672
	1574704486608 -> 1575027590672
	1574704486656 -> 1575027590672
	1574704486704 -> 1575027590672
	1574704486752 -> 1575027590672
	1575027590624 -> 1575027590576
	1574606599136 [label="features.denseblock4.denselayer14.norm1.weight
 (1680)" fillcolor=lightblue]
	1574606599136 -> 1575027590624
	1575027590624 [label=AccumulateGrad]
	1575027590480 -> 1575027590576
	1574606599216 [label="features.denseblock4.denselayer14.norm1.bias
 (1680)" fillcolor=lightblue]
	1574606599216 -> 1575027590480
	1575027590480 [label=AccumulateGrad]
	1575027590384 -> 1575027590240
	1574606599696 [label="features.denseblock4.denselayer14.conv1.weight
 (192, 1680, 1, 1)" fillcolor=lightblue]
	1574606599696 -> 1575027590384
	1575027590384 [label=AccumulateGrad]
	1575027589952 -> 1575027590144
	1574606599776 [label="features.denseblock4.denselayer14.norm2.weight
 (192)" fillcolor=lightblue]
	1574606599776 -> 1575027589952
	1575027589952 [label=AccumulateGrad]
	1575027589712 -> 1575027590144
	1574606599856 [label="features.denseblock4.denselayer14.norm2.bias
 (192)" fillcolor=lightblue]
	1574606599856 -> 1575027589712
	1575027589712 [label=AccumulateGrad]
	1575027589616 -> 1574704486800
	1574606600336 [label="features.denseblock4.denselayer14.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606600336 -> 1575027589616
	1575027589616 [label=AccumulateGrad]
	1574704486848 -> 1574704486032
	1574704486848 [label=ConvolutionBackward0]
	1575027590192 -> 1574704486848
	1575027590192 [label=ReluBackward0]
	1575027590720 -> 1575027590192
	1575027590720 [label=NativeBatchNormBackward0]
	1575027590816 -> 1575027590720
	1575027590816 [label=ConvolutionBackward0]
	1575027591008 -> 1575027590816
	1575027591008 [label=ReluBackward0]
	1575027591152 -> 1575027591008
	1575027591152 [label=NativeBatchNormBackward0]
	1575027591248 -> 1575027591152
	1575027591248 [label=CatBackward0]
	1574704486224 -> 1575027591248
	1574704486176 -> 1575027591248
	1574704486128 -> 1575027591248
	1574704486272 -> 1575027591248
	1574704486320 -> 1575027591248
	1574704486368 -> 1575027591248
	1574704486416 -> 1575027591248
	1574704486464 -> 1575027591248
	1574704486512 -> 1575027591248
	1574704486560 -> 1575027591248
	1574704486608 -> 1575027591248
	1574704486656 -> 1575027591248
	1574704486704 -> 1575027591248
	1574704486752 -> 1575027591248
	1574704486800 -> 1575027591248
	1575027591200 -> 1575027591152
	1574606600416 [label="features.denseblock4.denselayer15.norm1.weight
 (1728)" fillcolor=lightblue]
	1574606600416 -> 1575027591200
	1575027591200 [label=AccumulateGrad]
	1575027591056 -> 1575027591152
	1574606600496 [label="features.denseblock4.denselayer15.norm1.bias
 (1728)" fillcolor=lightblue]
	1574606600496 -> 1575027591056
	1575027591056 [label=AccumulateGrad]
	1575027590960 -> 1575027590816
	1574606600976 [label="features.denseblock4.denselayer15.conv1.weight
 (192, 1728, 1, 1)" fillcolor=lightblue]
	1574606600976 -> 1575027590960
	1575027590960 [label=AccumulateGrad]
	1575027590528 -> 1575027590720
	1574606601056 [label="features.denseblock4.denselayer15.norm2.weight
 (192)" fillcolor=lightblue]
	1574606601056 -> 1575027590528
	1575027590528 [label=AccumulateGrad]
	1575027590288 -> 1575027590720
	1574606601136 [label="features.denseblock4.denselayer15.norm2.bias
 (192)" fillcolor=lightblue]
	1574606601136 -> 1575027590288
	1575027590288 [label=AccumulateGrad]
	1575027590336 -> 1574704486848
	1574606601616 [label="features.denseblock4.denselayer15.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606601616 -> 1575027590336
	1575027590336 [label=AccumulateGrad]
	1574704486896 -> 1574704486032
	1574704486896 [label=ConvolutionBackward0]
	1575027590768 -> 1574704486896
	1575027590768 [label=ReluBackward0]
	1575027591296 -> 1575027590768
	1575027591296 [label=NativeBatchNormBackward0]
	1575027591392 -> 1575027591296
	1575027591392 [label=ConvolutionBackward0]
	1575027591584 -> 1575027591392
	1575027591584 [label=ReluBackward0]
	1575027591728 -> 1575027591584
	1575027591728 [label=NativeBatchNormBackward0]
	1575027591824 -> 1575027591728
	1575027591824 [label=CatBackward0]
	1574704486224 -> 1575027591824
	1574704486176 -> 1575027591824
	1574704486128 -> 1575027591824
	1574704486272 -> 1575027591824
	1574704486320 -> 1575027591824
	1574704486368 -> 1575027591824
	1574704486416 -> 1575027591824
	1574704486464 -> 1575027591824
	1574704486512 -> 1575027591824
	1574704486560 -> 1575027591824
	1574704486608 -> 1575027591824
	1574704486656 -> 1575027591824
	1574704486704 -> 1575027591824
	1574704486752 -> 1575027591824
	1574704486800 -> 1575027591824
	1574704486848 -> 1575027591824
	1575027591776 -> 1575027591728
	1574606601696 [label="features.denseblock4.denselayer16.norm1.weight
 (1776)" fillcolor=lightblue]
	1574606601696 -> 1575027591776
	1575027591776 [label=AccumulateGrad]
	1575027591632 -> 1575027591728
	1574606601776 [label="features.denseblock4.denselayer16.norm1.bias
 (1776)" fillcolor=lightblue]
	1574606601776 -> 1575027591632
	1575027591632 [label=AccumulateGrad]
	1575027591536 -> 1575027591392
	1574606848080 [label="features.denseblock4.denselayer16.conv1.weight
 (192, 1776, 1, 1)" fillcolor=lightblue]
	1574606848080 -> 1575027591536
	1575027591536 [label=AccumulateGrad]
	1575027591104 -> 1575027591296
	1574606848160 [label="features.denseblock4.denselayer16.norm2.weight
 (192)" fillcolor=lightblue]
	1574606848160 -> 1575027591104
	1575027591104 [label=AccumulateGrad]
	1575027590864 -> 1575027591296
	1574606848240 [label="features.denseblock4.denselayer16.norm2.bias
 (192)" fillcolor=lightblue]
	1574606848240 -> 1575027590864
	1575027590864 [label=AccumulateGrad]
	1575027590912 -> 1574704486896
	1574606848640 [label="features.denseblock4.denselayer16.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606848640 -> 1575027590912
	1575027590912 [label=AccumulateGrad]
	1574704486944 -> 1574704486032
	1574704486944 [label=ConvolutionBackward0]
	1575027591344 -> 1574704486944
	1575027591344 [label=ReluBackward0]
	1575027591872 -> 1575027591344
	1575027591872 [label=NativeBatchNormBackward0]
	1575027591968 -> 1575027591872
	1575027591968 [label=ConvolutionBackward0]
	1575027592160 -> 1575027591968
	1575027592160 [label=ReluBackward0]
	1575027592304 -> 1575027592160
	1575027592304 [label=NativeBatchNormBackward0]
	1575027592400 -> 1575027592304
	1575027592400 [label=CatBackward0]
	1574704486224 -> 1575027592400
	1574704486176 -> 1575027592400
	1574704486128 -> 1575027592400
	1574704486272 -> 1575027592400
	1574704486320 -> 1575027592400
	1574704486368 -> 1575027592400
	1574704486416 -> 1575027592400
	1574704486464 -> 1575027592400
	1574704486512 -> 1575027592400
	1574704486560 -> 1575027592400
	1574704486608 -> 1575027592400
	1574704486656 -> 1575027592400
	1574704486704 -> 1575027592400
	1574704486752 -> 1575027592400
	1574704486800 -> 1575027592400
	1574704486848 -> 1575027592400
	1574704486896 -> 1575027592400
	1575027592352 -> 1575027592304
	1574606848720 [label="features.denseblock4.denselayer17.norm1.weight
 (1824)" fillcolor=lightblue]
	1574606848720 -> 1575027592352
	1575027592352 [label=AccumulateGrad]
	1575027592208 -> 1575027592304
	1574606848800 [label="features.denseblock4.denselayer17.norm1.bias
 (1824)" fillcolor=lightblue]
	1574606848800 -> 1575027592208
	1575027592208 [label=AccumulateGrad]
	1575027592112 -> 1575027591968
	1574606849200 [label="features.denseblock4.denselayer17.conv1.weight
 (192, 1824, 1, 1)" fillcolor=lightblue]
	1574606849200 -> 1575027592112
	1575027592112 [label=AccumulateGrad]
	1575027591680 -> 1575027591872
	1574606849280 [label="features.denseblock4.denselayer17.norm2.weight
 (192)" fillcolor=lightblue]
	1574606849280 -> 1575027591680
	1575027591680 [label=AccumulateGrad]
	1575027591440 -> 1575027591872
	1574606849360 [label="features.denseblock4.denselayer17.norm2.bias
 (192)" fillcolor=lightblue]
	1574606849360 -> 1575027591440
	1575027591440 [label=AccumulateGrad]
	1575027591488 -> 1574704486944
	1574606849840 [label="features.denseblock4.denselayer17.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606849840 -> 1575027591488
	1575027591488 [label=AccumulateGrad]
	1574704486992 -> 1574704486032
	1574704486992 [label=ConvolutionBackward0]
	1575027591920 -> 1574704486992
	1575027591920 [label=ReluBackward0]
	1575027592448 -> 1575027591920
	1575027592448 [label=NativeBatchNormBackward0]
	1575027592544 -> 1575027592448
	1575027592544 [label=ConvolutionBackward0]
	1575027592736 -> 1575027592544
	1575027592736 [label=ReluBackward0]
	1575027592880 -> 1575027592736
	1575027592880 [label=NativeBatchNormBackward0]
	1575027592976 -> 1575027592880
	1575027592976 [label=CatBackward0]
	1574704486224 -> 1575027592976
	1574704486176 -> 1575027592976
	1574704486128 -> 1575027592976
	1574704486272 -> 1575027592976
	1574704486320 -> 1575027592976
	1574704486368 -> 1575027592976
	1574704486416 -> 1575027592976
	1574704486464 -> 1575027592976
	1574704486512 -> 1575027592976
	1574704486560 -> 1575027592976
	1574704486608 -> 1575027592976
	1574704486656 -> 1575027592976
	1574704486704 -> 1575027592976
	1574704486752 -> 1575027592976
	1574704486800 -> 1575027592976
	1574704486848 -> 1575027592976
	1574704486896 -> 1575027592976
	1574704486944 -> 1575027592976
	1575027592928 -> 1575027592880
	1574606849920 [label="features.denseblock4.denselayer18.norm1.weight
 (1872)" fillcolor=lightblue]
	1574606849920 -> 1575027592928
	1575027592928 [label=AccumulateGrad]
	1575027592784 -> 1575027592880
	1574606850000 [label="features.denseblock4.denselayer18.norm1.bias
 (1872)" fillcolor=lightblue]
	1574606850000 -> 1575027592784
	1575027592784 [label=AccumulateGrad]
	1575027592688 -> 1575027592544
	1574606850400 [label="features.denseblock4.denselayer18.conv1.weight
 (192, 1872, 1, 1)" fillcolor=lightblue]
	1574606850400 -> 1575027592688
	1575027592688 [label=AccumulateGrad]
	1575027592256 -> 1575027592448
	1574606850480 [label="features.denseblock4.denselayer18.norm2.weight
 (192)" fillcolor=lightblue]
	1574606850480 -> 1575027592256
	1575027592256 [label=AccumulateGrad]
	1575027592016 -> 1575027592448
	1574606850560 [label="features.denseblock4.denselayer18.norm2.bias
 (192)" fillcolor=lightblue]
	1574606850560 -> 1575027592016
	1575027592016 [label=AccumulateGrad]
	1575027592064 -> 1574704486992
	1574606850960 [label="features.denseblock4.denselayer18.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606850960 -> 1575027592064
	1575027592064 [label=AccumulateGrad]
	1574704487040 -> 1574704486032
	1574704487040 [label=ConvolutionBackward0]
	1575027592496 -> 1574704487040
	1575027592496 [label=ReluBackward0]
	1575027593024 -> 1575027592496
	1575027593024 [label=NativeBatchNormBackward0]
	1575027593120 -> 1575027593024
	1575027593120 [label=ConvolutionBackward0]
	1575027593312 -> 1575027593120
	1575027593312 [label=ReluBackward0]
	1575027593456 -> 1575027593312
	1575027593456 [label=NativeBatchNormBackward0]
	1575027593552 -> 1575027593456
	1575027593552 [label=CatBackward0]
	1574704486224 -> 1575027593552
	1574704486176 -> 1575027593552
	1574704486128 -> 1575027593552
	1574704486272 -> 1575027593552
	1574704486320 -> 1575027593552
	1574704486368 -> 1575027593552
	1574704486416 -> 1575027593552
	1574704486464 -> 1575027593552
	1574704486512 -> 1575027593552
	1574704486560 -> 1575027593552
	1574704486608 -> 1575027593552
	1574704486656 -> 1575027593552
	1574704486704 -> 1575027593552
	1574704486752 -> 1575027593552
	1574704486800 -> 1575027593552
	1574704486848 -> 1575027593552
	1574704486896 -> 1575027593552
	1574704486944 -> 1575027593552
	1574704486992 -> 1575027593552
	1575027593504 -> 1575027593456
	1574606851040 [label="features.denseblock4.denselayer19.norm1.weight
 (1920)" fillcolor=lightblue]
	1574606851040 -> 1575027593504
	1575027593504 [label=AccumulateGrad]
	1575027593360 -> 1575027593456
	1574606851120 [label="features.denseblock4.denselayer19.norm1.bias
 (1920)" fillcolor=lightblue]
	1574606851120 -> 1575027593360
	1575027593360 [label=AccumulateGrad]
	1575027593264 -> 1575027593120
	1574606851600 [label="features.denseblock4.denselayer19.conv1.weight
 (192, 1920, 1, 1)" fillcolor=lightblue]
	1574606851600 -> 1575027593264
	1575027593264 [label=AccumulateGrad]
	1575027592832 -> 1575027593024
	1574606851680 [label="features.denseblock4.denselayer19.norm2.weight
 (192)" fillcolor=lightblue]
	1574606851680 -> 1575027592832
	1575027592832 [label=AccumulateGrad]
	1575027592592 -> 1575027593024
	1574606851760 [label="features.denseblock4.denselayer19.norm2.bias
 (192)" fillcolor=lightblue]
	1574606851760 -> 1575027592592
	1575027592592 [label=AccumulateGrad]
	1575027592640 -> 1574704487040
	1574606852240 [label="features.denseblock4.denselayer19.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606852240 -> 1575027592640
	1575027592640 [label=AccumulateGrad]
	1574704487088 -> 1574704486032
	1574704487088 [label=ConvolutionBackward0]
	1575027593072 -> 1574704487088
	1575027593072 [label=ReluBackward0]
	1575027593600 -> 1575027593072
	1575027593600 [label=NativeBatchNormBackward0]
	1575027593696 -> 1575027593600
	1575027593696 [label=ConvolutionBackward0]
	1575027593888 -> 1575027593696
	1575027593888 [label=ReluBackward0]
	1575027594032 -> 1575027593888
	1575027594032 [label=NativeBatchNormBackward0]
	1575027594128 -> 1575027594032
	1575027594128 [label=CatBackward0]
	1574704486224 -> 1575027594128
	1574704486176 -> 1575027594128
	1574704486128 -> 1575027594128
	1574704486272 -> 1575027594128
	1574704486320 -> 1575027594128
	1574704486368 -> 1575027594128
	1574704486416 -> 1575027594128
	1574704486464 -> 1575027594128
	1574704486512 -> 1575027594128
	1574704486560 -> 1575027594128
	1574704486608 -> 1575027594128
	1574704486656 -> 1575027594128
	1574704486704 -> 1575027594128
	1574704486752 -> 1575027594128
	1574704486800 -> 1575027594128
	1574704486848 -> 1575027594128
	1574704486896 -> 1575027594128
	1574704486944 -> 1575027594128
	1574704486992 -> 1575027594128
	1574704487040 -> 1575027594128
	1575027594080 -> 1575027594032
	1574606852320 [label="features.denseblock4.denselayer20.norm1.weight
 (1968)" fillcolor=lightblue]
	1574606852320 -> 1575027594080
	1575027594080 [label=AccumulateGrad]
	1575027593936 -> 1575027594032
	1574606852400 [label="features.denseblock4.denselayer20.norm1.bias
 (1968)" fillcolor=lightblue]
	1574606852400 -> 1575027593936
	1575027593936 [label=AccumulateGrad]
	1575027593840 -> 1575027593696
	1574606852880 [label="features.denseblock4.denselayer20.conv1.weight
 (192, 1968, 1, 1)" fillcolor=lightblue]
	1574606852880 -> 1575027593840
	1575027593840 [label=AccumulateGrad]
	1575027593408 -> 1575027593600
	1574606852960 [label="features.denseblock4.denselayer20.norm2.weight
 (192)" fillcolor=lightblue]
	1574606852960 -> 1575027593408
	1575027593408 [label=AccumulateGrad]
	1575027593168 -> 1575027593600
	1574606853040 [label="features.denseblock4.denselayer20.norm2.bias
 (192)" fillcolor=lightblue]
	1574606853040 -> 1575027593168
	1575027593168 [label=AccumulateGrad]
	1575027593216 -> 1574704487088
	1574606853520 [label="features.denseblock4.denselayer20.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606853520 -> 1575027593216
	1575027593216 [label=AccumulateGrad]
	1574704487136 -> 1574704486032
	1574704487136 [label=ConvolutionBackward0]
	1575027593648 -> 1574704487136
	1575027593648 [label=ReluBackward0]
	1575027594176 -> 1575027593648
	1575027594176 [label=NativeBatchNormBackward0]
	1575027594272 -> 1575027594176
	1575027594272 [label=ConvolutionBackward0]
	1575027594464 -> 1575027594272
	1575027594464 [label=ReluBackward0]
	1575027594608 -> 1575027594464
	1575027594608 [label=NativeBatchNormBackward0]
	1575027594704 -> 1575027594608
	1575027594704 [label=CatBackward0]
	1574704486224 -> 1575027594704
	1574704486176 -> 1575027594704
	1574704486128 -> 1575027594704
	1574704486272 -> 1575027594704
	1574704486320 -> 1575027594704
	1574704486368 -> 1575027594704
	1574704486416 -> 1575027594704
	1574704486464 -> 1575027594704
	1574704486512 -> 1575027594704
	1574704486560 -> 1575027594704
	1574704486608 -> 1575027594704
	1574704486656 -> 1575027594704
	1574704486704 -> 1575027594704
	1574704486752 -> 1575027594704
	1574704486800 -> 1575027594704
	1574704486848 -> 1575027594704
	1574704486896 -> 1575027594704
	1574704486944 -> 1575027594704
	1574704486992 -> 1575027594704
	1574704487040 -> 1575027594704
	1574704487088 -> 1575027594704
	1575027594656 -> 1575027594608
	1574606853600 [label="features.denseblock4.denselayer21.norm1.weight
 (2016)" fillcolor=lightblue]
	1574606853600 -> 1575027594656
	1575027594656 [label=AccumulateGrad]
	1575027594512 -> 1575027594608
	1574606853680 [label="features.denseblock4.denselayer21.norm1.bias
 (2016)" fillcolor=lightblue]
	1574606853680 -> 1575027594512
	1575027594512 [label=AccumulateGrad]
	1575027594416 -> 1575027594272
	1574606854160 [label="features.denseblock4.denselayer21.conv1.weight
 (192, 2016, 1, 1)" fillcolor=lightblue]
	1574606854160 -> 1575027594416
	1575027594416 [label=AccumulateGrad]
	1575027593984 -> 1575027594176
	1574606854240 [label="features.denseblock4.denselayer21.norm2.weight
 (192)" fillcolor=lightblue]
	1574606854240 -> 1575027593984
	1575027593984 [label=AccumulateGrad]
	1575027593744 -> 1575027594176
	1574606854320 [label="features.denseblock4.denselayer21.norm2.bias
 (192)" fillcolor=lightblue]
	1574606854320 -> 1575027593744
	1575027593744 [label=AccumulateGrad]
	1575027593792 -> 1574704487136
	1574606854800 [label="features.denseblock4.denselayer21.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606854800 -> 1575027593792
	1575027593792 [label=AccumulateGrad]
	1574704487184 -> 1574704486032
	1574704487184 [label=ConvolutionBackward0]
	1575027594224 -> 1574704487184
	1575027594224 [label=ReluBackward0]
	1575027594752 -> 1575027594224
	1575027594752 [label=NativeBatchNormBackward0]
	1575027594848 -> 1575027594752
	1575027594848 [label=ConvolutionBackward0]
	1575027595040 -> 1575027594848
	1575027595040 [label=ReluBackward0]
	1575027595184 -> 1575027595040
	1575027595184 [label=NativeBatchNormBackward0]
	1575027595280 -> 1575027595184
	1575027595280 [label=CatBackward0]
	1574704486224 -> 1575027595280
	1574704486176 -> 1575027595280
	1574704486128 -> 1575027595280
	1574704486272 -> 1575027595280
	1574704486320 -> 1575027595280
	1574704486368 -> 1575027595280
	1574704486416 -> 1575027595280
	1574704486464 -> 1575027595280
	1574704486512 -> 1575027595280
	1574704486560 -> 1575027595280
	1574704486608 -> 1575027595280
	1574704486656 -> 1575027595280
	1574704486704 -> 1575027595280
	1574704486752 -> 1575027595280
	1574704486800 -> 1575027595280
	1574704486848 -> 1575027595280
	1574704486896 -> 1575027595280
	1574704486944 -> 1575027595280
	1574704486992 -> 1575027595280
	1574704487040 -> 1575027595280
	1574704487088 -> 1575027595280
	1574704487136 -> 1575027595280
	1575027595232 -> 1575027595184
	1574606854880 [label="features.denseblock4.denselayer22.norm1.weight
 (2064)" fillcolor=lightblue]
	1574606854880 -> 1575027595232
	1575027595232 [label=AccumulateGrad]
	1575027595088 -> 1575027595184
	1574606854960 [label="features.denseblock4.denselayer22.norm1.bias
 (2064)" fillcolor=lightblue]
	1574606854960 -> 1575027595088
	1575027595088 [label=AccumulateGrad]
	1575027594992 -> 1575027594848
	1574606855440 [label="features.denseblock4.denselayer22.conv1.weight
 (192, 2064, 1, 1)" fillcolor=lightblue]
	1574606855440 -> 1575027594992
	1575027594992 [label=AccumulateGrad]
	1575027594560 -> 1575027594752
	1574606855520 [label="features.denseblock4.denselayer22.norm2.weight
 (192)" fillcolor=lightblue]
	1574606855520 -> 1575027594560
	1575027594560 [label=AccumulateGrad]
	1575027594320 -> 1575027594752
	1574606855600 [label="features.denseblock4.denselayer22.norm2.bias
 (192)" fillcolor=lightblue]
	1574606855600 -> 1575027594320
	1575027594320 [label=AccumulateGrad]
	1575027594368 -> 1574704487184
	1574606856080 [label="features.denseblock4.denselayer22.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606856080 -> 1575027594368
	1575027594368 [label=AccumulateGrad]
	1574704487232 -> 1574704486032
	1574704487232 [label=ConvolutionBackward0]
	1575027594800 -> 1574704487232
	1575027594800 [label=ReluBackward0]
	1575027595328 -> 1575027594800
	1575027595328 [label=NativeBatchNormBackward0]
	1575027595424 -> 1575027595328
	1575027595424 [label=ConvolutionBackward0]
	1575027595616 -> 1575027595424
	1575027595616 [label=ReluBackward0]
	1575027595760 -> 1575027595616
	1575027595760 [label=NativeBatchNormBackward0]
	1575027595856 -> 1575027595760
	1575027595856 [label=CatBackward0]
	1574704486224 -> 1575027595856
	1574704486176 -> 1575027595856
	1574704486128 -> 1575027595856
	1574704486272 -> 1575027595856
	1574704486320 -> 1575027595856
	1574704486368 -> 1575027595856
	1574704486416 -> 1575027595856
	1574704486464 -> 1575027595856
	1574704486512 -> 1575027595856
	1574704486560 -> 1575027595856
	1574704486608 -> 1575027595856
	1574704486656 -> 1575027595856
	1574704486704 -> 1575027595856
	1574704486752 -> 1575027595856
	1574704486800 -> 1575027595856
	1574704486848 -> 1575027595856
	1574704486896 -> 1575027595856
	1574704486944 -> 1575027595856
	1574704486992 -> 1575027595856
	1574704487040 -> 1575027595856
	1574704487088 -> 1575027595856
	1574704487136 -> 1575027595856
	1574704487184 -> 1575027595856
	1575027595808 -> 1575027595760
	1574606856160 [label="features.denseblock4.denselayer23.norm1.weight
 (2112)" fillcolor=lightblue]
	1574606856160 -> 1575027595808
	1575027595808 [label=AccumulateGrad]
	1575027595664 -> 1575027595760
	1574606856240 [label="features.denseblock4.denselayer23.norm1.bias
 (2112)" fillcolor=lightblue]
	1574606856240 -> 1575027595664
	1575027595664 [label=AccumulateGrad]
	1575027595568 -> 1575027595424
	1574606856720 [label="features.denseblock4.denselayer23.conv1.weight
 (192, 2112, 1, 1)" fillcolor=lightblue]
	1574606856720 -> 1575027595568
	1575027595568 [label=AccumulateGrad]
	1575027595136 -> 1575027595328
	1574606856800 [label="features.denseblock4.denselayer23.norm2.weight
 (192)" fillcolor=lightblue]
	1574606856800 -> 1575027595136
	1575027595136 [label=AccumulateGrad]
	1575027594896 -> 1575027595328
	1574606856880 [label="features.denseblock4.denselayer23.norm2.bias
 (192)" fillcolor=lightblue]
	1574606856880 -> 1575027594896
	1575027594896 [label=AccumulateGrad]
	1575027594944 -> 1574704487232
	1574606857360 [label="features.denseblock4.denselayer23.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606857360 -> 1575027594944
	1575027594944 [label=AccumulateGrad]
	1574704487280 -> 1574704486032
	1574704487280 [label=ConvolutionBackward0]
	1575027595376 -> 1574704487280
	1575027595376 [label=ReluBackward0]
	1575027595904 -> 1575027595376
	1575027595904 [label=NativeBatchNormBackward0]
	1575027596000 -> 1575027595904
	1575027596000 [label=ConvolutionBackward0]
	1575027596192 -> 1575027596000
	1575027596192 [label=ReluBackward0]
	1575027596336 -> 1575027596192
	1575027596336 [label=NativeBatchNormBackward0]
	1575027596432 -> 1575027596336
	1575027596432 [label=CatBackward0]
	1574704486224 -> 1575027596432
	1574704486176 -> 1575027596432
	1574704486128 -> 1575027596432
	1574704486272 -> 1575027596432
	1574704486320 -> 1575027596432
	1574704486368 -> 1575027596432
	1574704486416 -> 1575027596432
	1574704486464 -> 1575027596432
	1574704486512 -> 1575027596432
	1574704486560 -> 1575027596432
	1574704486608 -> 1575027596432
	1574704486656 -> 1575027596432
	1574704486704 -> 1575027596432
	1574704486752 -> 1575027596432
	1574704486800 -> 1575027596432
	1574704486848 -> 1575027596432
	1574704486896 -> 1575027596432
	1574704486944 -> 1575027596432
	1574704486992 -> 1575027596432
	1574704487040 -> 1575027596432
	1574704487088 -> 1575027596432
	1574704487136 -> 1575027596432
	1574704487184 -> 1575027596432
	1574704487232 -> 1575027596432
	1575027596384 -> 1575027596336
	1574606857440 [label="features.denseblock4.denselayer24.norm1.weight
 (2160)" fillcolor=lightblue]
	1574606857440 -> 1575027596384
	1575027596384 [label=AccumulateGrad]
	1575027596240 -> 1575027596336
	1574606857520 [label="features.denseblock4.denselayer24.norm1.bias
 (2160)" fillcolor=lightblue]
	1574606857520 -> 1575027596240
	1575027596240 [label=AccumulateGrad]
	1575027596144 -> 1575027596000
	1574606858000 [label="features.denseblock4.denselayer24.conv1.weight
 (192, 2160, 1, 1)" fillcolor=lightblue]
	1574606858000 -> 1575027596144
	1575027596144 [label=AccumulateGrad]
	1575027595712 -> 1575027595904
	1574606858080 [label="features.denseblock4.denselayer24.norm2.weight
 (192)" fillcolor=lightblue]
	1574606858080 -> 1575027595712
	1575027595712 [label=AccumulateGrad]
	1575027595472 -> 1575027595904
	1574606858160 [label="features.denseblock4.denselayer24.norm2.bias
 (192)" fillcolor=lightblue]
	1574606858160 -> 1575027595472
	1575027595472 [label=AccumulateGrad]
	1575027595520 -> 1574704487280
	1574606858640 [label="features.denseblock4.denselayer24.conv2.weight
 (48, 192, 3, 3)" fillcolor=lightblue]
	1574606858640 -> 1575027595520
	1575027595520 [label=AccumulateGrad]
	1574704485984 -> 1574704485936
	1574606858560 [label="features.norm5.weight
 (2208)" fillcolor=lightblue]
	1574606858560 -> 1574704485984
	1574704485984 [label=AccumulateGrad]
	1574704485744 -> 1574704485936
	1574606858720 [label="features.norm5.bias
 (2208)" fillcolor=lightblue]
	1574606858720 -> 1574704485744
	1574704485744 [label=AccumulateGrad]
	1574704485648 -> 1574704485408
	1574704485648 [label=TBackward0]
	1574704485888 -> 1574704485648
	1574606859040 [label="classifier.weight
 (1000, 2208)" fillcolor=lightblue]
	1574606859040 -> 1574704485888
	1574704485888 [label=AccumulateGrad]
	1574704485408 -> 1574703919136
}
